# main_integration.py
# ä¸»é›†æˆæ‰§è¡Œè„šæœ¬ - åè°ƒæ‰€æœ‰æ¨¡å—é€šè¿‡Orchestratorè¿è¡Œ
#
# æ‰§è¡Œé¡ºåº: M1 â†’ M4 â†’ M5 â†’ M6 â†’ M3
# æ¯æ—¥å¤„ç†æ¨¡å¼ï¼Œç¡®ä¿æ¨¡å—é—´æ•°æ®æµç¯ç¯ç›¸æ‰£

import pandas as pd
import numpy as np
from pathlib import Path
import sys
from datetime import datetime
import os

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
from orchestrator import create_orchestrator
from validation_manager import ValidationManager
from time_manager import SimulationTimeManager, initialize_time_manager
from config_validator import run_pre_simulation_validation
from inventory_balance_checker import InventoryBalanceChecker
from summary_report_generator import SummaryReportGenerator
import module1
import module3
import module4
import module5
import module6


# æ ‡è¯†ç¬¦å­—æ®µæ ‡å‡†åŒ–å‡½æ•°ï¼ˆç»Ÿä¸€å¤„ç†æ‰€æœ‰é…ç½®è¡¨ï¼‰
def _normalize_location(location_str) -> str:
    """Normalize location string by padding with leading zeros to 4 digits"""
    try:
        return str(int(location_str)).zfill(4)
    except (ValueError, TypeError):
        return str(location_str).zfill(4)

def _normalize_material(material_str) -> str:
    """Normalize material string"""
    return str(material_str) if material_str is not None else ""

def _normalize_sending(sending_str) -> str:
    """Normalize sending string by padding with leading zeros to 4 digits"""
    try:
        return str(int(sending_str)).zfill(4)
    except (ValueError, TypeError):
        return str(sending_str).zfill(4)

def _normalize_receiving(receiving_str) -> str:
    """Normalize receiving string by padding with leading zeros to 4 digits"""
    try:
        return str(int(receiving_str)).zfill(4)
    except (ValueError, TypeError):
        return str(receiving_str).zfill(4)

def _normalize_identifiers(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize identifier columns to string format with proper formatting"""
    if df.empty:
        return df
    
    # Define identifier columns that need string conversion
    identifier_cols = ['material', 'location', 'sending', 'receiving', 'sourcing', 'dps_location', 'from_material', 'to_material', 'line', 'delegate_line']
    
    df = df.copy()
    for col in identifier_cols:
        if col in df.columns:
            # Convert to string and handle NaN values
            df[col] = df[col].astype('string')
            # Apply specific normalization for location-type fields
            if col in ['location', 'dps_location']:
                df[col] = df[col].apply(_normalize_location)
            elif col == 'sending':
                df[col] = df[col].apply(_normalize_sending)
            elif col == 'receiving':
                df[col] = df[col].apply(_normalize_receiving)
            # Apply specific normalization for material-type fields
            elif col in ['material', 'from_material', 'to_material']:
                df[col] = df[col].apply(_normalize_material)
            # For other identifier columns (line, delegate_line, etc), ensure they are properly formatted strings
            else:
                df[col] = df[col].apply(lambda x: str(x) if pd.notna(x) else "")
    
    return df

def run_module4_integrated(
    config_dict: dict,
    module3_output_dir: str,
    simulation_date: pd.Timestamp,
    simulation_start: pd.Timestamp,
    output_dir: str
) -> pd.DataFrame:
    """
    é›†æˆæ¨¡å¼è¿è¡Œ Module4 ç”Ÿäº§è®¡åˆ’ï¼Œç›´æ¥ä½¿ç”¨ config_dict æ•°æ®
    
    Args:
        config_dict: é…ç½®æ•°æ®å­—å…¸
        module3_output_dir: Module3 è¾“å‡ºç›®å½•
        simulation_date: å½“å‰ä»¿çœŸæ—¥æœŸ
        simulation_start: ä»¿çœŸå¼€å§‹æ—¥æœŸ
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        pd.DataFrame: ç”Ÿäº§è®¡åˆ’æ•°æ®
    """
    try:
        # éªŒè¯å¿…éœ€çš„Module4é…ç½®æ•°æ®
        required_m4_configs = [
            'M4_MaterialLocationLineCfg',
            'M4_LineCapacity', 
            'M4_ChangeoverMatrix',
            'M4_ChangeoverDefinition',
            'M4_ProductionReliability'
        ]
        
        for config_name in required_m4_configs:
            if config_name not in config_dict or config_dict[config_name].empty:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„Module4é…ç½®æ•°æ®ï¼š{config_name}")
        
        # ç›´æ¥æ„å»º Module4 æ‰€éœ€çš„é…ç½®æ•°æ®
        # ç›´æ¥ä½¿ç”¨config_dictï¼Œä¸å†éœ€è¦å­é…ç½®å­—å…¸
        m4_config = config_dict
        
        # åŠ è½½ Module3 çš„æ—¥åº¦å‡€éœ€æ±‚æ•°æ®
        net_demand_df = module4.load_daily_net_demand(module3_output_dir, simulation_date)
        net_demand_df = module4._cast_identifiers_to_str(net_demand_df, ['material', 'location'])
        
        if net_demand_df.empty:
            print(f"Warning: No NetDemand data for {simulation_date.strftime('%Y-%m-%d')}. Generating empty output.")
        
        # ç¡®ä¿ requirement_date æ˜¯ datetime ç±»å‹
        if not net_demand_df.empty and 'requirement_date' in net_demand_df.columns:
            net_demand_df['requirement_date'] = pd.to_datetime(net_demand_df['requirement_date'])
        
        # æ„å»ºæ— çº¦æŸè®¡åˆ’
        mlcfg = m4_config['M4_MaterialLocationLineCfg']
        
        # ç¡®ä¿MLCFGä¹Ÿåº”ç”¨ç±»å‹è½¬æ¢ï¼ˆä¸NetDemandä¿æŒä¸€è‡´ï¼‰
        mlcfg = module4._cast_identifiers_to_str(mlcfg.copy(), ['material', 'location'])
        
        issues = []
        uncon_plan = module4.build_unconstrained_plan_for_single_day(
            net_demand_df, mlcfg, simulation_date, simulation_start, issues
        )
        
        # è®¾ç½®äº§èƒ½åˆ†é…å‚æ•°
        co_mat = m4_config['M4_ChangeoverMatrix'].set_index(['from_material', 'to_material'])['changeover_id']
        co_def_df = m4_config['M4_ChangeoverDefinition']
        co_def = co_def_df.set_index(['changeover_id', 'line'])['time'].to_dict()
        
        cap_df = m4_config['M4_LineCapacity'].copy()
        cap_df['date'] = pd.to_datetime(cap_df['date'])
        
        rate_map = mlcfg.set_index(['material', 'delegate_line'])['prd_rate']
        rate_map.index.set_names(['material', 'line'], inplace=True)
        
        # åˆ†é…äº§èƒ½
        plan_log, exceed_log = module4.centralized_capacity_allocation_with_changeover(
            uncon_plan, cap_df, rate_map, co_mat, co_def, mlcfg
        )
        
        # ä»¿çœŸç”Ÿäº§å¯é æ€§
        random_seed = m4_config.get('RandomSeed', 42)
        plan_log = module4.simulate_production(plan_log, m4_config['M4_ProductionReliability'], seed=random_seed)
        
        # è®¡ç®—æ¢äº§æŒ‡æ ‡
        changeover_log = module4.calculate_changeover_metrics(plan_log, co_def_df)
        
        # å»é‡é—®é¢˜
        issues = module4.dedup_issues(issues)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        base_output_file = os.path.join(output_dir, "Module4Output.xlsx")
        daily_output_path = module4.write_output(
            plan_log, exceed_log, issues, changeover_log, 
            base_output_file, simulation_date
        )
        
        print(f"Module4 daily output generated: {daily_output_path}")
        
        # è¿”å›ç”Ÿäº§è®¡åˆ’æ•°æ®ï¼ˆåªè¿”å›å½“æ—¥å¯ç”¨çš„ç”Ÿäº§ï¼‰
        if not plan_log.empty and 'available_date' in plan_log.columns:
            plan_log['available_date'] = pd.to_datetime(plan_log['available_date'])
            current_production = plan_log[plan_log['available_date'] >= simulation_date.normalize()]
            return current_production
        else:
            return pd.DataFrame()
        
    except Exception as e:
        import traceback
        print(f'[ERROR] Module4 integrated execution failed for {simulation_date.strftime("%Y-%m-%d")}: {str(e)}')
        print("Full traceback:")
        traceback.print_exc()
        return pd.DataFrame()

# ========== Module4 é›†æˆè¾…åŠ©å‡½æ•°ï¼ˆæ¸…ç†åï¼‰ ==========

# ä»¥ä¸‹å‡½æ•°ä¿ç•™ä½œä¸ºé»˜è®¤é…ç½®çš„å¤‡ç”¨ï¼Œä½†ä¸å†ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶













def load_all_historical_production_plans(module4_output_dir: str, current_date: pd.Timestamp, start_date: pd.Timestamp) -> pd.DataFrame:
    """
    åŠ è½½æ‰€æœ‰å†å²çš„M4ç”Ÿäº§è®¡åˆ’ï¼Œç­›é€‰å‡ºå½“æ—¥åº”è¯¥å…¥åº“çš„ç”Ÿäº§
    
    Args:
        module4_output_dir: Module4 è¾“å‡ºç›®å½•
        current_date: å½“å‰æ—¥æœŸ
        start_date: ä»¿çœŸå¼€å§‹æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å½“æ—¥åº”è¯¥å…¥åº“çš„ç”Ÿäº§è®¡åˆ’æ•°æ®
    """
    all_production_plans = []
    
    # éå†ä»ä»¿çœŸå¼€å§‹åˆ°å½“å‰æ—¥æœŸçš„æ‰€æœ‰M4è¾“å‡ºæ–‡ä»¶
    date_range = pd.date_range(start_date, current_date, freq='D')
    
    for date in date_range:
        m4_file = Path(module4_output_dir) / f"Module4Output_{date.strftime('%Y%m%d')}.xlsx"
        
        if m4_file.exists():
            try:
                xl = pd.ExcelFile(m4_file)
                if 'ProductionPlan' in xl.sheet_names:
                    production_df = xl.parse('ProductionPlan')
                    
                    if not production_df.empty:
                        # æ·»åŠ æ•°æ®æ¥æºæ ‡è¯†
                        production_df['source_file'] = str(m4_file)
                        production_df['source_date'] = date
                        all_production_plans.append(production_df)
                        
            except Exception as e:
                print(f"Warning: Failed to read {m4_file}: {e}")
                continue
    
    if not all_production_plans:
        return pd.DataFrame()
    
    # åˆå¹¶æ‰€æœ‰ç”Ÿäº§è®¡åˆ’
    combined_production = pd.concat(all_production_plans, ignore_index=True)
    
    # ç­›é€‰å‡ºå½“æ—¥åº”è¯¥å…¥åº“çš„ç”Ÿäº§ (available_date = current_date)
    if 'available_date' in combined_production.columns:
        combined_production['available_date'] = pd.to_datetime(combined_production['available_date'])
        daily_available = combined_production[
            combined_production['available_date'].dt.normalize() == current_date.normalize()
        ]
        
        if not daily_available.empty:
            print(f"  ğŸ“¦ å‘ç°å½“æ—¥å…¥åº“çš„å†å²ç”Ÿäº§: {len(daily_available)} æ¡è®°å½•")
            for _, row in daily_available.iterrows():
                print(f"    {row['material']}@{row['location']}: {row['produced_qty']} (ç”Ÿäº§æ—¥æœŸ: {row['source_date'].strftime('%Y-%m-%d')})")
        
        return daily_available[['material', 'location', 'line', 'simulation_date', 'available_date', 'produced_qty']]
    
    return pd.DataFrame()

def load_module4_production_output(output_path: str, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä» Module4 è¾“å‡ºæ–‡ä»¶ä¸­åŠ è½½ç”Ÿäº§è®¡åˆ’æ•°æ® (ä¿ç•™ç”¨äºå‘åå…¼å®¹)
    
    Args:
        output_path: Module4 è¾“å‡ºæ–‡ä»¶è·¯å¾„
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: ç”Ÿäº§è®¡åˆ’æ•°æ®
    """
    try:
        if not os.path.exists(output_path):
            print(f"Warning: Module4 output file not found: {output_path}")
            return pd.DataFrame()
            
        xl = pd.ExcelFile(output_path)
        if 'ProductionPlan' not in xl.sheet_names:
            print(f"Warning: ProductionPlan sheet not found in {output_path}")
            return pd.DataFrame()
            
        production_df = xl.parse('ProductionPlan')
        
        # ç­›é€‰å½“æ—¥çš„ç”Ÿäº§è®¡åˆ’ (available_date = current_date)
        if not production_df.empty and 'available_date' in production_df.columns:
            production_df['available_date'] = pd.to_datetime(production_df['available_date'])
            # åªè¿”å›å½“æ—¥æˆ–æœªæ¥çš„ç”Ÿäº§è®¡åˆ’
            production_df = production_df[production_df['available_date'] >= current_date.normalize()]
            
        return production_df
        
    except Exception as e:
        print(f"Error loading Module4 production output: {e}")
        return pd.DataFrame()

def load_global_seed(config_dict: dict) -> int:
    """
    ç»Ÿä¸€ä» Global_Seed sheet è¯»å–éšæœºç§å­
    
    Args:
        config_dict: é…ç½®æ•°æ®å­—å…¸
        
    Returns:
        int: éšæœºç§å­å€¼ï¼Œé»˜è®¤ä¸º 42
    """
    if 'Global_Seed' in config_dict and not config_dict['Global_Seed'].empty:
        seed_df = config_dict['Global_Seed']
        if 'seed' in seed_df.columns:
            seed_value = int(seed_df.iloc[0]['seed'])
            print(f"ğŸŒ± ä» Global_Seed è¯»å–éšæœºç§å­: {seed_value}")
            return seed_value
        elif len(seed_df.columns) > 0 and len(seed_df) > 0:
            # å…¼å®¹æ—§æ ¼å¼ï¼Œè¯»å–ç¬¬ä¸€åˆ—ç¬¬ä¸€è¡Œ
            seed_value = int(seed_df.iloc[0, 0])
            print(f"ğŸŒ± ä» Global_Seed å…¼å®¹æ ¼å¼è¯»å–éšæœºç§å­: {seed_value}")
            return seed_value
    
    print(f"âš ï¸  æœªæ‰¾åˆ° Global_Seed é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼: 42")
    return 42

def set_module_seeds(config_dict: dict, global_seed: int = None):
    """
    ä¸ºæ‰€æœ‰æ¨¡å—è®¾ç½®ç»Ÿä¸€çš„éšæœºç§å­
    
    Args:
        config_dict: é…ç½®æ•°æ®å­—å…¸
        global_seed: å…¨å±€ç§å­å€¼ï¼Œå¦‚æœä¸º None åˆ™ä»é…ç½®è¯»å–
    """
    if global_seed is None:
        global_seed = load_global_seed(config_dict)
    
    # è®¾ç½® numpyå…¨å±€ç§å­
    np.random.seed(global_seed)
    
    # ä¸ºå„æ¨¡å—è®¾ç½®ç§å­ï¼ˆåœ¨é…ç½®ä¸­è¦†ç›–æ¨¡å—ç‰¹å®šé…ç½®ï¼‰
    config_dict['M1_RandomSeed'] = global_seed
    config_dict['M3_RandomSeed'] = global_seed  
    config_dict['M4_RandomSeed'] = global_seed
    config_dict['M5_RandomSeed'] = global_seed
    config_dict['M6_RandomSeed'] = global_seed
    
    print(f"âœ¨ å·²ä¸ºæ‰€æœ‰æ¨¡å—è®¾ç½®ç»Ÿä¸€éšæœºç§å­: {global_seed}")
    return global_seed

def load_configuration(config_path: str) -> dict:
    """
    åŠ è½½é…ç½®æ•°æ®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: é…ç½®æ•°æ®å­—å…¸
    """
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    
    try:
        xl = pd.ExcelFile(config_path)
        config_dict = {}
        
        # åŠ è½½æ‰€æœ‰é…ç½®è¡¨
        for sheet_name in xl.sheet_names:
            config_dict[sheet_name] = xl.parse(sheet_name)
            print(f"  âœ… åŠ è½½é…ç½®è¡¨: {sheet_name} ({len(config_dict[sheet_name])} è¡Œ)")
        
        # ç¡®ä¿å¿…è¦çš„é…ç½®è¡¨å­˜åœ¨
        required_sheets = [
            'M1_InitialInventory',
            'Global_SpaceCapacity',
            'Global_Network',
            'Global_LeadTime',
            'Global_DemandPriority'
        ]
        
        missing_sheets = [sheet for sheet in required_sheets if sheet not in config_dict]
        if missing_sheets:
            print(f"âš ï¸  ç¼ºå°‘å¿…è¦é…ç½®è¡¨: {missing_sheets}")
            # åˆ›å»ºç©ºçš„é…ç½®è¡¨
            for sheet in missing_sheets:
                config_dict[sheet] = pd.DataFrame()
        
        # ç»Ÿä¸€æ ‡å‡†åŒ–æ‰€æœ‰é…ç½®è¡¨çš„æ ‡è¯†ç¬¦å­—æ®µ
        print(f"ğŸ”§ æ­£åœ¨æ ‡å‡†åŒ–æ ‡è¯†ç¬¦å­—æ®µ...")
        standardized_count = 0
        for sheet_name, df in config_dict.items():
            if isinstance(df, pd.DataFrame) and not df.empty:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡è¯†ç¬¦å­—æ®µ
                identifier_cols = ['material', 'location', 'sending', 'receiving', 'sourcing', 'dps_location']
                has_identifiers = any(col in df.columns for col in identifier_cols)
                
                if has_identifiers:
                    original_dtypes = {col: str(df[col].dtype) for col in identifier_cols if col in df.columns}
                    config_dict[sheet_name] = _normalize_identifiers(df)
                    new_dtypes = {col: str(config_dict[sheet_name][col].dtype) for col in identifier_cols if col in config_dict[sheet_name].columns}
                    
                    # è®°å½•æ ‡å‡†åŒ–çš„å­—æ®µ
                    normalized_fields = []
                    for col in identifier_cols:
                        if col in df.columns and original_dtypes[col] != new_dtypes[col]:
                            normalized_fields.append(f"{col}({original_dtypes[col]}â†’{new_dtypes[col]})")
                    
                    if normalized_fields:
                        print(f"  ğŸ”§ {sheet_name}: {', '.join(normalized_fields)}")
                        standardized_count += 1
        
        if standardized_count > 0:
            print(f"âœ… å·²æ ‡å‡†åŒ– {standardized_count} ä¸ªé…ç½®è¡¨çš„æ ‡è¯†ç¬¦å­—æ®µ")
        else:
            print(f"âœ… æ‰€æœ‰é…ç½®è¡¨çš„æ ‡è¯†ç¬¦å­—æ®µå·²æ˜¯æ ‡å‡†æ ¼å¼")
        
        return config_dict
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        raise

def run_integrated_simulation(
    config_path: str,
    start_date: str,
    end_date: str,
    output_base_dir: str = "./integrated_output"
):
    """
    è¿è¡Œå®Œæ•´çš„é›†æˆä»¿çœŸ
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        start_date: ä»¿çœŸå¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ä»¿çœŸç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
    """
    print(f"ğŸš€ å¼€å§‹é›†æˆä»¿çœŸ: {start_date} åˆ° {end_date}")
    print("=" * 60)
    
    # 1. é¢„éªŒè¯é…ç½®
    print(f"ğŸ” æ­£åœ¨è¿è¡Œä»¿çœŸå‰é…ç½®éªŒè¯...")
    validation_passed, validation_report = run_pre_simulation_validation(config_path, output_base_dir)
    
    print(f"ğŸ“ éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {validation_report}")
    
    if not validation_passed:
        print("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æŸ¥çœ‹éªŒè¯æŠ¥å‘Šå¹¶ä¿®å¤é”™è¯¯åå†è¿è¡Œä»¿çœŸã€‚")
        return {
            'validation_passed': False,
            'validation_report': validation_report,
            'simulation_completed': False
        }
    
    print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼Œå¼€å§‹ä»¿çœŸ...")
    
    # 2. åˆå§‹åŒ–æ—¶é—´ç®¡ç†å™¨
    time_manager = initialize_time_manager(start_date)
    
    # 3. åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(output_base_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    orchestrator_output_dir = output_dir / "orchestrator"
    module_outputs = {
        'module1': output_dir / "module1",
        'module3': output_dir / "module3", 
        'module4': output_dir / "module4",
        'module5': output_dir / "module5",
        'module6': output_dir / "module6"
    }
    
    for module_dir in module_outputs.values():
        module_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½é…ç½®
    config_dict = load_configuration(config_path)
    
    # è®¾ç½®å…¨å±€éšæœºç§å­
    global_seed = set_module_seeds(config_dict)
    
    # åˆå§‹åŒ–Orchestrator
    print(f"\nğŸ¯ åˆå§‹åŒ–Orchestrator")
    orchestrator = create_orchestrator(
        start_date=start_date,
        output_dir=str(orchestrator_output_dir)
    )
    
    # è®¾ç½®åˆå§‹åº“å­˜
    if 'M1_InitialInventory' in config_dict and not config_dict['M1_InitialInventory'].empty:
        orchestrator.initialize_inventory(config_dict['M1_InitialInventory'])
    else:
        print("âš ï¸  æœªæ‰¾åˆ°åˆå§‹åº“å­˜é…ç½®ï¼Œä½¿ç”¨ç©ºåº“å­˜")
        orchestrator.initialize_inventory(pd.DataFrame(columns=['material', 'location', 'quantity']))
    
    # è®¾ç½®ç©ºé—´å®¹é‡
    if 'Global_SpaceCapacity' in config_dict and not config_dict['Global_SpaceCapacity'].empty:
        orchestrator.set_space_capacity(config_dict['Global_SpaceCapacity'])
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ç©ºé—´å®¹é‡é…ç½®")
    
    # ç”Ÿæˆä»¿çœŸæ—¥æœŸèŒƒå›´
    sim_dates = pd.date_range(start_date, end_date, freq='D')
    print(f"ğŸ“… ä»¿çœŸæ—¥æœŸèŒƒå›´: {len(sim_dates)} å¤©")
    
    # æ¯æ—¥å¾ªç¯æ‰§è¡Œ
    all_results = {
        'module1': [],
        'module3': [],
        'module4': [], 
        'module5': [],
        'module6': []
    }
    
    for i, current_date in enumerate(sim_dates, 1):
        print(f"\n{'='*20} ç¬¬ {i}/{len(sim_dates)} å¤©: {current_date.strftime('%Y-%m-%d')} {'='*20}")
        
        # ==================== æ¯æ—¥å¼€å§‹ï¼šGRå…¥åº“å¤„ç† ====================
        try:
            print(f"\nğŸŒ… æ¯æ—¥å¼€å§‹çŠ¶æ€æ›´æ–°")
            # ğŸ”„ ç¬¬0æ­¥ï¼šä¿å­˜æœŸåˆåº“å­˜å¿«ç…§ï¼ˆåœ¨ä»»ä½•å˜åŠ¨ä¹‹å‰ï¼‰
            print(f"  ğŸ’¾ ä¿å­˜æœŸåˆåº“å­˜å¿«ç…§...")
            orchestrator.save_beginning_inventory(current_date.strftime('%Y-%m-%d'))

            # ğŸ”„ ç¬¬1æ­¥ï¼šå¤„ç†å½“æ—¥åˆ°è¾¾çš„delivery GR (in-transit â†’ inventory)
            print(f"  ğŸ“¦ å¤„ç†å½“æ—¥delivery GRåˆ°è¾¾...")
            orchestrator._process_delivery_arrivals(current_date.strftime('%Y-%m-%d'))
            
            # ğŸ”„ ç¬¬2æ­¥ï¼šå¤„ç†å†å²ç”Ÿäº§çš„å½“æ—¥å…¥åº“ (historical production â†’ inventory)
            print(f"  ğŸ­ å¤„ç†å†å²ç”Ÿäº§å½“æ—¥å…¥åº“...")
            historical_production = load_all_historical_production_plans(
                module4_output_dir=str(module_outputs['module4']),
                current_date=current_date,
                start_date=pd.to_datetime(start_date)
            )
            
            if not historical_production.empty:
                print(f"    ğŸ“¦ å½“æ—¥éœ€è¦å…¥åº“çš„å†å²ç”Ÿäº§: {len(historical_production)} æ¡è®°å½•")
                orchestrator.process_module4_production(historical_production, current_date.strftime('%Y-%m-%d'))
            else:
                print(f"    ğŸ“¦ å½“æ—¥æ— å†å²ç”Ÿäº§å…¥åº“")
                
        except Exception as e:
            print(f"  âŒ æ¯æ—¥å¼€å§‹å¤„ç†å¤±è´¥: {e}")
        
        # ==================== æ¨¡å—è¿è¡Œåºåˆ— ====================
        # åˆå§‹åŒ–æ¯æ—¥æ•°æ®å˜é‡
        m1_shipments = pd.DataFrame()
        m4_production = pd.DataFrame()
        m5_deployment_df = pd.DataFrame()
        m6_delivery_df = pd.DataFrame()
        
        try:
            # ========== M1: è®¢å•ç”Ÿæˆ + ç«‹å³åº“å­˜æ‰£å‡ ==========
            print(f"\n1ï¸âƒ£ è¿è¡Œ Module1 - è®¢å•ç”Ÿæˆ")
            try:
                m1_result = module1.run_daily_order_generation(
                    config_dict=config_dict,
                    simulation_date=current_date,
                    output_dir=str(module_outputs['module1']),
                    orchestrator=orchestrator
                )
                m1_shipments = m1_result.get('shipment_df', pd.DataFrame())
                
                # ğŸ”„ ç«‹å³å¤„ç†M1 shipmentï¼Œæ‰£å‡åº“å­˜
                if not m1_shipments.empty:
                    print(f"    ğŸšš ç«‹å³å¤„ç†M1 shipmentï¼Œæ‰£å‡åº“å­˜...")
                    orchestrator.process_module1_shipments(m1_shipments, current_date.strftime('%Y-%m-%d'))
                    print(f"    âœ… å·²æ‰£å‡ {len(m1_shipments)} ä¸ªshipmentçš„åº“å­˜")
                
                print(f"  âœ… Module1 å®Œæˆ - ç”Ÿæˆ {len(m1_result.get('orders_df', []))} ä¸ªè®¢å•, {len(m1_shipments)} ä¸ªå‘è´§")
                all_results['module1'].append(m1_result)
            except Exception as e:
                print(f"  âŒ Module1 å¤±è´¥: {e}")
                m1_shipments = pd.DataFrame()  # å¤±è´¥æ—¶ä½¿ç”¨ç©ºæ•°æ®
                # ä¸ç”¨continueï¼Œè®©åé¢çš„æ¨¡å—ç»§ç»­æ‰§è¡Œ
            
            # ========== M4: ç”Ÿäº§è®¡åˆ’ + ç«‹å³å½“æ—¥ç”Ÿäº§å…¥åº“ ==========
            print(f"\n2ï¸âƒ£ è¿è¡Œ Module4 - ç”Ÿäº§è®¡åˆ’")
            try:
                # ä½¿ç”¨é›†æˆæ¨¡å¼ç›´æ¥è°ƒç”¨ Module4 (æ”¹è¿›çš„è§£å†³æ–¹æ¡ˆ)
                m4_production = run_module4_integrated(
                    config_dict=config_dict,
                    module3_output_dir=str(module_outputs['module3']),
                    simulation_date=current_date,
                    simulation_start=pd.to_datetime(start_date),
                    output_dir=str(module_outputs['module4'])
                )
                
                # ğŸ”„ ç«‹å³å¤„ç†M4å½“æ—¥ç”Ÿäº§å…¥åº“
                if not m4_production.empty:
                    # ç­›é€‰å½“æ—¥å¯ç”¨çš„ç”Ÿäº§ (available_date = current_date)
                    daily_available = m4_production[
                        pd.to_datetime(m4_production['available_date']).dt.normalize() == current_date.normalize()
                    ]
                    
                    if not daily_available.empty:
                        print(f"    ğŸ­ ç«‹å³å¤„ç†M4å½“æ—¥ç”Ÿäº§å…¥åº“...")
                        orchestrator.process_module4_production(daily_available, current_date.strftime('%Y-%m-%d'))
                        print(f"    âœ… å·²å…¥åº“ {len(daily_available)} æ¡å½“æ—¥ç”Ÿäº§")
                    else:
                        print(f"    ğŸ“¦ M4å½“æ—¥æ— å¯ç”¨ç”Ÿäº§å…¥åº“")
                
                print(f"  âœ… Module4 å®Œæˆ - ç”Ÿæˆç”Ÿäº§è®¡åˆ’: {len(m4_production)} æ¡è®°å½•")
                all_results['module4'].append({'production_df': m4_production})
            except Exception as e:
                print(f"  âŒ Module4 å¤±è´¥: {e}")
                m4_production = pd.DataFrame()  # å¤±è´¥æ—¶ä½¿ç”¨ç©ºæ•°æ®
            
            # ========== M5: éƒ¨ç½²è®¡åˆ’ ==========
            print(f"\n3ï¸âƒ£ è¿è¡Œ Module5 - éƒ¨ç½²è®¡åˆ’")
            try:
                m5_result = module5.main(
                    # é›†æˆæ¨¡å¼å‚æ•°
                    config_dict=config_dict,
                    module1_output_dir=str(module_outputs['module1']),
                    module4_output_path=str(module_outputs['module4'] / f"Module4Output_{current_date.strftime('%Y%m%d')}.xlsx"),
                    orchestrator=orchestrator,
                    current_date=current_date.strftime('%Y-%m-%d'),
                    # è¾“å‡ºè·¯å¾„
                    output_path=str(module_outputs['module5'] / f"Module5Output_{current_date.strftime('%Y%m%d')}.xlsx")
                )
                
                # è·å–éƒ¨ç½²è®¡åˆ’æ•°æ®
                if m5_result and 'deployment_plan' in m5_result:
                    deployment_plan_df = m5_result['deployment_plan']
                    print(f"    ğŸ” Module5è¿”å›çš„éƒ¨ç½²è®¡åˆ’: {len(deployment_plan_df)} æ¡è®°å½•")
                    
                    if not deployment_plan_df.empty:
                        print(f"    ğŸ“Š éƒ¨ç½²è®¡åˆ’ç¤ºä¾‹æ•°æ®:")
                        print(f"    åˆ—å: {list(deployment_plan_df.columns)}")
                        if len(deployment_plan_df) > 0:
                            first_row = deployment_plan_df.iloc[0]
                            print(f"    ç¬¬ä¸€è¡Œæ•°æ®: {dict(first_row)}")
                            if 'deployed_qty_invCon' in deployment_plan_df.columns:
                                qty_stats = deployment_plan_df['deployed_qty_invCon'].describe()
                                print(f"    deployed_qty_invConç»Ÿè®¡: {qty_stats}")
                        
                        # è¿‡æ»¤å‡ºæœ‰å®é™…éƒ¨ç½²é‡çš„è®¡åˆ’ï¼Œæ’é™¤è‡ªå¾ªç¯ï¼ˆsending=receivingï¼‰
                        valid_deployment = deployment_plan_df[
                            (deployment_plan_df['deployed_qty_invCon'] > 0) & 
                            (deployment_plan_df['deployed_qty_invCon'].notna()) &
                            (deployment_plan_df['sending'] != deployment_plan_df['receiving'])  # æ’é™¤è‡ªå¾ªç¯
                        ].copy()
                        
                        print(f"    ğŸ¯ æœ‰æ•ˆéƒ¨ç½²è®¡åˆ’: {len(valid_deployment)}/{len(deployment_plan_df)} æ¡")
                        
                        if not valid_deployment.empty:
                            # æ£€æŸ¥æ˜¯å¦å·²æœ‰deployed_qtyåˆ—ï¼Œé¿å…é‡å¤
                            if 'deployed_qty' in valid_deployment.columns:
                                # å¦‚æœå·²æœ‰deployed_qtyåˆ—ï¼Œç›´æ¥ä½¿ç”¨
                                m5_deployment_df = valid_deployment[[
                                    'material', 'sending', 'receiving', 'date', 'deployed_qty', 'demand_element'
                                ]].rename(columns={'date': 'planned_deployment_date'})
                            else:
                                # é‡å‘½ååˆ—ä»¥åŒ¹é…orchestratoræœŸæœ›çš„æ ¼å¼
                                m5_deployment_df = valid_deployment.rename(columns={
                                    'date': 'planned_deployment_date',
                                    'deployed_qty_invCon': 'deployed_qty'
                                })[['material', 'sending', 'receiving', 'planned_deployment_date', 'deployed_qty', 'demand_element']]
                            
                            print(f"    âœ… æœ€ç»ˆä¼ é€’ç»™Orchestratorçš„æ•°æ®: {len(m5_deployment_df)} æ¡")
                            if len(m5_deployment_df) > 0:
                                final_qty_stats = m5_deployment_df['deployed_qty'].describe()
                                print(f"    deployed_qtyç»Ÿè®¡: {final_qty_stats}")
                            
                            # ğŸ”„ ç«‹å³å¤„ç†M5 deploymentï¼Œæ›´æ–°open deployment
                            print(f"    ğŸ“¦ ç«‹å³å¤„ç†M5 deploymentï¼Œæ›´æ–°open deployment...")
                            orchestrator.process_module5_deployment(m5_deployment_df, current_date.strftime('%Y-%m-%d'))
                            print(f"    âœ… å·²æ›´æ–° {len(m5_deployment_df)} æ¡éƒ¨ç½²è®¡åˆ’åˆ°open deployment")
                            
                            print(f"  âœ… Module5 å®Œæˆ - ç”Ÿæˆ {len(m5_deployment_df)} æ¡æœ‰æ•ˆéƒ¨ç½²è®¡åˆ’")
                        else:
                            print(f"  âœ… Module5 å®Œæˆ - æ— æœ‰æ•ˆéƒ¨ç½²è®¡åˆ’")
                    else:
                        print(f"  âœ… Module5 å®Œæˆ - éƒ¨ç½²è®¡åˆ’ä¸ºç©º")
                else:
                    print(f"  âœ… Module5 å®Œæˆ - æ— è¿”å›ç»“æœ")
                
                all_results['module5'].append(m5_result)
            except Exception as e:
                print(f"  âŒ Module5 å¤±è´¥: {e}")
                # ä¸ç”¨continueï¼Œè®©åé¢çš„æ¨¡å—ç»§ç»­æ‰§è¡Œ
                m5_deployment_df = pd.DataFrame()  # è®¾ç½®é»˜è®¤å€¼
            
            # ========== M6: ç‰©æµæ‰§è¡Œ + ç«‹å³å¤šçŠ¶æ€æ›´æ–° ==========
            print(f"\n4ï¸âƒ£ è¿è¡Œ Module6 - ç‰©æµæ‰§è¡Œ")
            try:
                m6_result = module6.run_daily_physical_flow(
                    config_dict=config_dict,
                    orchestrator=orchestrator,
                    current_date=current_date,
                    output_dir=str(module_outputs['module6']),
                    max_wait_days=7,
                    random_seed=config_dict.get('M6_RandomSeed', 42)  # ä½¿ç”¨ç»Ÿä¸€ç§å­
                )
                
                # è·å–äº¤ä»˜è®¡åˆ’æ•°æ®
                if m6_result and 'delivery_plan' in m6_result:
                    m6_delivery_df = m6_result.get('delivery_plan', pd.DataFrame())
                    
                    # ğŸ”„ ç«‹å³å¤„ç†M6 deliveryï¼Œæ›´æ–°å¤šä¸ªçŠ¶æ€
                    if not m6_delivery_df.empty:
                        print(f"    ğŸš› ç«‹å³å¤„ç†M6 deliveryï¼Œæ›´æ–°åº“å­˜/open deployment/in-transit...")
                        orchestrator.process_module6_delivery(m6_delivery_df, current_date.strftime('%Y-%m-%d'))
                        print(f"    âœ… å·²å¤„ç† {len(m6_delivery_df)} æ¡deliveryè®¡åˆ’ï¼Œæ›´æ–°ç›¸å…³çŠ¶æ€")
                    
                    print(f"  âœ… Module6 å®Œæˆ - ç”Ÿæˆ {len(m6_delivery_df)} æ¡äº¤ä»˜è®¡åˆ’")
                else:
                    print(f"  âœ… Module6 å®Œæˆ - æ— äº¤ä»˜è®¡åˆ’")
                    m6_delivery_df = pd.DataFrame()
                
                all_results['module6'].append(m6_result)
            except Exception as e:
                print(f"  âŒ Module6 å¤±è´¥: {e}")
                # ä¸ç”¨continueï¼Œè®©åé¢çš„æ¨¡å—ç»§ç»­æ‰§è¡Œ
                m6_delivery_df = pd.DataFrame()  # è®¾ç½®é»˜è®¤å€¼
            
            # ========== M3: å‡€éœ€æ±‚è®¡ç®— ==========
            print(f"\n5ï¸âƒ£ è¿è¡Œ Module3 - å‡€éœ€æ±‚è®¡ç®—")
            try:
                m3_result = module3.run_integrated_mode(
                    module1_output_dir=str(module_outputs['module1']),
                    orchestrator=orchestrator,
                    config_dict=config_dict,
                    start_date=current_date.strftime('%Y-%m-%d'),
                    end_date=current_date.strftime('%Y-%m-%d'),
                    output_dir=str(module_outputs['module3'])
                )
                print(f"  âœ… Module3 å®Œæˆ")
                all_results['module3'].append(m3_result)
            except Exception as e:
                print(f"  âŒ Module3 å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                # ä¸ç”¨continueï¼Œè®©ä»–ç»§ç»­æ‰§è¡Œ
            
            # ==================== æ¯æ—¥ç»“æŸï¼šä¿å­˜çŠ¶æ€ ====================
            print(f"\nğŸ’¾ æ¯æ—¥ç»“æŸçŠ¶æ€ä¿å­˜")
            try:
                # ä¿å­˜æœŸæœ«åº“å­˜å¿«ç…§ï¼ˆåœ¨ä¿å­˜çŠ¶æ€ä¹‹å‰ï¼‰
                orchestrator.save_ending_inventory(current_date.strftime('%Y-%m-%d'))
                
                # è¾“å‡ºè¯¦ç»†çš„åº“å­˜å˜åŠ¨è®°å½•ç”¨äºè°ƒè¯•
                orchestrator.output_daily_inventory_summary(current_date.strftime('%Y-%m-%d'))
                
                # ç›´æ¥ä¿å­˜æ¯æ—¥çŠ¶æ€ï¼ŒçŠ¶æ€æ›´æ–°å·²åœ¨å„æ¨¡å—è¿è¡Œåå®æ—¶å®Œæˆ
                orchestrator.save_daily_state(current_date.strftime('%Y-%m-%d'))
                
                # è·å–å½“æ—¥ç»Ÿè®¡
                stats = orchestrator.get_summary_statistics(current_date.strftime('%Y-%m-%d'))
                print(f"  ğŸ“Š å½“æ—¥ç»Ÿè®¡: {stats}")
                print(f"  ğŸ’¾ Orchestrator çŠ¶æ€å·²ä¿å­˜")
                
            except Exception as e:
                print(f"  âŒ æ¯æ—¥çŠ¶æ€ä¿å­˜å¤±è´¥: {e}")
                # ä¸ç”¨continueï¼Œè®©ä»–ç»§ç»­åˆ°ä¸‹ä¸€å¤©
            
            print(f"âœ… ç¬¬ {i} å¤©å¤„ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ ç¬¬ {i} å¤©å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print(f"\nğŸ“Š ä»¿çœŸå®ŒæˆæŠ¥å‘Š")
    print("=" * 60)
    print(f"ä»¿çœŸæœŸé—´: {start_date} åˆ° {end_date} ({len(sim_dates)} å¤©)")
    print(f"è¾“å‡ºç›®å½•: {output_base_dir}")
    
    for module_name, results in all_results.items():
        print(f"{module_name.upper()}: {len(results)} å¤©æˆåŠŸå¤„ç†")
    
    # è¿›è¡Œåº“å­˜å¹³è¡¡æ£€æŸ¥
    print(f"\nğŸ” æ­£åœ¨è¿›è¡Œåº“å­˜å¹³è¡¡æ£€æŸ¥...")
    validation_manager = ValidationManager(str(output_dir))
    inventory_checker = InventoryBalanceChecker(validation_manager, orchestrator)
    balance_passed = inventory_checker.validate_inventory_consistency(start_date, end_date)
    
    if balance_passed:
        print("âœ… åº“å­˜å¹³è¡¡æ£€æŸ¥é€šè¿‡")
    else:
        print("âš ï¸  åº“å­˜å¹³è¡¡æ£€æŸ¥å‘ç°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹éªŒè¯æŠ¥å‘Š")
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
    summary_generator = SummaryReportGenerator(str(output_dir))
    summary_reports = summary_generator.generate_all_reports(start_date, end_date)
    
    # å†™å…¥åº“å­˜å¹³è¡¡æ£€æŸ¥æŠ¥å‘Š
    balance_report_path = validation_manager.write_report()
    
    # è·å–æœ€ç»ˆOrchestratorç»Ÿè®¡
    final_date = sim_dates[-1].strftime('%Y-%m-%d')
    final_stats = orchestrator.get_summary_statistics(final_date)
    print(f"\nğŸ¯ æœ€ç»ˆOrchestratorçŠ¶æ€:")
    for key, value in final_stats.items():
        print(f"  {key}: {value}")
    
    print(f"\nğŸ‰ é›†æˆä»¿çœŸå®Œæˆ!")
    
    return {
        'validation_passed': True,
        'simulation_completed': True,
        'dates_processed': len(sim_dates),
        'results': all_results,
        'final_stats': final_stats,
        'output_directory': output_base_dir,
        'validation_report': validation_report,
        'balance_check_passed': balance_passed,
        'balance_report': balance_report_path,
        'summary_reports': summary_reports
    }

def main():
    """ä¸»å‡½æ•° - ç‹¬ç«‹æ‰§è¡Œé›†æˆä»¿çœŸ"""
    # é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æˆ–ç¯å¢ƒå˜é‡æŒ‡å®šï¼‰
    import argparse
    
    parser = argparse.ArgumentParser(description="è¿è¡Œä¾›åº”é“¾é›†æˆä»¿çœŸ")
    parser.add_argument("--config", "-c", 
                       default="./config/integration_config.json",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./config/integration_config.json)")
    parser.add_argument("--start-date", "-s", 
                       default="2024-01-01",
                       help="ä»¿çœŸå¼€å§‹æ—¥æœŸ (é»˜è®¤: 2024-01-01)")
    parser.add_argument("--end-date", "-e", 
                       default="2024-01-05",
                       help="ä»¿çœŸç»“æŸæ—¥æœŸ (é»˜è®¤: 2024-01-03)")
    parser.add_argument("--output", "-o", 
                       default=None,
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: æ ¹æ®é…ç½®æ–‡ä»¶åç”Ÿæˆ)")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.config):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        print("è¯·æä¾›æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä½¿ç”¨æµ‹è¯•è„šæœ¬ç”Ÿæˆé…ç½®")
        sys.exit(1)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œæ ¹æ®é…ç½®æ–‡ä»¶åç”Ÿæˆ
    if args.output is None:
        config_name = os.path.splitext(os.path.basename(args.config))[0]
        args.output = f"./{config_name}_output"
        print(f"ğŸ’« ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•: {args.output}")
    
    try:
        result = run_integrated_simulation(
            config_path=args.config,
            start_date=args.start_date,
            end_date=args.end_date,
            output_base_dir=args.output
        )
        
        print(f"\nâœ… ä»¿çœŸç»“æœ:")
        print(f"  å¤„ç†å¤©æ•°: {result.get('dates_processed', 0)}")
        print(f"  è¾“å‡ºç›®å½•: {result.get('output_directory', 'Unknown')}")
        
    except Exception as e:
        print(f"âŒ é›†æˆä»¿çœŸå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()