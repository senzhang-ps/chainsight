# summary_report_generator.py
# æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå™¨ - å…¨å‘¨æœŸæ¨¡æ‹Ÿç»“æŸåè¾“å‡º7ç±»fullæŠ¥å‘Š

import pandas as pd
import numpy as np
import os
from typing import Dict, List, Optional
from pathlib import Path
import glob

class SummaryReportGenerator:
    """æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_base_dir: str, config_dict: dict = None):
        """
        åˆå§‹åŒ–æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            config_dict: é…ç½®æ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼Œç”¨äºè·å–safety stockç­‰é…ç½®ä¿¡æ¯ï¼‰
        """
        self.output_base_dir = Path(output_base_dir)
        self.summary_dir = self.output_base_dir / "summary"
        self.summary_dir.mkdir(parents=True, exist_ok=True)
        self.config_dict = config_dict or {}
        
        # å„æ¨¡å—è¾“å‡ºç›®å½•
        self.module_dirs = {
            'module1': self.output_base_dir / "module1",
            'module3': self.output_base_dir / "module3",
            'module4': self.output_base_dir / "module4",
            'module5': self.output_base_dir / "module5",
            'module6': self.output_base_dir / "module6",
            'orchestrator': self.output_base_dir / "orchestrator"
        }
    
    @staticmethod
    def _normalize_material_value(material_str: str) -> str:
        """æ ‡å‡†åŒ– material å€¼ï¼šç§»é™¤.0åç¼€"""
        if not material_str or material_str in ['nan', 'None', '']:
            return ""
        try:
            # å¦‚æœæ˜¯æ•°å­—ï¼Œç§»é™¤.0åç¼€
            if '.' in material_str and material_str.replace('.', '').replace('-', '').isdigit():
                return str(int(float(material_str)))
            return material_str.strip()
        except:
            return material_str.strip()
    
    @staticmethod
    def _normalize_location_value(location_str: str) -> str:
        """æ ‡å‡†åŒ– location å€¼ï¼šçº¯æ•°å­—è¡¥é½ä¸º4ä½ï¼Œå­—æ¯æ•°å­—ä¿æŒåŸæ ·"""
        if not location_str or location_str in ['nan', 'None', '']:
            return ""
        location_str = str(location_str).strip()
        try:
            # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œè¡¥é½ä¸º4ä½
            if location_str.isdigit():
                return str(int(location_str)).zfill(4)
            # å­—æ¯æ•°å­—æ··åˆï¼Œä¿æŒåŸæ ·
            return location_str
        except:
            return location_str
    
    def generate_all_reports(self, start_date: str, end_date: str) -> Dict[str, str]:
        """
        ç”Ÿæˆæ‰€æœ‰æ±‡æ€»æŠ¥å‘Š
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            Dict[str, str]: æŠ¥å‘Šåç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
        """
        print(f"ğŸ“Š å¼€å§‹ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š ({start_date} åˆ° {end_date})")
        
        # ä¿å­˜æ—¥æœŸèŒƒå›´ï¼Œç”¨äºåç»­è¿‡æ»¤
        self.start_date = pd.to_datetime(start_date)
        self.end_date = pd.to_datetime(end_date)
        
        report_files = {}
        
        # æ”¶é›†æ‰€æœ‰å¤©çš„æ•°æ®æ–‡ä»¶
        daily_files = self._collect_daily_files(start_date, end_date)
        
        # ç”Ÿæˆå„ä¸ªæ±‡æ€»æŠ¥å‘Š
        report_files['order_shipment_cut'] = self._generate_order_shipment_report(daily_files)
        report_files['exceed_capacity'] = self._generate_capacity_exceed_report(daily_files)
        report_files['changeover'] = self._generate_changeover_report(daily_files)
        report_files['deployment_plan'] = self._generate_deployment_report(daily_files)
        report_files['production_plan'] = self._generate_production_report(daily_files)
        report_files['delivery_plan'] = self._generate_delivery_report(daily_files)
        report_files['truck_usage'] = self._generate_truck_usage_report(daily_files)
        report_files['historical_inventory'] = self._generate_historical_inventory_report(start_date, end_date)
        
        print(f"âœ… æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè¾“å‡ºç›®å½•: {self.summary_dir}")
        return report_files
    
    def _collect_daily_files(self, start_date: str, end_date: str) -> Dict[str, List[str]]:
        """æ”¶é›†æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ¨¡å—è¾“å‡ºæ–‡ä»¶"""
        date_range = pd.date_range(start_date, end_date, freq='D')
        daily_files = {module: [] for module in self.module_dirs.keys()}
        
        for date in date_range:
            date_str = date.strftime('%Y%m%d')
            
            # Module1 è¾“å‡ºæ–‡ä»¶
            m1_file = self.module_dirs['module1'] / f"module1_output_{date_str}.xlsx"
            if m1_file.exists():
                daily_files['module1'].append(str(m1_file))
            
            # Module3 è¾“å‡ºæ–‡ä»¶
            m3_file = self.module_dirs['module3'] / f"Module3Output_{date_str}.xlsx"
            if m3_file.exists():
                daily_files['module3'].append(str(m3_file))
            
            # Module4 è¾“å‡ºæ–‡ä»¶
            m4_file = self.module_dirs['module4'] / f"Module4Output_{date_str}.xlsx"
            if m4_file.exists():
                daily_files['module4'].append(str(m4_file))
            
            # Module5 è¾“å‡ºæ–‡ä»¶
            m5_file = self.module_dirs['module5'] / f"Module5Output_{date_str}.xlsx"
            if m5_file.exists():
                daily_files['module5'].append(str(m5_file))
            
            # Module6 è¾“å‡ºæ–‡ä»¶
            m6_file = self.module_dirs['module6'] / f"Module6Output_{date_str}.xlsx"
            if m6_file.exists():
                daily_files['module6'].append(str(m6_file))
        
        return daily_files
    
    def _generate_order_shipment_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆè®¢å•å‘è´§åˆ‡å‰²æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_order_shipment_cut_report.xlsx"
        
        all_orders = []
        all_shipments = []
        all_cuts = []
        
        # æ”¶é›†æ‰€æœ‰å¤©çš„æ•°æ®ï¼Œå¹¶æ·»åŠ simulation_date
        for file_path in daily_files['module1']:
            try:
                # ä»æ–‡ä»¶åæå–simulation_date
                simulation_date = self._extract_date_from_filename(file_path)
                
                xl = pd.ExcelFile(file_path)
                
                if 'OrderLog' in xl.sheet_names:
                    orders_df = xl.parse('OrderLog')
                    if not orders_df.empty and simulation_date:
                        orders_df['simulation_date'] = simulation_date
                    all_orders.append(orders_df)
                
                if 'ShipmentLog' in xl.sheet_names:
                    shipments_df = xl.parse('ShipmentLog')
                    if not shipments_df.empty and simulation_date:
                        shipments_df['simulation_date'] = simulation_date
                    all_shipments.append(shipments_df)
                
                if 'CutLog' in xl.sheet_names:
                    cuts_df = xl.parse('CutLog')
                    if not cuts_df.empty and simulation_date:
                        cuts_df['simulation_date'] = simulation_date
                    all_cuts.append(cuts_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        # åˆå¹¶å¹¶æ±‡æ€»æ•°æ®
        summary_data = []
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        combined_orders = pd.concat(all_orders, ignore_index=True) if all_orders else pd.DataFrame()
        combined_shipments = pd.concat(all_shipments, ignore_index=True) if all_shipments else pd.DataFrame()
        combined_cuts = pd.concat(all_cuts, ignore_index=True) if all_cuts else pd.DataFrame()
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šå»é™¤é‡å¤çš„ AO è®¢å•
        # AO è®¢å•å¯èƒ½åœ¨å¤šä¸ª simulation_date è¢«é‡å¤è®°å½•ï¼Œéœ€è¦æŒ‰å”¯ä¸€é”®å»é‡
        if not combined_orders.empty:
            original_count = len(combined_orders)
            # æŒ‰ date, material, location, demand_type, quantity å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¡ï¼‰
            dedup_cols = ['date', 'material', 'location', 'quantity']
            if 'demand_type' in combined_orders.columns:
                dedup_cols.append('demand_type')
            combined_orders = combined_orders.drop_duplicates(subset=dedup_cols, keep='first')
            dedup_count = len(combined_orders)
            if original_count != dedup_count:
                print(f"ğŸ“Š OrderLog å»é‡ï¼šåŸå§‹ {original_count} æ¡ â†’ å»é‡å {dedup_count} æ¡ï¼ˆç§»é™¤äº† {original_count - dedup_count} æ¡é‡å¤çš„ AO è®¢å•ï¼‰")
        
        # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤º CutLog æ•°æ®
        # print(f"\nğŸ” Order Shipment Cut Report æ•°æ®ç»Ÿè®¡:")
        # print(f"  OrderLog è®°å½•æ•°: {len(combined_orders)}")
        # print(f"  ShipmentLog è®°å½•æ•°: {len(combined_shipments)}")
        # print(f"  CutLog è®°å½•æ•°: {len(combined_cuts)}")
        # if not combined_cuts.empty:
        #     print(f"  CutLog å‰5æ¡è®°å½•:")
        #     print(combined_cuts.head())
        
        # æ„å»ºæ±‡æ€»è¡¨
        if not combined_orders.empty or not combined_shipments.empty or not combined_cuts.empty:
            # å‡†å¤‡è®¢å•æ•°æ®ï¼ˆå»æ‰ demand_typeï¼Œåˆå¹¶æ‰€æœ‰ç±»å‹çš„è®¢å•ï¼‰
            if not combined_orders.empty:
                order_agg = combined_orders.groupby(
                    ['date', 'material', 'location', 'simulation_date'], 
                    dropna=False
                ).agg({'quantity': 'sum'}).reset_index()
                order_agg.rename(columns={'quantity': 'order_qty'}, inplace=True)
            else:
                order_agg = pd.DataFrame(columns=['date', 'material', 'location', 'simulation_date', 'order_qty'])
            
            # å‡†å¤‡å‘è´§æ•°æ®ï¼ˆå»æ‰ demand_typeï¼Œåˆå¹¶æ‰€æœ‰ç±»å‹çš„å‘è´§ï¼‰
            if not combined_shipments.empty:
                shipment_agg = combined_shipments.groupby(
                    ['date', 'material', 'location', 'simulation_date'], 
                    dropna=False
                ).agg({'quantity': 'sum'}).reset_index()
                shipment_agg.rename(columns={'quantity': 'shipment_qty'}, inplace=True)
            else:
                shipment_agg = pd.DataFrame(columns=['date', 'material', 'location', 'simulation_date', 'shipment_qty'])
            
            # å‡†å¤‡ç¼ºè´§æ•°æ®ï¼ˆå»æ‰ demand_typeï¼Œåˆå¹¶æ‰€æœ‰ç±»å‹çš„ç¼ºè´§ï¼‰
            if not combined_cuts.empty:
                cut_agg = combined_cuts.groupby(
                    ['date', 'material', 'location', 'simulation_date'], 
                    dropna=False
                ).agg({'quantity': 'sum'}).reset_index()
                cut_agg.rename(columns={'quantity': 'cut_qty'}, inplace=True)
            else:
                cut_agg = pd.DataFrame(columns=['date', 'material', 'location', 'simulation_date', 'cut_qty'])
            
            # åˆå¹¶ä¸‰ä¸ªæ±‡æ€»è¡¨
            summary = order_agg.merge(
                shipment_agg, 
                on=['date', 'material', 'location', 'simulation_date'], 
                how='outer'
            )
            summary = summary.merge(
                cut_agg, 
                on=['date', 'material', 'location', 'simulation_date'], 
                how='outer'
            )
            
            # å¡«å……ç¼ºå¤±å€¼ä¸º0
            summary['order_qty'] = summary['order_qty'].fillna(0).infer_objects(copy=False).astype(int)
            summary['shipment_qty'] = summary['shipment_qty'].fillna(0).infer_objects(copy=False).astype(int)
            summary['cut_qty'] = summary['cut_qty'].fillna(0).infer_objects(copy=False).astype(int)
            
            # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
            if 'date' in summary.columns:
                original_count = len(summary)
                summary['date'] = pd.to_datetime(summary['date'])
                summary = summary[summary['date'] <= self.end_date]
                filtered_count = len(summary)
                if original_count != filtered_count:
                    print(f"ğŸ“Š è¿‡æ»¤è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡º {self.end_date.date()} çš„è®°å½•ï¼‰")
            
            # ğŸ”§ éªŒè¯ï¼šè®¡ç®— cut_qty æ˜¯å¦ç­‰äº order - shipment
            summary['calculated_cut'] = (summary['order_qty'] - summary['shipment_qty']).clip(lower=0)
            
            # æ£€æŸ¥ä¸ä¸€è‡´çš„è®°å½•
            inconsistent = summary[summary['cut_qty'] != summary['calculated_cut']]
            if not inconsistent.empty:
                print(f"\nâš ï¸  å‘ç° {len(inconsistent)} æ¡ cut_qty ä¸ä¸€è‡´çš„è®°å½•:")
                print(f"  (cut_qty åº”è¯¥ = max(0, order_qty - shipment_qty))")
                print(inconsistent[['date', 'material', 'location', 'order_qty', 'shipment_qty', 'cut_qty', 'calculated_cut']].head(10))
            
            # ç§»é™¤ä¸´æ—¶åˆ—
            summary = summary.drop(columns=['calculated_cut'])
            
            # æŒ‰æ—¥æœŸå’Œç‰©æ–™æ’åº
            summary = summary.sort_values(['simulation_date', 'date', 'material', 'location'])
            
            # è°ƒæ•´åˆ—é¡ºåºï¼ˆå»æ‰ demand_typeï¼‰
            column_order = ['simulation_date', 'date', 'material', 'location', 'order_qty', 'shipment_qty', 'cut_qty']
            summary = summary[column_order]
            
            # è¾“å‡ºåˆ°Excel
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                summary.to_excel(writer, sheet_name='OrderShipmentCutSummary', index=False)
        
        return str(output_file)
    
    def _generate_delivery_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆäº¤ä»˜è®¡åˆ’æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_delivery_plan_report.xlsx"
        
        all_deliveries = []
        
        for file_path in daily_files['module6']:
            try:
                xl = pd.ExcelFile(file_path)
                if 'DeliveryPlan' in xl.sheet_names:
                    delivery_df = xl.parse('DeliveryPlan')
                    # æ·»åŠ date, planned_deploy_date, actual_ship_dateå­—æ®µ
                    file_date = self._extract_date_from_filename(file_path)
                    delivery_df['date'] = file_date
                    all_deliveries.append(delivery_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        if all_deliveries:
            combined_deliveries = pd.concat(all_deliveries, ignore_index=True)
            
            # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
            original_count = len(combined_deliveries)
            date_cols_to_filter = ['planned_deploy_date', 'actual_ship_date', 'date']
            for col in date_cols_to_filter:
                if col in combined_deliveries.columns:
                    combined_deliveries[col] = pd.to_datetime(combined_deliveries[col], errors='coerce')
            
            # åªä¿ç•™ planned_deploy_date æˆ– actual_ship_date åœ¨èŒƒå›´å†…çš„è®°å½•
            if 'planned_deploy_date' in combined_deliveries.columns or 'actual_ship_date' in combined_deliveries.columns:
                mask = pd.Series([True] * len(combined_deliveries))
                if 'planned_deploy_date' in combined_deliveries.columns:
                    mask = mask & ((combined_deliveries['planned_deploy_date'].isna()) | (combined_deliveries['planned_deploy_date'] <= self.end_date))
                if 'actual_ship_date' in combined_deliveries.columns:
                    mask = mask & ((combined_deliveries['actual_ship_date'].isna()) | (combined_deliveries['actual_ship_date'] <= self.end_date))
                combined_deliveries = combined_deliveries[mask]
                
                filtered_count = len(combined_deliveries)
                if original_count != filtered_count:
                    print(f"ğŸ“Š Delivery Plan è¿‡æ»¤ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼‰")
            
            # æŒ‰éœ€æ±‚æ·»åŠ å­—æ®µ: date, material, sending, receiving, planned_qty, delivered_qty, planned_deploy_date, actual_ship_date
            required_columns = ['date', 'material', 'sending', 'receiving', 'planned_qty', 'delivered_qty', 'planned_deploy_date', 'actual_ship_date']
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                combined_deliveries.to_excel(writer, sheet_name='FullDeliveryPlan', index=False)
        
        return str(output_file)
    
    def _generate_truck_usage_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆå¡è½¦ä½¿ç”¨æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_truck_usage_report.xlsx"
        
        all_usage = []
        
        for file_path in daily_files['module6']:
            try:
                xl = pd.ExcelFile(file_path)
                if 'TruckUsageLog' in xl.sheet_names:
                    usage_df = xl.parse('TruckUsageLog')
                    all_usage.append(usage_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        if all_usage:
            combined_usage = pd.concat(all_usage, ignore_index=True)
            
            # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
            if 'date' in combined_usage.columns:
                original_count = len(combined_usage)
                combined_usage['date'] = pd.to_datetime(combined_usage['date'], errors='coerce')
                combined_usage = combined_usage[
                    (combined_usage['date'].isna()) | 
                    (combined_usage['date'] <= self.end_date)
                ]
                filtered_count = len(combined_usage)
                if original_count != filtered_count:
                    print(f"ğŸ“Š Truck Usage è¿‡æ»¤ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼‰")
            
            # æŒ‰éœ€æ±‚å­—æ®µ: date, sending, receiving, truck_type, available_trucks, used_trucks, wfr, vfr
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                combined_usage.to_excel(writer, sheet_name='FullTruckUsage', index=False)
        
        return str(output_file)
    
    def _generate_capacity_exceed_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆäº§èƒ½è¶…é™æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_exceed_capacity_report.xlsx"
        
        all_exceeds = []
        
        for file_path in daily_files['module4']:
            try:
                xl = pd.ExcelFile(file_path)
                if 'CapacityExceed' in xl.sheet_names:
                    exceed_df = xl.parse('CapacityExceed')
                    all_exceeds.append(exceed_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        if all_exceeds:
            combined_exceeds = pd.concat(all_exceeds, ignore_index=True)
            
            # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
            if 'date' in combined_exceeds.columns:
                original_count = len(combined_exceeds)
                combined_exceeds['date'] = pd.to_datetime(combined_exceeds['date'], errors='coerce')
                combined_exceeds = combined_exceeds[
                    (combined_exceeds['date'].isna()) | 
                    (combined_exceeds['date'] <= self.end_date)
                ]
                filtered_count = len(combined_exceeds)
                if original_count != filtered_count:
                    print(f"ğŸ“Š Capacity Exceed è¿‡æ»¤ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼‰")
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                combined_exceeds.to_excel(writer, sheet_name='FullCapacityExceed', index=False)
        
        return str(output_file)
    
    def _generate_changeover_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆæ¢çº¿æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_changeover_report.xlsx"
        
        all_changeovers = []
        
        for file_path in daily_files['module4']:
            try:
                xl = pd.ExcelFile(file_path)
                if 'ChangeoverLog' in xl.sheet_names:
                    changeover_df = xl.parse('ChangeoverLog')
                    all_changeovers.append(changeover_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        if all_changeovers:
            # è¿‡æ»¤æ‰ç©ºçš„ DataFrame ä»¥é¿å… FutureWarning
            non_empty_changeovers = [df for df in all_changeovers if not df.empty]
            if non_empty_changeovers:
                combined_changeovers = pd.concat(non_empty_changeovers, ignore_index=True)
                
                # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
                original_count = len(combined_changeovers)
                date_cols_to_filter = ['changeover_start_date', 'changeover_end_date', 'date']
                for col in date_cols_to_filter:
                    if col in combined_changeovers.columns:
                        combined_changeovers[col] = pd.to_datetime(combined_changeovers[col], errors='coerce')
                
                # åªä¿ç•™ changeover_end_date åœ¨èŒƒå›´å†…çš„è®°å½•
                if 'changeover_end_date' in combined_changeovers.columns:
                    combined_changeovers = combined_changeovers[
                        (combined_changeovers['changeover_end_date'].isna()) | 
                        (combined_changeovers['changeover_end_date'] <= self.end_date)
                    ]
                    filtered_count = len(combined_changeovers)
                    if original_count != filtered_count:
                        print(f"ğŸ“Š Changeover Log è¿‡æ»¤ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼‰")
                
                with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                    combined_changeovers.to_excel(writer, sheet_name='FullChangeoverLog', index=False)
        
        return str(output_file)
    
    def _generate_deployment_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆéƒ¨ç½²è®¡åˆ’æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_deployment_plan_report.xlsx"
        
        all_deployments = []
        
        for file_path in daily_files['module5']:
            try:
                xl = pd.ExcelFile(file_path)
                if 'DeploymentPlan' in xl.sheet_names:
                    deployment_df = xl.parse('DeploymentPlan')
                    all_deployments.append(deployment_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        if all_deployments:
            combined_deployments = pd.concat(all_deployments, ignore_index=True)
            
            # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
            original_count = len(combined_deployments)
            # Deployment å¯èƒ½çš„æ—¥æœŸå­—æ®µï¼šdeployment_date, arrival_date, ship_date ç­‰
            date_cols_to_filter = ['deployment_date', 'arrival_date', 'ship_date', 'date']
            for col in date_cols_to_filter:
                if col in combined_deployments.columns:
                    combined_deployments[col] = pd.to_datetime(combined_deployments[col], errors='coerce')
            
            # è¿‡æ»¤ï¼šå¦‚æœæœ‰ä»»ä½•æ—¥æœŸåˆ—ï¼Œåªä¿ç•™æ—¥æœŸåœ¨èŒƒå›´å†…çš„è®°å½•
            mask = pd.Series([True] * len(combined_deployments))
            for col in ['deployment_date', 'arrival_date', 'ship_date', 'date']:
                if col in combined_deployments.columns:
                    mask = mask & ((combined_deployments[col].isna()) | (combined_deployments[col] <= self.end_date))
            
            combined_deployments = combined_deployments[mask]
            filtered_count = len(combined_deployments)
            if original_count != filtered_count:
                print(f"ğŸ“Š Deployment Plan è¿‡æ»¤ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼‰")
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                combined_deployments.to_excel(writer, sheet_name='FullDeploymentPlan', index=False)
        
        return str(output_file)
    
    def _generate_production_report(self, daily_files: Dict) -> str:
        """ç”Ÿæˆç”Ÿäº§è®¡åˆ’æ±‡æ€»æŠ¥å‘Š"""
        output_file = self.summary_dir / "full_production_plan_report.xlsx"
        
        all_productions = []
        
        for file_path in daily_files['module4']:
            try:
                xl = pd.ExcelFile(file_path)
                if 'ProductionPlan' in xl.sheet_names:
                    production_df = xl.parse('ProductionPlan')
                    all_productions.append(production_df)
            except Exception as e:
                print(f"Warning: Failed to read {file_path}: {e}")
        
        if all_productions:
            combined_productions = pd.concat(all_productions, ignore_index=True)
            
            # ğŸ”§ è¿‡æ»¤æ‰è¶…å‡ºæ¨¡æ‹Ÿæ—¥æœŸèŒƒå›´çš„æ•°æ®
            original_count = len(combined_productions)
            date_cols_to_filter = ['available_date', 'production_plan_date']
            for col in date_cols_to_filter:
                if col in combined_productions.columns:
                    combined_productions[col] = pd.to_datetime(combined_productions[col], errors='coerce')
            
            # åªä¿ç•™ available_date åœ¨èŒƒå›´å†…çš„è®°å½•ï¼ˆè¿™æ˜¯å®é™…äº§å“å¯ç”¨çš„æ—¥æœŸï¼‰
            if 'available_date' in combined_productions.columns:
                combined_productions = combined_productions[
                    (combined_productions['available_date'].isna()) | 
                    (combined_productions['available_date'] <= self.end_date)
                ]
                filtered_count = len(combined_productions)
                if original_count != filtered_count:
                    print(f"ğŸ“Š Production Plan è¿‡æ»¤ï¼š{original_count} æ¡ â†’ {filtered_count} æ¡ï¼ˆç§»é™¤äº† {original_count - filtered_count} æ¡è¶…å‡ºæ—¥æœŸèŒƒå›´çš„è®°å½•ï¼‰")
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                combined_productions.to_excel(writer, sheet_name='FullProductionPlan', index=False)
        
        return str(output_file)
    
    def _extract_date_from_filename(self, file_path: str) -> str:
        """ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸ"""
        import re
        match = re.search(r'(\d{8})', file_path)
        if match:
            date_str = match.group(1)
            return pd.to_datetime(date_str, format='%Y%m%d').strftime('%Y-%m-%d')
        return None
    
    def _generate_historical_inventory_report(self, start_date: str, end_date: str) -> str:
        """ç”Ÿæˆå†å²åº“å­˜è®°å½•CSVæŠ¥å‘Š"""
        output_file = self.summary_dir / "historical_inventory_record.csv"
        
        date_range = pd.date_range(start_date, end_date, freq='D')
        orchestrator_dir = self.module_dirs['orchestrator']
        module1_dir = self.module_dirs['module1']
        
        # è¯»å–safety stocké…ç½®
        safety_stock_dict = {}
        if 'M3_SafetyStock' in self.config_dict and not self.config_dict['M3_SafetyStock'].empty:
            ss_df = self.config_dict['M3_SafetyStock'].copy()
            # ç¡®ä¿æ—¥æœŸæ ¼å¼
            if 'date' in ss_df.columns:
                ss_df['date'] = pd.to_datetime(ss_df['date'])
            for _, row in ss_df.iterrows():
                material = self._normalize_material_value(str(row['material']))
                location = self._normalize_location_value(str(row['location']))
                key = (material, location)
                # ä½¿ç”¨æœ€æ–°çš„safety stockå€¼ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ—¥æœŸï¼‰
                safety_stock_dict[key] = int(row.get('safety_stock_qty', 0))
        
        all_records = []
        
        for date in date_range:
            date_str = date.strftime('%Y-%m-%d')
            date_str_file = date.strftime('%Y%m%d')
            
            # åˆå§‹åŒ–å½“æ—¥æ•°æ®å®¹å™¨
            ending_inv_dict = {}
            in_transit_dict = {}
            production_gr_dict = {}
            delivery_gr_dict = {}
            order_dict = {}
            shipment_dict = {}
            delivery_ship_dict = {}
            supply_demand_dict = {}
            
            # 1. è¯»å–æœŸæœ«åº“å­˜ (unrestricted_inventory)
            inv_file = orchestrator_dir / f"unrestricted_inventory_{date_str_file}.csv"
            if inv_file.exists():
                try:
                    inv_df = pd.read_csv(inv_file)
                    for _, row in inv_df.iterrows():
                        # ğŸ”§ ç¡®ä¿ä½¿ç”¨æ ‡å‡†åŒ–çš„ material å’Œ location
                        material = self._normalize_material_value(str(row['material']))
                        location = self._normalize_location_value(str(row['location']))
                        key = (material, location)
                        ending_inv_dict[key] = int(row['quantity'])
                except Exception as e:
                    print(f"Warning: Failed to read {inv_file}: {e}")
            
            # 2. è¯»å–åœ¨é€”åº“å­˜ (planning_intransit)
            intransit_file = orchestrator_dir / f"planning_intransit_{date_str_file}.csv"
            if intransit_file.exists():
                try:
                    intransit_df = pd.read_csv(intransit_file)
                    if not intransit_df.empty:
                        # æŒ‰æ¥æ”¶åœ°ç‚¹æ±‡æ€»åœ¨é€”æ•°é‡
                        for _, row in intransit_df.iterrows():
                            material = self._normalize_material_value(str(row['material']))
                            location = self._normalize_location_value(str(row['receiving']))
                            key = (material, location)
                            in_transit_dict[key] = in_transit_dict.get(key, 0) + int(row['quantity'])
                except Exception as e:
                    print(f"Warning: Failed to read {intransit_file}: {e}")
            
            # 3. è¯»å–ç”Ÿäº§å…¥åº“ (production_gr)
            prod_gr_file = orchestrator_dir / f"production_gr_{date_str_file}.csv"
            if prod_gr_file.exists():
                try:
                    prod_gr_df = pd.read_csv(prod_gr_file)
                    if not prod_gr_df.empty:
                        for _, row in prod_gr_df.iterrows():
                            material = self._normalize_material_value(str(row['material']))
                            location = self._normalize_location_value(str(row['location']))
                            key = (material, location)
                            production_gr_dict[key] = production_gr_dict.get(key, 0) + int(row['quantity'])
                except Exception as e:
                    print(f"Warning: Failed to read {prod_gr_file}: {e}")
            
            # 4. è¯»å–é…é€å…¥åº“ (delivery_gr)
            del_gr_file = orchestrator_dir / f"delivery_gr_{date_str_file}.csv"
            if del_gr_file.exists():
                try:
                    del_gr_df = pd.read_csv(del_gr_file)
                    if not del_gr_df.empty:
                        for _, row in del_gr_df.iterrows():
                            material = self._normalize_material_value(str(row['material']))
                            location = self._normalize_location_value(str(row['receiving']))
                            key = (material, location)
                            delivery_gr_dict[key] = delivery_gr_dict.get(key, 0) + int(row['quantity'])
                except Exception as e:
                    print(f"Warning: Failed to read {del_gr_file}: {e}")
            
            # 5. è¯»å–è®¢å• (order from module1)
            order_file = module1_dir / f"module1_output_{date_str_file}.xlsx"
            if order_file.exists():
                try:
                    xl = pd.ExcelFile(order_file)
                    if 'OrderLog' in xl.sheet_names:
                        order_df = xl.parse('OrderLog')
                        # åªç»Ÿè®¡å½“æ—¥åˆ°æœŸçš„è®¢å•
                        today_orders = order_df[pd.to_datetime(order_df['date']) == date]
                        if not today_orders.empty:
                            for _, row in today_orders.iterrows():
                                material = self._normalize_material_value(str(row['material']))
                                location = self._normalize_location_value(str(row['location']))
                                key = (material, location)
                                order_dict[key] = order_dict.get(key, 0) + int(row['quantity'])
                    
                    # è¯»å–ä¾›éœ€æ—¥å¿— (supply demand log)
                    if 'SupplyDemandLog' in xl.sheet_names:
                        sd_df = xl.parse('SupplyDemandLog')
                        if not sd_df.empty and 'date' in sd_df.columns:
                            # åªç»Ÿè®¡å½“æ—¥çš„ä¾›éœ€æ•°æ®
                            today_sd = sd_df[pd.to_datetime(sd_df['date']) == date]
                            if not today_sd.empty:
                                for _, row in today_sd.iterrows():
                                    material = self._normalize_material_value(str(row['material']))
                                    location = self._normalize_location_value(str(row['location']))
                                    key = (material, location)
                                    # æ±‡æ€»æ‰€æœ‰demand_elementçš„quantity
                                    supply_demand_dict[key] = supply_demand_dict.get(key, 0) + int(row.get('quantity', 0))
                except Exception as e:
                    print(f"Warning: Failed to read orders/supply-demand from {order_file}: {e}")
            
            # 6. è¯»å–å‘è´§ (shipment from orchestrator)
            shipment_file = orchestrator_dir / f"shipment_log_{date_str_file}.csv"
            if shipment_file.exists():
                try:
                    shipment_df = pd.read_csv(shipment_file)
                    if not shipment_df.empty:
                        for _, row in shipment_df.iterrows():
                            material = self._normalize_material_value(str(row['material']))
                            location = self._normalize_location_value(str(row['location']))
                            key = (material, location)
                            shipment_dict[key] = shipment_dict.get(key, 0) + int(row['quantity'])
                except Exception as e:
                    print(f"Warning: Failed to read {shipment_file}: {e}")
            
            # 7. è¯»å–é…é€å‘è´§ (delivery_shipment from orchestrator)
            del_ship_file = orchestrator_dir / f"delivery_shipment_log_{date_str_file}.csv"
            if del_ship_file.exists():
                try:
                    del_ship_df = pd.read_csv(del_ship_file)
                    if not del_ship_df.empty:
                        for _, row in del_ship_df.iterrows():
                            material = self._normalize_material_value(str(row['material']))
                            location = self._normalize_location_value(str(row['sending']))
                            key = (material, location)
                            delivery_ship_dict[key] = delivery_ship_dict.get(key, 0) + int(row['quantity'])
                except Exception as e:
                    print(f"Warning: Failed to read {del_ship_file}: {e}")
            
            # æ•´åˆæ‰€æœ‰æ•°æ® - ä»¥æœŸæœ«åº“å­˜ä¸ºåŸºå‡†ï¼ŒåŒ…å«æ‰€æœ‰å‡ºç°è¿‡çš„ (material, location)
            all_keys = set()
            all_keys.update(ending_inv_dict.keys())
            all_keys.update(in_transit_dict.keys())
            all_keys.update(production_gr_dict.keys())
            all_keys.update(delivery_gr_dict.keys())
            all_keys.update(order_dict.keys())
            all_keys.update(shipment_dict.keys())
            all_keys.update(delivery_ship_dict.keys())
            all_keys.update(supply_demand_dict.keys())
            all_keys.update(safety_stock_dict.keys())
            
            for material, location in sorted(all_keys):
                record = {
                    'date': date_str,
                    'material': material,
                    'location': location,
                    'ending_inventory': ending_inv_dict.get((material, location), 0),
                    'in_transit': in_transit_dict.get((material, location), 0),
                    'production_gr': production_gr_dict.get((material, location), 0),
                    'delivery_gr': delivery_gr_dict.get((material, location), 0),
                    'order': order_dict.get((material, location), 0),
                    'shipment': shipment_dict.get((material, location), 0),
                    'delivery_ship': delivery_ship_dict.get((material, location), 0),
                    'supply_demand': supply_demand_dict.get((material, location), 0),
                    'safety_stock': safety_stock_dict.get((material, location), 0)
                }
                all_records.append(record)
        
        # åˆ›å»ºDataFrameå¹¶è¾“å‡ºä¸ºCSV
        if all_records:
            historical_df = pd.DataFrame(all_records)
            historical_df.to_csv(output_file, index=False)
            print(f"ğŸ“Š å†å²åº“å­˜è®°å½•å·²ç”Ÿæˆ: {output_file} ({len(historical_df)} æ¡è®°å½•)")
        else:
            # åˆ›å»ºç©ºæ–‡ä»¶ï¼ŒåŒ…å«åˆ—å¤´
            empty_df = pd.DataFrame(columns=['date', 'material', 'location', 'ending_inventory', 
                                            'in_transit', 'production_gr', 'delivery_gr', 
                                            'order', 'shipment', 'delivery_ship', 'supply_demand', 'safety_stock'])
            empty_df.to_csv(output_file, index=False)
            print(f"âš ï¸  å†å²åº“å­˜è®°å½•ä¸ºç©ºï¼Œå·²åˆ›å»ºç©ºæ–‡ä»¶: {output_file}")
        
        return str(output_file)