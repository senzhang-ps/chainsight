#module 5
import pandas as pd
import numpy as np
import os
from datetime import timedelta
from typing import Dict, List

# ========= é›†æˆæ•°æ®åŠ è½½å‡½æ•° (æ–°å¢) =========

def load_module1_daily_shipment(module1_output_dir: str, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»Module1è¾“å‡ºåŠ è½½å½“æ—¥å‘è´§æ•°æ®
    
    Args:
        module1_output_dir: Module1è¾“å‡ºç›®å½•
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å½“æ—¥å‘è´§æ•°æ® [date, material, location, quantity]
    """
    try:
        date_str = current_date.strftime('%Y%m%d')
        module1_file = f"{module1_output_dir}/module1_output_{date_str}.xlsx"
        
        if os.path.exists(module1_file):
            xl = pd.ExcelFile(module1_file)
            if 'ShipmentLog' in xl.sheet_names:
                shipment_df = xl.parse('ShipmentLog')
                # ç¡®ä¿åŒ…å«éœ€è¦çš„åˆ—
                required_cols = ['date', 'material', 'location', 'quantity']
                if all(col in shipment_df.columns for col in required_cols):
                    return shipment_df[required_cols].copy()
                else:
                    print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {module1_file}")
            else:
                print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ä¸­æ— ShipmentLogè¡¨: {module1_file}")
        else:
            print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {module1_file}")
    except Exception as e:
        print(f"âš ï¸  åŠ è½½Module1å‘è´§æ•°æ®å¤±è´¥: {e}")
    
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame(columns=['date', 'material', 'location', 'quantity'])

def load_orchestrator_delivery_gr(orchestrator: object, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»OrchestratoråŠ è½½å½“æ—¥æ”¶è´§æ•°æ®
    
    Args:
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å½“æ—¥æ”¶è´§æ•°æ® [date, material, receiving, quantity]
    """
    try:
        date_str = current_date.strftime('%Y-%m-%d')
        delivery_gr_view = orchestrator.get_delivery_gr_view(date_str)
        
        if isinstance(delivery_gr_view, pd.DataFrame) and not delivery_gr_view.empty:
            # ç¡®ä¿åŒ…å«éœ€è¦çš„åˆ—
            required_cols = ['date', 'material', 'receiving', 'quantity']
            available_cols = delivery_gr_view.columns.tolist()
            
            # å°è¯•æ˜ å°„åˆ—åç§°
            col_mapping = {
                'location': 'receiving',  # location æ˜ å°„ä¸º receiving
                'gr_qty': 'quantity',     # gr_qty æ˜ å°„ä¸º quantity
                'received_qty': 'quantity'  # received_qty æ˜ å°„ä¸º quantity
            }
            
            # åº”ç”¨åˆ—æ˜ å°„
            renamed_df = delivery_gr_view.copy()
            for old_col, new_col in col_mapping.items():
                if old_col in renamed_df.columns:
                    renamed_df = renamed_df.rename(columns={old_col: new_col})
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in required_cols if col not in renamed_df.columns]
            if not missing_cols:
                return renamed_df[required_cols].copy()
            else:
                print(f"âš ï¸  Orchestrator delivery_gr_viewç¼ºå°‘å­—æ®µ: {missing_cols}")
        else:
            print(f"âš ï¸  Orchestratorè¿”å›ç©ºçš„delivery_gr_view")
    except Exception as e:
        print(f"âš ï¸  ä»OrchestratoråŠ è½½æ”¶è´§æ•°æ®å¤±è´¥: {e}")
    
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame(columns=['date', 'material', 'receiving', 'quantity'])

def load_orchestrator_open_deployment(orchestrator: object, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»OrchestratoråŠ è½½å¼€æ”¾è°ƒæ‹¨æ•°æ®
    
    Args:
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å¼€æ”¾è°ƒæ‹¨æ•°æ® [material, sending, quantity]
    """
    try:
        date_str = current_date.strftime('%Y-%m-%d')
        open_deployment_view = orchestrator.get_open_deployment_view(date_str)
        
        if isinstance(open_deployment_view, pd.DataFrame) and not open_deployment_view.empty:
            # ç¡®ä¿åŒ…å«éœ€è¦çš„åˆ—
            required_cols = ['material', 'sending', 'quantity']
            available_cols = open_deployment_view.columns.tolist()
            
            # å°è¯•æ˜ å°„åˆ—åç§°
            col_mapping = {
                'location': 'sending',     # location æ˜ å°„ä¸º sending
                'deployed_qty': 'quantity',  # deployed_qty æ˜ å°„ä¸º quantity
                'planned_qty': 'quantity'    # planned_qty æ˜ å°„ä¸º quantity
            }
            
            # åº”ç”¨åˆ—æ˜ å°„
            renamed_df = open_deployment_view.copy()
            for old_col, new_col in col_mapping.items():
                if old_col in renamed_df.columns:
                    renamed_df = renamed_df.rename(columns={old_col: new_col})
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in required_cols if col not in renamed_df.columns]
            if not missing_cols:
                return renamed_df[required_cols].copy()
            else:
                print(f"âš ï¸  Orchestrator open_deployment_viewç¼ºå°‘å­—æ®µ: {missing_cols}")
        else:
            print(f"âš ï¸  Orchestratorè¿”å›ç©ºçš„open_deployment_view")
    except Exception as e:
        print(f"âš ï¸  ä»OrchestratoråŠ è½½å¼€æ”¾è°ƒæ‹¨æ•°æ®å¤±è´¥: {e}")
    
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame(columns=['material', 'sending', 'quantity'])

def calculate_available_inventory(
    unrestricted_inventory: dict,
    in_transit: dict, 
    delivery_gr: dict,
    today_production_gr: dict,
    future_production: dict,
    today_shipment: dict,
    open_deployment: dict
) -> dict:
    """
    è®¡ç®—å¯ç”¨åº“å­˜ï¼Œä¸Module3é€»è¾‘å®Œå…¨ä¸€è‡´
    
    Formula: available_inventory = unrestricted + in_transit + delivery_gr + 
             today_production + future_production - today_shipment - open_deployment
    
    Args:
        å„ä¸ªåº“å­˜ç»´åº¦çš„å­—å…¸ï¼Œé”®ä¸º(material, location)ï¼Œå€¼ä¸ºæ•°é‡
        
    Returns:
        dict: å¯ç”¨åº“å­˜å­—å…¸ {(material, location): quantity}
    """
    all_keys = set()
    for d in [unrestricted_inventory, in_transit, delivery_gr, today_production_gr, 
              future_production, today_shipment, open_deployment]:
        all_keys.update(d.keys())
    
    available_inventory = {}
    for key in all_keys:
        available_inventory[key] = (
            unrestricted_inventory.get(key, 0) +
            in_transit.get(key, 0) +
            delivery_gr.get(key, 0) +
            today_production_gr.get(key, 0) +
            future_production.get(key, 0) -
            today_shipment.get(key, 0) -
            open_deployment.get(key, 0)
        )
    
    return available_inventory

# ========= 1. é€šç”¨è¾…åŠ© =========

def get_upstream(location, material, network_df, sim_date):
    row = get_active_network(network_df, material, location, sim_date)
    if not row.empty:
        return row.iloc[0]['sourcing']
    return None

def apply_moq_rv(qty, moq, rv):
    """è¡¥è´§é‡å°äºmoqè¡¥moqï¼Œå¦åˆ™å‘ä¸Šå–æ•´åˆ°rvçš„å€æ•°"""
    if qty <= 0:
        return 0
    if qty < moq:
        return moq
    return int(np.ceil(qty / rv)) * rv

def determine_lead_time(
    sending: str,
    receiving: str,
    location_type: str,
    lead_time_df: pd.DataFrame
) -> tuple[int, str]:
    """
    ç¡®å®šä¸¤åœ°ä¹‹é—´çš„æå‰æœŸ - ä¸Module3ä¿æŒä¸€è‡´
    ä½¿ç”¨Global_Networkä¸­çš„location_typeå­—æ®µè¿›è¡Œè®¡ç®—
    
    Args:
        sending: å‘é€åœ°ç‚¹
        receiving: æ¥æ”¶åœ°ç‚¹
        location_type: åœ°ç‚¹ç±»å‹ï¼ˆæ¥è‡ªGlobal_Networkï¼‰
        lead_time_df: æå‰æœŸé…ç½®æ•°æ®
        
    Returns:
        tuple[int, str]: (æå‰æœŸå¤©æ•°, é”™è¯¯ä¿¡æ¯)
    """
    if lead_time_df.empty:
        return 1, 'empty_lead_time_config'
        
    row = lead_time_df[
        (lead_time_df['sending'] == sending) & 
        (lead_time_df['receiving'] == receiving)
    ]
    
    if row.empty:
        return 1, 'lead_time_missing'
    
    try:
        PDT = int(row.iloc[0]['PDT']) if pd.notna(row.iloc[0]['PDT']) else 0
        GR = int(row.iloc[0]['GR']) if pd.notna(row.iloc[0]['GR']) else 0
        MCT = int(row.iloc[0]['MCT']) if pd.notna(row.iloc[0]['MCT']) else 0
        
        if str(location_type).lower() == 'plant':
            lead_time = max(MCT, PDT + GR)
        else:  # DC (Distribution Center)
            lead_time = PDT + GR
            
        return max(1, lead_time), ""
        
    except Exception as e:
        return 1, f'lead_time_calculation_error: {str(e)}'

def assign_network_layers(network_df: pd.DataFrame) -> pd.DataFrame:
    from collections import defaultdict, deque

    # 1. åŸå§‹ç½‘ç»œæ•°æ®å¤„ç†
    net = network_df.copy()
    
    # 2. æ„å»ºçˆ¶å­å…³ç³»å›¾
    children = defaultdict(list)
    parents = defaultdict(list)
    for _, row in net.iterrows():
        if pd.notna(row['sourcing']):  # åªå¤„ç†æœ‰æ•ˆçš„sourcingå…³ç³»
            children[row['sourcing']].append(row['location'])
            parents[row['location']].append(row['sourcing'])

    # 3. æ”¶é›†æ‰€æœ‰æ¶‰åŠçš„èŠ‚ç‚¹
    all_locations = set()
    # æ·»åŠ æ‰€æœ‰locationèŠ‚ç‚¹
    all_locations.update(network_df['location'].dropna().unique())
    # æ·»åŠ æ‰€æœ‰sourcingèŠ‚ç‚¹ï¼ˆå¯èƒ½ä¸åœ¨locationåˆ—ä¸­ï¼‰
    all_locations.update(network_df['sourcing'].dropna().unique())

    # 4. è‡ªåŠ¨è¯†åˆ«æ ¹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰çˆ¶èŠ‚ç‚¹çš„èŠ‚ç‚¹ï¼‰
    roots = []
    for loc in all_locations:
        if not parents.get(loc):  # æ²¡æœ‰çˆ¶èŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹ä¸ºç©º
            roots.append(loc)
    
    # 5. å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ ¹èŠ‚ç‚¹ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•
    if not roots:
        # å¯å‘å¼ï¼šå¯»æ‰¾åœ¨ç½‘ç»œä¸­ä½œä¸ºsourcingå‡ºç°ä½†ä¸ä½œä¸ºlocationå‡ºç°çš„èŠ‚ç‚¹
        sourcing_only = set(network_df['sourcing'].dropna().unique()) - set(network_df['location'].dropna().unique())
        if sourcing_only:
            roots = list(sourcing_only)
        else:
            # æœ€åæ‰‹æ®µï¼šä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ä¸­æœ€ä¸Šæ¸¸çš„èŠ‚ç‚¹
            all_sourcing = set(network_df['sourcing'].dropna().unique())
            all_locations_set = set(network_df['location'].dropna().unique())
            potential_roots = all_sourcing - all_locations_set
            roots = list(potential_roots) if potential_roots else list(all_locations)[:1] if all_locations else []

    # 6. å±‚çº§åˆ†é…ï¼ˆBFSï¼‰
    layer_dict = {}
    queue = deque()
    for root in roots:
        queue.append((root, 0))
    
    while queue:
        loc, layer = queue.popleft()
        if loc in layer_dict and layer_dict[loc] <= layer:
            continue
        layer_dict[loc] = layer
        for child in children.get(loc, []):
            queue.append((child, layer + 1))
    
    # 7. å­¤ç«‹ç‚¹å¤„ç†
    for loc in all_locations:
        if loc not in layer_dict:
            layer_dict[loc] = max(layer_dict.values()) + 1 if layer_dict else 0
    
    # 8. åè½¬å±‚çº§ï¼ˆè®©æ¶ˆè´¹è€…å±‚ä¸º0ï¼Œä¾›åº”å•†å±‚é€’å¢ï¼‰
    layer_df = pd.DataFrame([{'location': loc, 'layer': layer} for loc, layer in layer_dict.items()])
    max_layer = layer_df['layer'].max()
    layer_df['layer'] = max_layer - layer_df['layer']
    
    return layer_df

def get_active_network(network_df, material, location, sim_date):
    rows = network_df[
        (network_df['material'] == material) &
        (network_df['location'] == location) &
        (network_df['eff_from'] <= sim_date) &
        (network_df['eff_to'] >= sim_date)
    ]
    return rows

def is_review_day(dt, lsk, day):
    if lsk == 'daily':
        return True
    if lsk == 'weekly':
        return dt.weekday() == (int(day) - 1)
    if lsk == 'monthly':
        return dt.day == int(day)
    raise ValueError(f"Unknown LSK: {lsk}")

def compute_horizon(dt, lsk, day):
    if lsk == 'daily':
        return dt, dt
    if lsk == 'weekly':
        # Only valid if dt is review day
        if dt.weekday() != (int(day)-1):
            raise ValueError(f"compute_horizon: input date {dt} is not review day (expected weekday {int(day)-1})")
        cur = dt + timedelta(days=1)
        while True:
            if cur.weekday() == (int(day) - 1):
                break
            cur += timedelta(days=1)
        window_end = cur - timedelta(days=1)
        return dt, window_end
    if lsk == 'monthly':
        if dt.day != int(day):
            raise ValueError(f"compute_horizon: input date {dt} is not review day (expected day {int(day)})")
        y, m = dt.year, dt.month
        if dt.day >= int(day):
            m += 1
            if m > 12:
                m = 1
                y += 1
        next_review = pd.Timestamp(y, m, int(day))
        window_end = next_review - timedelta(days=1)
        return dt, window_end
    raise ValueError(f"Unknown LSK: {lsk}")


def allocate_by_priority_and_weight(demand_rows, available_stock, demand_priority_map):
    demand_rows_sorted = sorted(demand_rows, key=lambda d: demand_priority_map.get(d['demand_type'], 99))
    grouped = {}
    for d in demand_rows_sorted:
        p = demand_priority_map.get(d['demand_type'], 99)
        grouped.setdefault(p, []).append(d)
    stock_left = available_stock
    for priority in sorted(grouped):
        group = grouped[priority]
        total = sum(d['planned_qty'] for d in group)
        if total == 0:
            for d in group:
                d['deployed_qty_invCon'] = 0
            continue
        if stock_left >= total:
            for d in group:
                d['deployed_qty_invCon'] = d['planned_qty']
            stock_left -= total
        else:
            allocated = 0
            for d in group:
                weight = d['planned_qty'] / total
                d['deployed_qty_invCon'] = int(stock_left * weight)
                allocated += d['deployed_qty_invCon']
            stock_left -= allocated
            for d in group:
                d['deployed_qty_invCon'] = min(d['deployed_qty_invCon'], d['planned_qty'])
    return stock_left

def load_integrated_config(
    config_dict: dict,
    module1_output_dir: str,
    module4_output_path: str, 
    orchestrator: object,
    current_date: pd.Timestamp
) -> dict:
    """
    åŠ è½½é›†æˆé…ç½®æ•°æ®ï¼Œæ›¿ä»£åŸæ¥çš„load_config
    
    Args:
        config_dict: é…ç½®æ•°æ®å­—å…¸
        module1_output_dir: Module1è¾“å‡ºç›®å½•
        module4_output_path: Module4è¾“å‡ºæ–‡ä»¶è·¯å¾„
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        dict: é›†æˆé…ç½®æ•°æ®
    """
    config = {}
    validation_log = []
    
    # 1. ä»é…ç½®è¡¨åŠ è½½é™æ€æ•°æ®
    config['SafetyStock'] = config_dict.get('M3_SafetyStock', pd.DataFrame())
    config['Network'] = config_dict.get('Global_Network', pd.DataFrame())
    config['LeadTime'] = config_dict.get('Global_LeadTime', pd.DataFrame())
    config['DemandPriority'] = config_dict.get('Global_DemandPriority', pd.DataFrame())
    config['PushPullModel'] = config_dict.get('M5_PushPullModel', pd.DataFrame())
    config['DeployConfig'] = config_dict.get('M5_DeployConfig', pd.DataFrame())
    
    # 2. ä»Module1åŠ è½½å½“æ—¥æ•°æ®
    config['SupplyDemandLog'] = config_dict.get('M5_SupplyDemandLog', pd.DataFrame())  # ä»æµ‹è¯•é…ç½®åŠ è½½
    
    # å®é™…ä» Module1 è¾“å‡ºåŠ è½½å½“æ—¥æ•°æ®
    if module1_output_dir and current_date:
        try:
            # ä» Module1 æ—¥è¾“å‡ºåŠ è½½ SupplyDemandLog
            date_str = current_date.strftime('%Y%m%d')
            module1_file = f"{module1_output_dir}/module1_output_{date_str}.xlsx"
            if os.path.exists(module1_file):
                xl = pd.ExcelFile(module1_file)
                if 'SupplyDemandLog' in xl.sheet_names:
                    m1_supply_demand = xl.parse('SupplyDemandLog')
                    if not m1_supply_demand.empty:
                        config['SupplyDemandLog'] = m1_supply_demand
                        print(f"  âœ… ä» Module1 åŠ è½½äº† {len(m1_supply_demand)} æ¡ SupplyDemandLog æ•°æ®")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•ä» Module1 åŠ è½½æ•°æ®: {e}")
    
    # ä»Module1åŠ è½½å½“æ—¥å‘è´§æ•°æ®
    if module1_output_dir and current_date:
        config['TodayShipment'] = load_module1_daily_shipment(module1_output_dir, current_date)
    else:
        config['TodayShipment'] = pd.DataFrame()
    
    # 3. ä»Module4åŠ è½½ç”Ÿäº§è®¡åˆ’
    config['ProductionPlan'] = config_dict.get('M5_ProductionPlan', pd.DataFrame())   # ä»æµ‹è¯•é…ç½®åŠ è½½
    
    # å®é™…ä»Module4è¾“å‡ºåŠ è½½æ•°æ®
    if module4_output_path and os.path.exists(module4_output_path):
        try:
            xl = pd.ExcelFile(module4_output_path)
            if 'ProductionPlan' in xl.sheet_names:
                m4_production = xl.parse('ProductionPlan')
                if not m4_production.empty:
                    config['ProductionPlan'] = m4_production
                    print(f"  âœ… ä» Module4 åŠ è½½äº† {len(m4_production)} æ¡ç”Ÿäº§è®¡åˆ’æ•°æ®")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•ä» Module4 åŠ è½½æ•°æ®: {e}")
    
    # 4. ä»OrchestratoråŠ è½½åŠ¨æ€æ•°æ®
    if orchestrator and current_date:
        date_str = current_date.strftime('%Y-%m-%d')
        try:
            config['InventoryLog'] = orchestrator.get_unrestricted_inventory_view(date_str)
            config['InTransit'] = orchestrator.get_planning_intransit_view(date_str)
            config['DeliveryGR'] = load_orchestrator_delivery_gr(orchestrator, current_date)
            config['OpenDeployment'] = load_orchestrator_open_deployment(orchestrator, current_date)
            config['ReceivingSpace'] = orchestrator.get_space_quota_view(date_str)
            print(f"  âœ… ä» Orchestrator åŠ è½½äº†åŠ¨æ€æ•°æ®")
        except Exception as e:
            print(f"  âš ï¸  ä» Orchestrator åŠ è½½åŠ¨æ€æ•°æ®å¤±è´¥: {e}")
            # ä½¿ç”¨ç©ºæ•°æ®ä½œä¸ºå¤‡é€‰
            config['InventoryLog'] = pd.DataFrame()
            config['InTransit'] = pd.DataFrame() 
            config['DeliveryGR'] = pd.DataFrame()
            config['OpenDeployment'] = pd.DataFrame()
            config['ReceivingSpace'] = pd.DataFrame()
    else:
        # ä½¿ç”¨ç©ºæ•°æ®
        config['InventoryLog'] = pd.DataFrame()
        config['InTransit'] = pd.DataFrame()
        config['DeliveryGR'] = pd.DataFrame()
        config['OpenDeployment'] = pd.DataFrame()
        config['ReceivingSpace'] = pd.DataFrame()
    
    # ä¸´æ—¶ä½¿ç”¨ç©ºæ•°æ®ä»¥ä¿æŒå…¼å®¹æ€§
    for key in ['SupplyDemandLog', 'ProductionPlan', 'InventoryLog', 'InTransit', 'ReceivingSpace']:
        if key not in config:
            config[key] = pd.DataFrame()
    
    # æ—¥æœŸå­—æ®µå¤„ç†
    date_fields = {
        'SupplyDemandLog': ['date'],
        'ProductionPlan': ['available_date'],
        'InventoryLog': ['date'],
        'InTransit': ['available_date'],
        'SafetyStock': ['date'],
        'ReceivingSpace': ['date'],
        'Network': ['eff_from', 'eff_to'],
    }
    
    for sheet, fields in date_fields.items():
        if sheet in config and not config[sheet].empty:
            for f in fields:
                if f in config[sheet].columns:
                    config[sheet][f] = pd.to_datetime(config[sheet][f])
    
    config['ValidationLog'] = validation_log
    return config

def load_config(input_path: str):
    required_sheets = [
        'SupplyDemandLog', 'ProductionPlan', 'InventoryLog', 'InTransit', 'SafetyStock',
        'Network', 'PushPullModel', 'ReceivingSpace', 'LeadTime',
        'DemandPriority', 'DeployConfig'
    ]
    config = {}
    validation_log = []
    xl = pd.ExcelFile(input_path)
    for sheet in required_sheets:
        if sheet not in xl.sheet_names:
            validation_log.append({'No': len(validation_log)+1, 'Issue': f'Missing required sheet: {sheet}'})
            config[sheet] = pd.DataFrame()
        else:
            df = xl.parse(sheet)
            config[sheet] = df
    # å­—æ®µæ ¡éªŒä¸¾ä¾‹
    sdl_required = ['date', 'material', 'location', 'demand_element', 'quantity']
    if not config['SupplyDemandLog'].empty:
        missing_cols = [c for c in sdl_required if c not in config['SupplyDemandLog'].columns]
        if missing_cols:
            validation_log.append({'No': len(validation_log)+1, 'Issue': f'SupplyDemandLog missing columns: {",".join(missing_cols)}'})
    # æ—¥æœŸç±»å‹å¤„ç†
    date_fields = {
        'SupplyDemandLog': ['date'],
        'ProductionPlan': ['available_date'],
        'InventoryLog': ['date'],
        'InTransit': ['available_date'],
        'SafetyStock': ['date'],
        'ReceivingSpace': ['date'],
        'Network': ['eff_from', 'eff_to'],
    }
    for sheet, fields in date_fields.items():
        if sheet in config and not config[sheet].empty:
            for f in fields:
                if f in config[sheet].columns:
                    config[sheet][f] = pd.to_datetime(config[sheet][f])
    config['ValidationLog'] = validation_log
    return config

def validate_config_before_run(config, validation_log):
    # æ£€æŸ¥leadtimeç¼ºå¤±ï¼Œpushpullç¼ºå¤±ï¼Œdemand_priorityç¼ºå¤±
    deploy_cfg = config['DeployConfig']
    leadtime_df = config['LeadTime']
    pushpull = config['PushPullModel']
    demand_priority = config['DemandPriority']
    network = config['Network']
    # ======= æ ¡éªŒnetworkæ˜¯å¦æœ‰multiple sourcing ==========
    multi_sourcing = (
        network.groupby(['material', 'location'])['sourcing']
        .nunique().reset_index()
    )
    multi_sourcing = multi_sourcing[multi_sourcing['sourcing'] > 1]
    for _, row in multi_sourcing.iterrows():
        validation_log.append({
            'No': len(validation_log) + 1,
            'Issue': f"Networké…ç½®ä¸åˆæ³•: material={row['material']}, location={row['location']} æœ‰å¤šä¸ªsourcing"
        })
    # æ ¡éªŒleadtime
    for _, row in network.iterrows():
        if leadtime_df[
            (leadtime_df['sending'] == row['sourcing']) & (leadtime_df['receiving'] == row['location'])
        ].empty:
            validation_log.append({'No': len(validation_log)+1,
                                  'Issue': f"Missing leadtime for {row['sourcing']}->{row['location']} ({row['material']})"})
    # æ ¡éªŒpushpull
    for _, row in deploy_cfg.iterrows():
        if pushpull[
            (pushpull['material'] == row['material']) & (pushpull['sending'] == row['sending'])
        ].empty:
            validation_log.append({'No': len(validation_log)+1,
                'Issue': f"Missing PushPullModel for {row['material']}/{row['sending']}"})
    # æ ¡éªŒdemand_priority
    demand_types = set(config['SupplyDemandLog']['demand_element'].unique()) if not config['SupplyDemandLog'].empty else set()
    for dt in demand_types:
        if demand_priority[demand_priority['demand_element'] == dt].empty:
            validation_log.append({'No': len(validation_log)+1,
                                   'Issue': f"DemandPriority not defined for {dt}"})
    return validation_log

def collect_node_demands(material, location, sim_date, config, up_gap_buffer):
    supply_demand_log = config['SupplyDemandLog']
    safety_stock = config['SafetyStock']
    deploy_cfg = config['DeployConfig']
    network = config['Network']
    leadtime_df = config['LeadTime']

    # å‚æ•°
    param_row = deploy_cfg[
        (deploy_cfg['material'] == material) & (deploy_cfg['sending'] == location)
    ]
    if not param_row.empty:
        moq = int(param_row.iloc[0]['moq'])
        rv = int(param_row.iloc[0]['rv'])
        lsk = param_row.iloc[0]['lsk']
        day = int(param_row.iloc[0]['day'])
    else:
        moq, rv, lsk, day = 1, 1, 1, 1

    network_row = get_active_network(network, material, location, sim_date)
    if not network_row.empty:
        upstream = network_row.iloc[0]['sourcing']
        
        # MCTæ˜¯å¾®ç”Ÿç‰©æ£€æµ‹æ—¶é—´ï¼Œä¸sending siteç›¸å…³
        # éœ€è¦æŸ¥æ‰¾sending locationçš„location_type
        if upstream:
            sending_network_row = get_active_network(network, material, upstream, sim_date)
            if not sending_network_row.empty:
                sending_location_type = sending_network_row.iloc[0].get('location_type', 'DC')
            else:
                sending_location_type = 'DC'
        else:
            sending_location_type = 'DC'
    else:
        upstream = None
        sending_location_type = 'DC'

    # ä½¿ç”¨ä¸Module3ä¸€è‡´çš„æå‰æœŸè®¡ç®—é€»è¾‘
    if upstream and pd.notna(upstream) and str(upstream).strip():
        leadtime, error_msg = determine_lead_time(
            sending=str(upstream),
            receiving=str(location),
            location_type=str(sending_location_type),  # ä½¿ç”¨sending locationçš„location_type
            lead_time_df=leadtime_df
        )
        if error_msg:
            print(f"Warning: {error_msg} for {upstream}->{location}, using default leadtime=1")
            leadtime = 1
    else:
        # é¡¶å±‚èŠ‚ç‚¹ï¼ˆæ— upstreamï¼‰ä¸éœ€è¦è®¡ç®—æå‰æœŸ
        leadtime = 0

    # ä½¿ç”¨ç»Ÿä¸€çš„planned_deploy_dateç­›é€‰é€»è¾‘: [simulation_date, simulation_date + lsk - 1]
    filter_start = sim_date
    filter_end = sim_date + pd.Timedelta(days=int(lsk) - 1)

    demand_rows = []

    # SupplyDemandLogï¼ˆéœ€æ±‚åŸå§‹è¡Œï¼‰
    sdl = supply_demand_log[
        (supply_demand_log['material'] == material) & (supply_demand_log['location'] == location)
    ].copy()
    if not sdl.empty:
        # dateå­—æ®µä»£è¡¨requirement_dateï¼ˆéœ€æ±‚éœ€è¦çš„æ—¥æœŸï¼‰
        sdl['requirement_date'] = pd.to_datetime(sdl['date'])
        # è®¡ç®—planned_deploy_dateå¹¶ç­›é€‰
        sdl['planned_deploy_date'] = sdl['requirement_date'] - pd.Timedelta(days=leadtime)
        sdl['planned_deploy_date'] = sdl[['planned_deploy_date']].apply(lambda x: max(x['planned_deploy_date'], sim_date), axis=1)
        # ä½¿ç”¨planned_deploy_dateçª—å£ç­›é€‰
        mask = (sdl['planned_deploy_date'] >= filter_start) & (sdl['planned_deploy_date'] <= filter_end)
        sdl = sdl[mask]
    for _, row in sdl.iterrows():
        requirement_date = row['requirement_date']
        planned_deploy_date = row['planned_deploy_date']
        
        demand_rows.append({
            'material': material,
            'location': location,
            'sending': upstream,
            'receiving': location,
            'demand_element': row['demand_element'],
            'demand_qty': int(row['quantity']),
            'planned_qty': int(row['quantity']),
            'moq': moq,
            'rv': rv,
            'leadtime': leadtime,
            'requirement_date': requirement_date,
            'plan_deploy_date': planned_deploy_date,
        })

    # SafetyStockåŒç†
    ss = safety_stock[
        (safety_stock['material'] == material) & (safety_stock['location'] == location)
    ].copy()
    if not ss.empty:
        # safety stockçš„dateå­—æ®µä¹Ÿä»£è¡¨requirement_date
        ss['requirement_date'] = pd.to_datetime(ss['date'])
        # è®¡ç®—planned_deploy_dateå¹¶ç­›é€‰
        ss['planned_deploy_date'] = ss['requirement_date'] - pd.Timedelta(days=leadtime)
        ss['planned_deploy_date'] = ss[['planned_deploy_date']].apply(lambda x: max(x['planned_deploy_date'], sim_date), axis=1)
        # ä½¿ç”¨planned_deploy_dateçª—å£ç­›é€‰
        mask = (ss['planned_deploy_date'] >= filter_start) & (ss['planned_deploy_date'] <= filter_end)
        ss = ss[mask]
    for _, row in ss.iterrows():
        requirement_date = row['requirement_date']
        planned_deploy_date = row['planned_deploy_date']
        
        demand_rows.append({
            'material': material,
            'location': location,
            'sending': upstream,
            'receiving': location,
            'demand_element': 'safety',
            'demand_qty': int(row['safety_stock_qty']),
            'planned_qty': int(row['safety_stock_qty']),
            'moq': moq,
            'rv': rv,
            'leadtime': leadtime,
            'requirement_date': requirement_date,
            'plan_deploy_date': planned_deploy_date,
        })

    # gapè¡Œï¼Œè¿™éƒ¨åˆ†éœ€è¦æŒ‰requirement_dateé‡æ–°è®¡ç®—planned_deploy_dateå¹¶ç­›é€‰
    if up_gap_buffer is not None and (material, location) in up_gap_buffer:
        for gap in up_gap_buffer[(material, location)]:
            requirement_date = gap.get('requirement_date', None)
            if requirement_date is None:
                # å¦‚æœæ²¡æœ‰requirement_dateï¼Œé»˜è®¤ä½¿ç”¨å½“å‰æ—¥æœŸ
                requirement_date = sim_date
                planned_deploy_date = sim_date
            else:
                requirement_date = pd.to_datetime(requirement_date)
                # åŸºäºä¸Šæ¸¸èŠ‚ç‚¹çš„leadtimeé‡æ–°è®¡ç®—planned_deploy_date
                planned_deploy_date = requirement_date - pd.Timedelta(days=leadtime)
                planned_deploy_date = max(planned_deploy_date, sim_date)
            
            # æ£€æŸ¥planned_deploy_dateæ˜¯å¦åœ¨ç­›é€‰çª—å£å†…
            if planned_deploy_date >= filter_start and planned_deploy_date <= filter_end:
                demand_rows.append({
                    'material': material,
                    'location': gap.get('location', location),
                    'receiving': gap.get('receiving', gap.get('location', location)),
                    'orig_location': gap.get('orig_location', gap.get('location', location)),
                    'sending': upstream,
                    'demand_element': gap['demand_element'],
                    'demand_qty': gap['planned_qty'],
                    'planned_qty': gap['planned_qty'],
                    'moq': moq,
                    'rv': rv,
                    'leadtime': leadtime,
                    'requirement_date': requirement_date,
                    'plan_deploy_date': planned_deploy_date,
                    'from_location': gap.get('from_location', None),
                })
    return demand_rows

def push_softpush_allocation(
    deployment_plan_rows, config, dynamic_soh, sim_date
):
    """
    å¯¹push/soft-pushæ¨¡å¼èŠ‚ç‚¹ï¼Œåˆ†é…å‰©ä½™åº“å­˜åˆ°ä¸‹æ¸¸receiving, è¾“å‡ºpushè¡¥è´§è®¡åˆ’è¡Œ
    ä¿®æ­£ï¼šplanned_delivery_date = date + leadtime (æŒ‰LeadTimeè¡¨æŸ¥)
    """
    pushpull = config['PushPullModel']
    safety_stock = config['SafetyStock']
    leadtime_df = config['LeadTime']
    deploy_cfg = config['DeployConfig']
    net = config['Network']
    plan_rows_push = []
    group_keys = {(row['material'], row['sending']) for row in deployment_plan_rows}
    for mat, sending in group_keys:
        row_pp = pushpull[
            (pushpull['material'] == mat) & (pushpull['sending'] == sending)
        ]
        if row_pp.empty:
            continue
        model = row_pp.iloc[0]['model']
        if model not in ['push', 'soft push']:
            continue
        soh = dynamic_soh.get((mat, sending), 0)
        recs = net[(net['material']==mat) & (net['sourcing']==sending)]['location'].unique()
        param_row = deploy_cfg[
            (deploy_cfg['material'] == mat) & (deploy_cfg['sending'] == sending)
        ]
        if not param_row.empty:
            lsk = int(param_row.iloc[0]['lsk'])  # ç¡®ä¿LSKä¸ºæ•´æ•°
            day = int(param_row.iloc[0]['day'])
        else:
            lsk, day = 1, 1
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ç­›é€‰é€»è¾‘è®¡ç®—filter_end
        filter_end = sim_date + pd.Timedelta(days=lsk - 1)
        ss = safety_stock[
            (safety_stock['material'] == mat) & (safety_stock['location'].isin(recs))
        ]
        ss = ss[pd.to_datetime(ss['date']) == filter_end]
        total_ss = ss['safety_stock_qty'].sum()
        for _, row in ss.iterrows():
            loc = row['location']
            ss_val = row['safety_stock_qty']
            if model == 'push':
                if total_ss > 0:
                    qty = soh * ss_val / total_ss
                else:
                    qty = 0
            else:  # soft push
                # è®¡ç®—æœ¬å±‚siteçš„safety
                own_ss = 0
                ss_self = safety_stock[
                    (safety_stock['material'] == mat) & (safety_stock['location'] == sending)
                ]
                if not ss_self.empty:
                    own_ss = ss_self['safety_stock_qty'].sum()
                qty_avail = max(0, soh - own_ss)
                qty = qty_avail * ss_val / total_ss if total_ss > 0 else 0
            qty = int(np.floor(qty))
            # å…³é”®ï¼šæŸ¥leadtimeï¼Œä½¿ç”¨ä¸Module3ä¸€è‡´çš„é€»è¾‘
            # MCTæ˜¯å¾®ç”Ÿç‰©æ£€æµ‹æ—¶é—´ï¼Œä¸sending siteç›¸å…³
            # è·å–sending locationçš„location_type
            sending_network_row = net[
                (net['material'] == mat) & (net['location'] == sending)
            ]
            if not sending_network_row.empty:
                sending_location_type = sending_network_row.iloc[0].get('location_type', 'DC')
            else:
                sending_location_type = 'DC'
            
            leadtime, error_msg = determine_lead_time(
                sending=str(sending),
                receiving=str(loc),
                location_type=str(sending_location_type),  # ä½¿ç”¨sending locationçš„location_type
                lead_time_df=leadtime_df
            )
            if error_msg:
                print(f"Warning: push/soft push {error_msg} for {sending}->{loc}, using default leadtime=1")
                leadtime = 1
                print(f"Warning: {error_msg} for {sending}->{loc}, using default leadtime=1")
                leadtime = 1
            planned_delivery_date = sim_date + timedelta(days=leadtime)
            plan = {
                'date': sim_date,
                'material': mat,
                'sending': sending,
                'receiving': loc,
                'demand_qty': 0,
                'demand_element': 'push replenishment' if model=='push' else 'soft push replenishment',
                'planned_qty': qty,
                'deployed_qty_invCon_push': qty,
                'planned_delivery_date': planned_delivery_date,
            }
            plan['deployed_qty_invCon'] = plan['deployed_qty_invCon_push']  # å…¼å®¹åç»­ç©ºé—´åˆ†é…å’Œåº“å­˜ç»Ÿè®¡
            plan_rows_push.append(plan)
    return plan_rows_push


def apply_receiving_space_quota(deployment_plan_rows, receiving_space, sim_date, demand_priority_map):
    """
    åœ¨æ‰€æœ‰è°ƒè¿è®¡åˆ’æ˜ç»†ç”Ÿæˆåï¼ŒæŒ‰receiving space quotaå†åˆ†é…ï¼Œæ›´æ–°deployed_qtyï¼Œunfulfilled log
    """
    df = pd.DataFrame(deployment_plan_rows)
    if df.empty:
        df['deployed_qty'] = []
        df['quota'] = []
        return df, []
    
    # å¦‚æœreceiving_spaceé…ç½®ä¸ºç©ºï¼Œç›´æ¥è¿”å›åŸåˆ†é…ç»“æœ
    if receiving_space.empty:
        df['deployed_qty'] = df['deployed_qty_invCon']
        df['quota'] = np.inf
        return df, []
    
    # æŒ‰receiving+dateåˆ†ç»„
    unfulfilled = []
    for (recv, date), grp in df.groupby(['receiving', 'date']):
        quota_row = receiving_space[
            (receiving_space['receiving'] == recv) & (pd.to_datetime(receiving_space['date']) == date)
        ]
        quota = quota_row['max_qty'].iloc[0] if not quota_row.empty else np.inf
        if grp['deployed_qty_invCon'].sum() <= quota:
            df.loc[grp.index, 'deployed_qty'] = grp['deployed_qty_invCon']
            df.loc[grp.index, 'quota'] = quota
            continue
        # ç©ºé—´ä¸è¶³ï¼ŒæŒ‰ä¼˜å…ˆçº§+æƒé‡åˆ†é…
        rows = grp.to_dict(orient='records')
        total = sum(r['deployed_qty_invCon'] for r in rows)
        # æŒ‰ä¼˜å…ˆçº§
        rows_sorted = sorted(rows, key=lambda r: demand_priority_map.get(r['demand_element'], 99))
        grouped = {}
        for r in rows_sorted:
            p = demand_priority_map.get(r['demand_element'], 99)
            grouped.setdefault(p, []).append(r)
        left = quota
        deploy_qtys = {i: 0 for i in range(len(rows))}
        for priority in sorted(grouped):
            group = grouped[priority]
            group_total = sum(r['deployed_qty_invCon'] for r in group)
            if left >= group_total:
                for r in group:
                    idx = rows.index(r)
                    deploy_qtys[idx] = r['deployed_qty_invCon']
                left -= group_total
            else:
                allocated = 0
                for r in group:
                    idx = rows.index(r)
                    weight = r['deployed_qty_invCon'] / group_total if group_total > 0 else 0
                    q = int(left * weight)
                    deploy_qtys[idx] = min(q, r['deployed_qty_invCon'])
                    allocated += deploy_qtys[idx]
                left -= allocated
                # ä¸å†åˆ†é…
        # æ›´æ–°å®é™…åˆ†é…
        for idx, qty in deploy_qtys.items():
            i = grp.index[idx]
            df.at[i, 'deployed_qty'] = qty
            df.at[i, 'quota'] = quota
            gap = rows[idx]['deployed_qty_invCon'] - qty
            if gap > 0:
                unfulfilled.append({
                    'date': date,
                    'sending': rows[idx]['sending'],
                    'receiving': rows[idx]['receiving'],
                    'demand_qty': rows[idx]['demand_qty'],
                    'demand_element': rows[idx]['demand_element'],
                    'unfulfilled_qty': gap,
                    'reason': "space constraint"
                })
    # ç©ºé—´å……è¶³è¡Œ
    df['deployed_qty'] = df['deployed_qty'].fillna(df['deployed_qty_invCon'])
    df['quota'] = df['quota'].fillna(np.nan)
    return df, unfulfilled

def log_outputs(output_path: str, outputs: Dict[str, pd.DataFrame]):
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        for sheet, df in outputs.items():
            if df.empty:
                # è¾“å‡ºç©ºè¡¨å¤´
                pd.DataFrame(columns=df.columns).to_excel(writer, sheet_name=sheet, index=False)
            else:
                df.to_excel(writer, sheet_name=sheet, index=False)

# ============ 2. ä¸»æµç¨‹ ===============

def main(
    input_path: str = None, 
    output_path: str = None, 
    sim_start: str = None, 
    sim_end: str = None,
    # æ–°å¢å‚æ•°æ”¯æŒé›†æˆæ¨¡å¼
    config_dict: dict = None,
    module1_output_dir: str = None,
    module4_output_path: str = None,
    orchestrator: object = None,
    current_date: str = None
):
    """
    Module 5: å¤šå±‚çº§éƒ¨ç½²è§„åˆ’æ¨¡å—
    
    æ”¯æŒä¸¤ç§è¿è¡Œæ¨¡å¼:
    1. ç‹¬ç«‹æ¨¡å¼: ä¼ å…¥input_path, output_path, sim_start, sim_end
    2. é›†æˆæ¨¡å¼: ä¼ å…¥config_dict, module1_output_dir, module4_output_path, orchestrator, current_date
    
    Args:
        # ç‹¬ç«‹æ¨¡å¼å‚æ•°
        input_path: è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ 
        sim_start: ä»¿çœŸå¼€å§‹æ—¥æœŸ
        sim_end: ä»¿çœŸç»“æŸæ—¥æœŸ
        
        # é›†æˆæ¨¡å¼å‚æ•°
        config_dict: é…ç½®æ•°æ®å­—å…¸
        module1_output_dir: Module1è¾“å‡ºç›®å½•
        module4_output_path: Module4è¾“å‡ºæ–‡ä»¶è·¯å¾„
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ(å•æ—¥è¿è¡Œæ—¶)
    """
    # åˆ¤æ–­è¿è¡Œæ¨¡å¼
    if config_dict is not None:
        # é›†æˆæ¨¡å¼ - å®Œæˆçš„é›†æˆæ•°æ®åŠ è½½
        print("\nğŸ”„ Module5 è¿è¡Œäºé›†æˆæ¨¡å¼")
        current_date_obj = pd.to_datetime(current_date) if current_date else None
        config = load_integrated_config(
            config_dict, module1_output_dir, module4_output_path, 
            orchestrator, current_date_obj
        )
        sim_dates = [current_date_obj] if current_date_obj else pd.date_range(sim_start, sim_end, freq='D')
        
        # é›†æˆæ¨¡å¼è¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = f"./Module5Output_{current_date_obj.strftime('%Y%m%d')}.xlsx" if current_date_obj else "./Module5Output.xlsx"
    else:
        # ç‹¬ç«‹æ¨¡å¼ - ä¿æŒå¾€åå…¼å®¹
        print("\nğŸ“œ Module5 è¿è¡Œäºç‹¬ç«‹æ¨¡å¼") 
        config = load_config(input_path)
        sim_dates = pd.date_range(sim_start, sim_end, freq='D')
    
    # ç»§ç»­åŸæœ‰é€»è¾‘æµç¨‹
    validation_log = list(config.get('ValidationLog', []))
    validate_config_before_run(config, validation_log)

    network = config['Network']
    deploy_cfg = config['DeployConfig']
    inventory_log = config['InventoryLog']
    production_plan = config['ProductionPlan']
    in_transit = config['InTransit']
    demand_priority = config['DemandPriority']
    receiving_space = config['ReceivingSpace']

    network_layers = assign_network_layers(network)
    location_to_layer = dict(zip(network_layers['location'], network_layers['layer']))
    layer_list = sorted(network_layers['layer'].unique())

    demand_priority_map = {row['demand_element']: row['priority'] for _, row in demand_priority.iterrows()}

    # ========== åˆå§‹åŒ–åº“å­˜ soh_dict ==========

    # 1. å…¨æ”¶é›†æ‰€æœ‰material/location
    all_mats = set(config['SupplyDemandLog']['material'].unique()) | \
            set(config['SafetyStock']['material'].unique())
    all_locs = set(config['SupplyDemandLog']['location'].unique()) | \
            set(config['SafetyStock']['location'].unique())

    # 2. ç¡®å®šä»¿çœŸå¼€å§‹æ—¥æœŸå¹¶è·å–å½“å¤©çš„åº“å­˜
    # é›†æˆæ¨¡å¼ä¸‹ä½¿ç”¨ç¬¬ä¸€ä¸ªä»¿çœŸæ—¥æœŸï¼Œç‹¬ç«‹æ¨¡å¼ä¸‹ä½¿ç”¨sim_startå‚æ•°
    actual_sim_start = sim_dates[0] if isinstance(sim_dates, list) and len(sim_dates) > 0 else sim_start
    
    inv_df = inventory_log[inventory_log['date'] == actual_sim_start]
    if inv_df.empty:
        print(f"[WARN] No inventory records found for sim_start: {actual_sim_start}")

    # 3. æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤è®°å½•
    duplicates = inv_df.duplicated(subset=['material', 'location'], keep=False)
    if duplicates.any():
        dup_rows = inv_df[duplicates]
        raise ValueError(f"InventoryLog contains duplicate (material, location) on sim_start {sim_start}:\n{dup_rows[['material', 'location', 'date']]}")

    # 4. åˆå§‹åŒ–soh_dictï¼Œé»˜è®¤0
    soh_dict = {}
    for mat in all_mats:
        for loc in all_locs:
            soh_dict[(mat, loc)] = 0  # é»˜è®¤0

    for _, row in inv_df.iterrows():
        soh_dict[(row['material'], row['location'])] = int(row['quantity'])


    deployment_plan_rows = []
    unfulfilled_rows = []
    stock_on_hand_log = []

    up_gap_buffer = {}

    for sim_date in sim_dates:
        # === ä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º ===
        print(f"\n{'='*60}")
        print(f"ğŸ“… ä»¿çœŸæ—¥æœŸ: {sim_date.strftime('%Y-%m-%d')}")
        print(f"{'='*60}")

        # ===== åº“å­˜è®¡ç®—é€»è¾‘é‡æ„ (ä¸Module3ä¿æŒä¸€è‡´) =====
        # ç›®æ ‡å…¬å¼: available_inventory = 
        #   unrestricted_inventory +        # ä»orchestratorè·å–å½“æ—¥æ— é™åˆ¶åº“å­˜
        #   in_transit +                   # ä»orchestratorè·å–å½“æ—¥åœ¨é€”åº“å­˜
        #   delivery_gr +                  # ä»orchestratorè·å–å½“æ—¥æ”¶è´§æ•°æ®
        #   today_production +             # ä»Module4è·å–å½“æ—¥ç”Ÿäº§ (available_date = today)
        #   future_production +            # ä»Module4è·å–æœªæ¥ç”Ÿäº§ (available_date > today)  
        #   - today_shipment -             # ä»Module1è·å–å½“æ—¥å‘è´§æ•°æ®
        #   - open_deployment              # ä»orchestratorè·å–å¼€æ”¾è°ƒæ‹¨æ•°æ®
        
        start_soh_dict = soh_dict.copy()
        
        # ä» Module4 è·å–å½“æ—¥å’Œæœªæ¥ç”Ÿäº§
        today_production_gr = {}
        future_production = {}
        if not production_plan.empty:
            # å½“æ—¥ç”Ÿäº§ (available_date = today)
            today_prod = production_plan[production_plan['available_date'] == sim_date]
            for _, row in today_prod.iterrows():
                k = (row['material'], row['location'])
                today_production_gr[k] = today_production_gr.get(k, 0) + int(row.get('produced_qty', row.get('planned_qty', 0)))
            
            # æœªæ¥ç”Ÿäº§ (available_date > today)
            future_prod = production_plan[production_plan['available_date'] > sim_date]
            for _, row in future_prod.iterrows():
                k = (row['material'], row['location'])
                future_production[k] = future_production.get(k, 0) + int(row.get('produced_qty', row.get('planned_qty', 0)))
        
        # ä» Orchestrator è·å–åœ¨é€”åº“å­˜
        today_intransit = {}
        if not in_transit.empty:
            for _, row in in_transit[in_transit['available_date'] == sim_date].iterrows():
                k = (row['material'], row['receiving'])
                today_intransit[k] = today_intransit.get(k, 0) + int(row['quantity'])
        
        # åŠ è½½å½“æ—¥æ”¶è´§ã€å‘è´§å’Œå¼€æ”¾è°ƒæ‹¨æ•°æ®
        delivery_gr_data = config.get('DeliveryGR', pd.DataFrame())
        today_shipment_data = config.get('TodayShipment', pd.DataFrame())
        open_deployment_data = config.get('OpenDeployment', pd.DataFrame())
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        delivery_gr = {}
        if not delivery_gr_data.empty:
            filtered_delivery = delivery_gr_data[pd.to_datetime(delivery_gr_data['date']) == sim_date] if 'date' in delivery_gr_data.columns else delivery_gr_data
            for _, row in filtered_delivery.iterrows():
                k = (row['material'], row['receiving'])
                delivery_gr[k] = delivery_gr.get(k, 0) + int(row['quantity'])
        
        today_shipment = {}
        if not today_shipment_data.empty:
            filtered_shipment = today_shipment_data[pd.to_datetime(today_shipment_data['date']) == sim_date] if 'date' in today_shipment_data.columns else today_shipment_data
            for _, row in filtered_shipment.iterrows():
                k = (row['material'], row['location'])
                today_shipment[k] = today_shipment.get(k, 0) + int(row['quantity'])
        
        open_deployment = {}
        if not open_deployment_data.empty:
            for _, row in open_deployment_data.iterrows():
                k = (row['material'], row['sending'])
                open_deployment[k] = open_deployment.get(k, 0) + int(row['quantity'])
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å¤šç»´åº¦åº“å­˜è®¡ç®—å…¬å¼
        unrestricted_inventory = start_soh_dict  # åŸºç¡€åº“å­˜
        
        dynamic_soh = calculate_available_inventory(
            unrestricted_inventory=unrestricted_inventory,
            in_transit=today_intransit, 
            delivery_gr=delivery_gr,
            today_production_gr=today_production_gr,
            future_production=future_production,
            today_shipment=today_shipment,
            open_deployment=open_deployment
        )
        up_gap_next = {}

        for layer in layer_list:
            print(f"\nğŸ“¦ å¤„ç†å±‚çº§ {layer}")
            print(f"{'-'*40}")
            
            # ç»„åˆæ‰€æœ‰material-locationå¯¹
            base_pairs = set(
                (mat, loc)
                for loc, l in location_to_layer.items() if l == layer
                for mat in config['SupplyDemandLog']['material'].unique()
            )
            # gap bufferè¡¥å……
            gap_pairs = set(
                (mat, loc)
                for (mat, loc) in up_gap_buffer
                if location_to_layer.get(loc, None) == layer
            )
            all_pairs = base_pairs | gap_pairs
            
            for mat, loc in all_pairs:
                node_key = (mat, loc)
                current_stock = dynamic_soh.get(node_key, 0)
                print(f"ğŸ“ èŠ‚ç‚¹: {mat}@{loc} [å½“å‰åº“å­˜: {current_stock}]")
                
                demand_rows = collect_node_demands(mat, loc, sim_date, config, up_gap_buffer)
                if not demand_rows:
                    print(f"   âš ï¸  æ— éœ€æ±‚éœ€è¦å¤„ç†")
                    continue
                
                demand_types = [d['demand_element'] for d in demand_rows]
                print(f"   ğŸ“‹ éœ€æ±‚ç±»å‹: {', '.join(demand_types)}")
                
                # åº”ç”¨MOQ/RVè§„åˆ™
                for d in demand_rows:
                    d['planned_qty'] = apply_moq_rv(d['demand_qty'], d['moq'], d['rv'])

                # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„å¤„ç†
                demand_rows_sorted = sorted(demand_rows, key=lambda d: demand_priority_map.get(d['demand_element'], 99))
                grouped = {}
                for d in demand_rows_sorted:
                    p = demand_priority_map.get(d['demand_element'], 99)
                    grouped.setdefault(p, []).append(d)
                
                total_demand = sum(d['planned_qty'] for d in demand_rows)
                print(f"   ğŸ“Š æ€»éœ€æ±‚: {total_demand}, å¯ç”¨åº“å­˜: {current_stock}")
                
                for priority in sorted(grouped):
                    group = grouped[priority]
                    group_demand = sum(d['planned_qty'] for d in group)
                    print(f"   ğŸ”¢ ä¼˜å…ˆçº§ {priority}: éœ€æ±‚ {group_demand}")
                    
                    # å¦‚æœæ²¡æœ‰å‰©ä½™åº“å­˜ï¼Œæ‰€æœ‰åç»­ä¼˜å…ˆçº§éƒ½åˆ†é…0
                    if current_stock <= 0:
                        for d in group:
                            d['deployed_qty_invCon'] = 0
                        print(f"      âŒ æ— å‰©ä½™åº“å­˜ï¼Œè·³è¿‡")
                        continue
                    
                    if group_demand == 0:
                        for d in group:
                            d['deployed_qty_invCon'] = 0
                        continue
                    
                    if current_stock >= group_demand:
                        # åº“å­˜å……è¶³ï¼Œå®Œå…¨æ»¡è¶³å½“å‰ä¼˜å…ˆçº§
                        for d in group:
                            d['deployed_qty_invCon'] = d['planned_qty']
                        current_stock -= group_demand
                        print(f"      âœ… åº“å­˜å……è¶³ï¼Œå®Œå…¨æ»¡è¶³")
                    else:
                        # åº“å­˜ä¸è¶³ï¼ŒæŒ‰æƒé‡åˆ†é…æ‰€æœ‰å‰©ä½™åº“å­˜ç»™å½“å‰ä¼˜å…ˆçº§
                        # å…³é”®ä¿®å¤ï¼šç”¨å®Œåº“å­˜åï¼Œåç»­ä¼˜å…ˆçº§ä¸å†åˆ†é…
                        allocated = 0
                        for d in group:
                            weight = d['planned_qty'] / group_demand if group_demand > 0 else 0
                            d['deployed_qty_invCon'] = int(current_stock * weight)
                            allocated += d['deployed_qty_invCon']
                        # ç¡®ä¿åˆ†é…ä¸è¶…è¿‡è®¡åˆ’é‡
                        for d in group:
                            d['deployed_qty_invCon'] = min(d['deployed_qty_invCon'], d['planned_qty'])
                        
                        # é‡æ–°è®¡ç®—å®é™…åˆ†é…é‡
                        actual_allocated = sum(d['deployed_qty_invCon'] for d in group)
                        current_stock = 0  # å…³é”®ä¿®å¤ï¼šåº“å­˜ä¸è¶³æ—¶ï¼Œç”¨å®Œæ‰€æœ‰åº“å­˜ï¼Œåç»­ä¼˜å…ˆçº§ä¸å†åˆ†é…
                        print(f"      âš ï¸  åº“å­˜ä¸è¶³ï¼Œéƒ¨åˆ†æ»¡è¶³ {actual_allocated}/{group_demand}ï¼Œåç»­ä¼˜å…ˆçº§ä¸å†åˆ†é…")
                        
                        # ä¸ºåç»­ä¼˜å…ˆçº§é¢„è®¾0åˆ†é…
                        remaining_priorities = [p for p in sorted(grouped) if p > priority]
                        for remaining_priority in remaining_priorities:
                            for d in grouped[remaining_priority]:
                                d['deployed_qty_invCon'] = 0
                        break  # è·³å‡ºä¼˜å…ˆçº§å¾ªç¯
                    
                    # æ˜¾ç¤ºåˆ†é…è¯¦æƒ…
                    for d in group:
                        status = "âœ…" if d['deployed_qty_invCon'] == d['planned_qty'] else "âš ï¸"
                        print(f"      {status} [{d['demand_element']}] è®¡åˆ’={d['planned_qty']} åˆ†é…={d['deployed_qty_invCon']} åŸå§‹ä½ç½®={d.get('orig_location', loc)}")

                # å¤„ç†GAPå’Œç”Ÿæˆè°ƒæ‹¨è®¡åˆ’
                gap_count = 0
                for d in demand_rows:
                    gap_qty = d['planned_qty'] - d['deployed_qty_invCon']
                    if gap_qty > 0:
                        up_loc = get_upstream(loc, mat, network, sim_date)
                        gap_count += 1
                        
                        if up_loc:
                            new_demand_element = f"net demand for {d['demand_element']}"
                            up_gap_next.setdefault((mat, up_loc), []).append({
                                'demand_element': new_demand_element,
                                'planned_qty': gap_qty,
                                'leadtime': d['leadtime'],
                                'requirement_date': d.get('requirement_date', d['plan_deploy_date']),
                                'location': up_loc,
                                'from_location': loc,
                                'orig_location': d.get('orig_location', d['location'])
                            })
                        
                        unfulfilled_rows.append({
                            'date': d['plan_deploy_date'],
                            'sending': loc,
                            'receiving': d.get('from_location', d.get('receiving', loc)),
                            'demand_qty': d['demand_qty'],
                            'demand_element': d['demand_element'],
                            'unfulfilled_qty': gap_qty,
                            'reason': "supply shortage"
                        })
                        
                        print(f"      ğŸ”¼ éœ€æ±‚ç¼ºå£: {gap_qty} [{d['demand_element']}] â†’ ä¸Šæ¸¸ {up_loc}")
                
                if gap_count == 0:
                    print(f"      ğŸŸ¢ æ— éœ€æ±‚ç¼ºå£")
                
                # ç”Ÿæˆè°ƒæ‹¨è®¡åˆ’è¡Œ
                for d in demand_rows:
                    receiving = d.get('from_location', d.get('receiving', loc))
                    
                    # è‡ªè¡¥è´§ï¼ˆsending == receivingï¼‰ä¸åº”æœ‰leadtime
                    if loc == receiving:
                        planned_delivery_date = d['plan_deploy_date']  # æœ¬åœ°åˆ†é…æ— éœ€leadtime
                    else:
                        planned_delivery_date = d.get('requirement_date', d['plan_deploy_date'])  # è·¨å±‚çº§è°ƒæ‹¨ä½¿ç”¨requirement_date
                    
                    plan_row = {
                        'date': d['plan_deploy_date'],
                        'material': mat,
                        'sending': loc,
                        'receiving': receiving,
                        'demand_qty': d['demand_qty'],
                        'demand_element': d['demand_element'],
                        'planned_qty': d['planned_qty'],
                        'deployed_qty_invCon': d['deployed_qty_invCon'],
                        'planned_delivery_date': planned_delivery_date,
                        'orig_location': d.get('orig_location', d['location'])
                    }
                    deployment_plan_rows.append(plan_row)

            print(f"\nâœ… å±‚çº§ {layer} å¤„ç†å®Œæˆï¼Œå‘ä¸Šæ¸¸ä¼ é€’ {sum(len(v) for v in up_gap_next.values())} ä¸ªéœ€æ±‚ç¼ºå£")

            # æ›´æ–°GAPç¼“å†²åŒº
            up_gap_buffer = up_gap_next.copy()
        
        # push/soft-pushå†åˆ†é…
        plan_push = push_softpush_allocation(deployment_plan_rows, config, dynamic_soh, sim_date)
        if plan_push:
            for plan in plan_push:
                plan['planned_delivery_date'] = plan['date']
            deployment_plan_rows.extend(plan_push)
            print(f"\nğŸ”„ Push/Soft-push è¡¥è´§: ç”Ÿæˆ {len(plan_push)} æ¡è¡¥è´§è®¡åˆ’")

        # æ›´æ–°åº“å­˜
        deployed_dict = {}
        df = pd.DataFrame(deployment_plan_rows)
        if not df.empty:
            today_rows = df[df['date'] == sim_date]
            for _, row in today_rows.iterrows():
                k = (row['material'], row['sending'])
                qty = row['deployed_qty_invCon'] if row['sending'] != row['receiving'] else 0
                deployed_dict[k] = deployed_dict.get(k, 0) + qty

        all_keys = set(list(start_soh_dict.keys()) +
                       list(today_production_gr.keys()) +
                       list(today_intransit.keys()) +
                       list(deployed_dict.keys()))
        
        for (mat, loc) in all_keys:
            start_soh = start_soh_dict.get((mat, loc), 0)
            prod = today_production_gr.get((mat, loc), 0)
            intrans = today_intransit.get((mat, loc), 0)
            deployed = deployed_dict.get((mat, loc), 0)
            end_soh = start_soh + prod + intrans - deployed
            soh_dict[(mat, loc)] = end_soh
            stock_on_hand_log.append({
                'material': mat,
                'location': loc,
                'date': sim_date,
                'start_soh': start_soh,
                'production': prod,
                'in_transit': intrans,
                'deployed_qty': deployed,
                'stock_on_hand': end_soh
            })
        
        print(f"\nğŸ“Š å½“æ—¥ç»Ÿè®¡:")
        print(f"   æ€»è°ƒæ‹¨è®¡åˆ’æ•°: {len(deployment_plan_rows)}")
        print(f"   æœªæ»¡è¶³éœ€æ±‚æ•°: {len([r for r in unfulfilled_rows if r['date'] == sim_date])}")

    # åº”ç”¨æ”¶è´§ç©ºé—´é…é¢
    deployment_plan_rows_df, unfulfilled_space = apply_receiving_space_quota(
        deployment_plan_rows, receiving_space, sim_date, demand_priority_map
    )
    unfulfilled_all = pd.DataFrame(unfulfilled_rows + unfulfilled_space)

    outputs = {
        'DeploymentPlan': deployment_plan_rows_df,
        'UnfulfilledLog': unfulfilled_all,
        'StockOnHandLog': pd.DataFrame(stock_on_hand_log),
        'Validation': pd.DataFrame(validation_log),
    }
    log_outputs(output_path, outputs)
    
    # é›†æˆæ¨¡å¼ï¼šå°†éƒ¨ç½²è®¡åˆ’å‘é€ç»™Orchestratorï¼ˆç”±ä¸»é›†æˆè„šæœ¬ç»Ÿä¸€å¤„ç†ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œæš‚æ—¶æ³¨é‡Šæ‰ç›´æ¥è°ƒç”¨ï¼Œäº¤ç”±ä¸»é›†æˆè„šæœ¬ç»Ÿä¸€å¤„ç†ä»¥é¿å…é‡å¤
    # if config_dict is not None and orchestrator is not None and not deployment_plan_rows_df.empty:
    #     try:
    #         # è¿‡æ»¤å‡ºæœ‰å®é™…éƒ¨ç½²é‡çš„è®¡åˆ’
    #         valid_deployment = deployment_plan_rows_df[
    #             (deployment_plan_rows_df['deployed_qty_invCon'] > 0) & 
    #             (deployment_plan_rows_df['deployed_qty_invCon'].notna())
    #         ].copy()
    #         
    #         if not valid_deployment.empty:
    #             # é‡å‘½ååˆ—ä»¥åŒ¹é…orchestratoræœŸæœ›çš„æ ¼å¼
    #             orchestrator_deployment = valid_deployment.rename(columns={
    #                 'date': 'planned_deployment_date',
    #                 'deployed_qty_invCon': 'deployed_qty'
    #             })[['material', 'sending', 'receiving', 'planned_deployment_date', 'deployed_qty', 'demand_element']]
    #             
    #             orchestrator.process_module5_deployment(orchestrator_deployment, current_date)
    #             print(f"âœ… å·²å‘Orchestratorå‘é€ {len(orchestrator_deployment)} æ¡éƒ¨ç½²è®¡åˆ’")
    #         else:
    #             print(f"â„¹ï¸  æ— æœ‰æ•ˆéƒ¨ç½²è®¡åˆ’å‘é€ç»™Orchestrator")
    #     except Exception as e:
    #         print(f"âš ï¸  Orchestratoré›†æˆå¤±è´¥: {str(e)}")
    #         print(f"Error type: {type(e).__name__}")
    #         print(f"Deployment plan columns: {list(deployment_plan_rows_df.columns)}")
    #         print(f"Deployment plan shape: {deployment_plan_rows_df.shape}")
    #         if not deployment_plan_rows_df.empty:
    #             print(f"Sample row: {deployment_plan_rows_df.iloc[0].to_dict()}")
    #         import traceback
    #         traceback.print_exc()
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ä»¿çœŸå®Œæˆ! æ‰€æœ‰å±‚çº§å·²å¤„ç†å®Œæ¯•")
    print(f"ğŸ’¾ è°ƒæ‹¨è®¡åˆ’å·²ä¿å­˜è‡³: {output_path}")
    print(f"ğŸ“ˆ æ€»è°ƒæ‹¨è®¡åˆ’æ•°: {len(deployment_plan_rows_df)}")
    print(f"ğŸ“ æœªæ»¡è¶³éœ€æ±‚æ•°: {len(unfulfilled_all)}")
    print(f"{'='*60}")
    
    # è¿”å›ç»“æœç”¨äºé›†æˆæ¨¡å¼
    return {
        'deployment_plan': deployment_plan_rows_df,
        'unfulfilled_log': unfulfilled_all,
        'stock_on_hand_log': pd.DataFrame(stock_on_hand_log),
        'validation_log': pd.DataFrame(validation_log),
        'statistics': {
            'deployment_count': len(deployment_plan_rows_df),
            'unfulfilled_count': len(unfulfilled_all),
            'processed_dates': len(sim_dates) if isinstance(sim_dates, list) else 1
        }
    }

# è¾…åŠ©å‡½æ•°ï¼ˆå¦‚assign_network_layersã€collect_node_demandsç­‰ï¼‰è¯·æŒ‰ä½ å½“å‰æœ€æ–°ç‰ˆç²˜è´´åœ¨åŒä¸€ä¸ªæ–‡ä»¶
# get_upstreaméœ€è¦sim_dateå‚æ•°
def get_upstream(location, material, network_df, sim_date):
    row = get_active_network(network_df, material, location, sim_date)
    if not row.empty:
        return row.iloc[0]['sourcing']
    return None

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='Module 5: Multi-echelon Deployment Planning')
    parser.add_argument('--input', required=True, help='Input config excel path')
    parser.add_argument('--output', required=True, help='Output excel path')
    parser.add_argument('--sim_start', required=True, help='Simulation start date, YYYY-MM-DD')
    parser.add_argument('--sim_end', required=True, help='Simulation end date, YYYY-MM-DD')
    args = parser.parse_args()
    main(args.input, args.output, args.sim_start, args.sim_end)
