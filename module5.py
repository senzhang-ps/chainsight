#module 5
import pandas as pd
import numpy as np
import os
from datetime import timedelta
from typing import Dict, List

# ========= é›†æˆæ•°æ®åŠ è½½å‡½æ•° (æ–°å¢) =========

def _normalize_location(location_str) -> str:
    """Normalize location string by padding with leading zeros to 4 digits"""
    try:
        return str(int(location_str)).zfill(4)
    except (ValueError, TypeError):
        return str(location_str).zfill(4)

def _normalize_material(material_str) -> str:
    """Normalize material string"""
    return str(material_str) if material_str is not None else ""

def _normalize_identifiers(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize identifier columns to string format with proper formatting"""
    if df.empty:
        return df
    
    # Define identifier columns that need string conversion
    identifier_cols = ['material', 'location', 'sending', 'receiving', 'sourcing']
    
    df = df.copy()
    for col in identifier_cols:
        if col in df.columns:
            # Convert to string and handle NaN values
            df[col] = df[col].astype('string')
            # Apply specific normalization for location-type fields
            if col in ['location', 'sending', 'receiving', 'sourcing']:
                df[col] = df[col].apply(_normalize_location)
            # Apply specific normalization for material
            elif col == 'material':
                df[col] = df[col].apply(_normalize_material)
            # For other identifier columns, ensure they are properly formatted strings
            else:
                df[col] = df[col].apply(lambda x: str(x) if pd.notna(x) else "")
    
    return df

def load_module1_daily_shipment(module1_output_dir: str, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»Module1è¾“å‡ºåŠ è½½å½“æ—¥å‘è´§æ•°æ®
    
    Args:
        module1_output_dir: Module1è¾“å‡ºç›®å½•
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å½“æ—¥å‘è´§æ•°æ® [date, material, location, quantity]
    """
    try:
        date_str = current_date.strftime('%Y%m%d')
        module1_file = f"{module1_output_dir}/module1_output_{date_str}.xlsx"
        
        if os.path.exists(module1_file):
            xl = pd.ExcelFile(module1_file)
            if 'ShipmentLog' in xl.sheet_names:
                shipment_df = xl.parse('ShipmentLog')
                # ç¡®ä¿åŒ…å«éœ€è¦çš„åˆ—
                required_cols = ['date', 'material', 'location', 'quantity']
                if all(col in shipment_df.columns for col in required_cols):
                    result_df = shipment_df[required_cols].copy()
                    # ç¡®ä¿æ ‡è¯†ç¬¦å­—æ®µä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    return _normalize_identifiers(result_df)
                else:
                    print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {module1_file}")
            else:
                print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ä¸­æ— ShipmentLogè¡¨: {module1_file}")
        else:
            print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {module1_file}")
    except Exception as e:
        print(f"âš ï¸  åŠ è½½Module1å‘è´§æ•°æ®å¤±è´¥: {e}")
    
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame(columns=['date', 'material', 'location', 'quantity'])

def load_module1_daily_orders(module1_output_dir: str, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»Module1è¾“å‡ºåŠ è½½"å½“æ—¥ç‰ˆæœ¬"çš„è®¢å•æ—¥å¿—ï¼ˆåŒ…å«å†å²å¤©ç”Ÿæˆä½†å°šæœªæ¥åˆ°æœŸçš„è®¢å• + å½“å¤©æ–°ç”Ÿæˆï¼‰
    ä»…æŒ‰ requirement_date>=current_date è¿‡æ»¤ï¼Œä¸æŒ‰ simulation_date è¿‡æ»¤
    è¿”å›åˆ—: [date, material, location, demand_type, quantity, simulation_date]
    """
    cols = ['date', 'material', 'location', 'demand_type', 'quantity', 'simulation_date']
    try:
        date_str = current_date.strftime('%Y%m%d')
        module1_file = f"{module1_output_dir}/module1_output_{date_str}.xlsx"
        if not os.path.exists(module1_file):
            print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {module1_file}")
            return pd.DataFrame(columns=cols)

        xl = pd.ExcelFile(module1_file)
        if 'OrderLog' not in xl.sheet_names:
            print(f"âš ï¸  Module1è¾“å‡ºæ–‡ä»¶ä¸­æ— OrderLogè¡¨: {module1_file}")
            return pd.DataFrame(columns=cols)

        df = xl.parse('OrderLog')
        for c in ['date', 'simulation_date']:
            if c in df.columns:
                df[c] = pd.to_datetime(df[c])
        # åªä¿ç•™ requirement_date(=date) >= today çš„è®¢å•è¡Œ
        if 'date' in df.columns:
            df = df[df['date'] >= current_date]

        # è§„èŒƒåˆ—
        for c in cols:
            if c not in df.columns:
                df[c] = pd.NaT if c in ['date','simulation_date'] else np.nan
        result_df = df[cols].copy()
        # ç¡®ä¿æ ‡è¯†ç¬¦å­—æ®µä¸ºå­—ç¬¦ä¸²æ ¼å¼
        return _normalize_identifiers(result_df)

    except Exception as e:
        print(f"âš ï¸  åŠ è½½Module1è®¢å•æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame(columns=cols)

def load_orchestrator_delivery_gr(orchestrator: object, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»OrchestratoråŠ è½½å½“æ—¥æ”¶è´§æ•°æ®
    
    Args:
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å½“æ—¥æ”¶è´§æ•°æ® [date, material, receiving, quantity]
    """
    try:
        date_str = current_date.strftime('%Y-%m-%d')
        delivery_gr_view = orchestrator.get_delivery_gr_view(date_str)
        
        if isinstance(delivery_gr_view, pd.DataFrame) and not delivery_gr_view.empty:
            # ç¡®ä¿åŒ…å«éœ€è¦çš„åˆ—
            required_cols = ['date', 'material', 'receiving', 'quantity']
            available_cols = delivery_gr_view.columns.tolist()
            
            # å°è¯•æ˜ å°„åˆ—åç§°
            col_mapping = {
                'location': 'receiving',  # location æ˜ å°„ä¸º receiving
                'gr_qty': 'quantity',     # gr_qty æ˜ å°„ä¸º quantity
                'received_qty': 'quantity'  # received_qty æ˜ å°„ä¸º quantity
            }
            
            # åº”ç”¨åˆ—æ˜ å°„
            renamed_df = delivery_gr_view.copy()
            for old_col, new_col in col_mapping.items():
                if old_col in renamed_df.columns:
                    renamed_df = renamed_df.rename(columns={old_col: new_col})
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in required_cols if col not in renamed_df.columns]
            if not missing_cols:
                result_df = renamed_df[required_cols].copy()
                # ç¡®ä¿æ ‡è¯†ç¬¦å­—æ®µä¸ºå­—ç¬¦ä¸²æ ¼å¼
                return _normalize_identifiers(result_df)
            else:
                print(f"âš ï¸  Orchestrator delivery_gr_viewç¼ºå°‘å­—æ®µ: {missing_cols}")
        else:
            print(f"âš ï¸  Orchestratorè¿”å›ç©ºçš„delivery_gr_view")
    except Exception as e:
        print(f"âš ï¸  ä»OrchestratoråŠ è½½æ”¶è´§æ•°æ®å¤±è´¥: {e}")
    
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame(columns=['date', 'material', 'receiving', 'quantity'])

def load_orchestrator_open_deployment(orchestrator: object, current_date: pd.Timestamp) -> pd.DataFrame:
    """
    ä»OrchestratoråŠ è½½å¼€æ”¾è°ƒæ‹¨æ•°æ®
    
    Args:
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        pd.DataFrame: å¼€æ”¾è°ƒæ‹¨æ•°æ® [material, sending, receiving, quantity]
    """
    try:
        date_str = current_date.strftime('%Y-%m-%d')
        open_deployment_view = orchestrator.get_open_deployment_view(date_str)
        
        if isinstance(open_deployment_view, pd.DataFrame) and not open_deployment_view.empty:
            # ç¡®ä¿åŒ…å«éœ€è¦çš„åˆ—ï¼ˆåŒ…æ‹¬receivingç”¨äºè‡ªå¾ªç¯æ£€æŸ¥ï¼‰
            required_cols = ['material', 'sending', 'receiving', 'quantity']
            available_cols = open_deployment_view.columns.tolist()
            
            # å°è¯•æ˜ å°„åˆ—åç§°
            col_mapping = {
                'location': 'sending',     # location æ˜ å°„ä¸º sending
                'deployed_qty': 'quantity',  # deployed_qty æ˜ å°„ä¸º quantity
                'planned_qty': 'quantity'    # planned_qty æ˜ å°„ä¸º quantity
            }
            
            # åº”ç”¨åˆ—æ˜ å°„
            renamed_df = open_deployment_view.copy()
            for old_col, new_col in col_mapping.items():
                if old_col in renamed_df.columns:
                    renamed_df = renamed_df.rename(columns={old_col: new_col})
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in required_cols if col not in renamed_df.columns]
            if not missing_cols:
                result_df = renamed_df[required_cols].copy()
                # ç¡®ä¿æ ‡è¯†ç¬¦å­—æ®µä¸ºå­—ç¬¦ä¸²æ ¼å¼
                return _normalize_identifiers(result_df)
            else:
                print(f"âš ï¸  Orchestrator open_deployment_viewç¼ºå°‘å­—æ®µ: {missing_cols}")
        else:
            print(f"âš ï¸  Orchestratorè¿”å›ç©ºçš„open_deployment_view")
    except Exception as e:
        print(f"âš ï¸  ä»OrchestratoråŠ è½½å¼€æ”¾è°ƒæ‹¨æ•°æ®å¤±è´¥: {e}")
    
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame(columns=['material', 'sending', 'receiving', 'quantity'])

def build_open_deployment_inbound(open_deployment_df: pd.DataFrame) -> dict[tuple[str, str], int]:
    """
    ä» open_deployment æ˜ç»†æ„é€  inbound è§†å›¾ï¼š
    - ç»´åº¦ï¼š (material, receiving)
    - è¿‡æ»¤ï¼šsending != receivingï¼ˆæ’é™¤è‡ªå¾ªç¯ï¼‰ï¼›deployed_qty/quantity > 0
    - æ±‡æ€»ï¼šsum(quantity)
    è¿”å›ï¼š{(material, receiving): qty}
    """
    if open_deployment_df is None or open_deployment_df.empty:
        return {}

    df = open_deployment_df.copy()
    # ç»Ÿä¸€æ•°é‡åˆ—å
    if 'quantity' not in df.columns and 'deployed_qty' in df.columns:
        df = df.rename(columns={'deployed_qty': 'quantity'})
    if 'quantity' not in df.columns:
        # å…œåº•ï¼šå¦‚æœå« planned_qty
        if 'planned_qty' in df.columns:
            df = df.rename(columns={'planned_qty': 'quantity'})
        else:
            return {}

    # è¿‡æ»¤ï¼šæ•°é‡>0ï¼Œä¸”éè‡ªå¾ªç¯
    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(0).astype(int)
    df = df[(df['quantity'] > 0) & (df['sending'] != df['receiving'])]

    # èšåˆï¼š (material, receiving)
    g = (df.groupby(['material', 'receiving'])['quantity']
           .sum().reset_index())

    inbound = { (row['material'], row['receiving']): int(row['quantity'])
                for _, row in g.iterrows() }
    return inbound

def calculate_projected_inventory(
    beginning_inventory: dict,
    in_transit: dict, 
    delivery_gr: dict,
    today_production_gr: dict,
    future_production: dict,
    today_shipment: dict,
    open_deployment: dict
) -> dict:
    """
    è®¡ç®—é¢„æµ‹åº“å­˜ï¼Œç”¨äºgapè®¡ç®—å’Œä¾›åº”é“¾è§„åˆ’
    
    Formula: projected_inventory = beginning_inventory + in_transit + delivery_gr + 
             today_production + future_production - today_shipment - open_deployment
    
    Args:
        å„ä¸ªåº“å­˜ç»´åº¦çš„å­—å…¸ï¼Œé”®ä¸º(material, location)ï¼Œå€¼ä¸ºæ•°é‡
        
    Returns:
        dict: é¢„æµ‹åº“å­˜å­—å…¸ {(material, location): quantity}
    """
    all_keys = set()
    for d in [beginning_inventory, in_transit, delivery_gr, today_production_gr, 
              future_production, today_shipment, open_deployment]:
        all_keys.update(d.keys())
    
    projected_inventory = {}
    for key in all_keys:
        projected_inventory[key] = (
            beginning_inventory.get(key, 0) +
            in_transit.get(key, 0) +
            delivery_gr.get(key, 0) +
            today_production_gr.get(key, 0) +
            future_production.get(key, 0) -
            today_shipment.get(key, 0) -
            open_deployment.get(key, 0)
        )
    
    return projected_inventory

def calculate_available_inventory(
    beginning_inventory: dict,
    delivery_gr: dict,
    today_production_gr: dict,
    today_shipment: dict,
    open_deployment: dict,
    open_deployment_inbound: dict
) -> dict:
    """
    è®¡ç®—å½“æ—¥çœŸå®å¯ç”¨åº“å­˜ï¼ˆdynamic_sohï¼‰ï¼Œç”¨äºå®é™…åˆ†é…

    æ›´æ–°åçš„å…¬å¼ï¼š
    dynamic_soh = beginning + delivery_gr + today_production_gr - open_deployment + open_deployment_inbound

    å¤‡æ³¨ï¼š
    - ä¸åŒ…å« in_transitã€future_production
    - today_shipment ä¸åœ¨ dynamic_soh ä¸­æ‰£å‡ï¼ˆä¸åŸé€»è¾‘ä¸€è‡´ï¼›è‹¥ä½ å¸Œæœ›æ‰£å‡ï¼Œå¯åœ¨æ­¤å¤„æ¢å¤å‡é¡¹ï¼‰
    """
    all_keys = set()
    for d in [beginning_inventory, delivery_gr, today_production_gr,
              today_shipment, open_deployment, open_deployment_inbound]:
        all_keys.update(d.keys())

    soh = {}
    for key in all_keys:
        soh[key] = (
            beginning_inventory.get(key, 0) +
            delivery_gr.get(key, 0) +
            today_production_gr.get(key, 0) -
            # today_shipment.get(key, 0) -   # å¦‚éœ€æ‰£å‡å½“æ—¥å¯¹å®¢å‘è´§å¯æ”¾å¼€
            open_deployment.get(key, 0) +
            open_deployment_inbound.get(key, 0)
        )
    return soh

# ========= 1. é€šç”¨è¾…åŠ© =========

def get_upstream(location, material, network_df, sim_date):
    row = get_active_network(network_df, material, location, sim_date)
    if not row.empty:
        return row.iloc[0]['sourcing']
    return None

def apply_moq_rv(qty, moq, rv, is_cross_node=True):
    """
    è¡¥è´§é‡å°äºmoqè¡¥moqï¼Œå¦åˆ™å‘ä¸Šå–æ•´åˆ°rvçš„å€æ•°
    
    Args:
        qty: éœ€æ±‚æ•°é‡
        moq: æœ€å°è®¢è´§é‡
        rv: é‡è®¢é‡(Round Volume)
        is_cross_node: æ˜¯å¦ä¸ºè·¨èŠ‚ç‚¹è°ƒè¿ã€‚True=è·¨èŠ‚ç‚¹éœ€è¦åº”ç”¨MOQ/RVï¼ŒFalse=è‡ªå¾ªç¯ä¸åº”ç”¨MOQ/RV
    """
    if qty <= 0:
        return 0
    
    # ğŸ”§ ä¿®å¤ï¼šè‡ªå¾ªç¯è°ƒè¿ä¸åº”ç”¨MOQ/RVçº¦æŸï¼Œç›´æ¥è¿”å›åŸéœ€æ±‚é‡
    if not is_cross_node:
        return qty
    
    # è·¨èŠ‚ç‚¹è°ƒè¿åº”ç”¨MOQ/RVçº¦æŸ
    if qty < moq:
        return moq
    return int(np.ceil(qty / rv)) * rv

def apply_grouped_moq_rv(demand_rows, location):
    """
    æŒ‰è°ƒè¿è·¯å¾„åˆ†ç»„åº”ç”¨MOQ/RV
    
    Args:
        demand_rows: éœ€æ±‚è¡Œåˆ—è¡¨
        location: å½“å‰ä½ç½®ï¼ˆsendingï¼‰
        
    Returns:
        dict: è°ƒæ•´åçš„ demand_row_index -> adjusted_qty æ˜ å°„
    """
    # æŒ‰ (material, sending, receiving, demand_element) åˆ†ç»„
    route_groups = {}
    for i, d in enumerate(demand_rows):
        receiving = d.get('from_location', d.get('receiving', location))
        is_cross_node = (location != receiving)
        
        route_key = (d['material'], location, receiving, d['demand_element'])
        if route_key not in route_groups:
            route_groups[route_key] = {
                'items': [],
                'total_qty': 0,
                'is_cross_node': is_cross_node,
                'moq': d['moq'],
                'rv': d['rv']
            }
        
        route_groups[route_key]['items'].append((i, d))
        route_groups[route_key]['total_qty'] += d['demand_qty']
    
    # å¯¹æ¯ä¸ªè·¯å¾„ç»„åº”ç”¨MOQ/RV
    adjusted_qtys = {}
    
    for route_key, group in route_groups.items():
        material, sending, receiving, demand_element = route_key
        total_qty = group['total_qty']
        is_cross_node = group['is_cross_node']
        moq = group['moq']
        rv = group['rv']
        
        # å¯¹ç»„åˆåçš„æ€»é‡åº”ç”¨MOQ/RV
        adjusted_total = apply_moq_rv(total_qty, moq, rv, is_cross_node=is_cross_node)
        
        # print(f"      ğŸ“¦ è·¯å¾„ç»„ {sending}â†’{receiving} [{demand_element}]: åŸå§‹={total_qty} â†’ è°ƒæ•´={adjusted_total} (MOQ={moq}, è·¨èŠ‚ç‚¹={is_cross_node})")
        
        # å°†è°ƒæ•´åçš„æ€»é‡æŒ‰åŸå§‹æ¯”ä¾‹åˆ†é…å›å„ä¸ªéœ€æ±‚é¡¹
        if total_qty > 0:
            adjustment_ratio = adjusted_total / total_qty
        else:
            adjustment_ratio = 1.0
            
        for item_idx, item in group['items']:
            original_qty = item['demand_qty']
            adjusted_qty = int(original_qty * adjustment_ratio)
            adjusted_qtys[item_idx] = adjusted_qty
            
    return adjusted_qtys

def _get_ptf_lsk(material: str, site: str, m4_mlcfg_df: pd.DataFrame | None) -> tuple[int, int]:
    ptf, lsk = 0, 1
    if m4_mlcfg_df is None or m4_mlcfg_df.empty:
        return ptf, lsk
    ml = m4_mlcfg_df[
        (m4_mlcfg_df['material'] == material) &
        (m4_mlcfg_df['location'] == site)
    ]
    if ml.empty:
        return ptf, lsk
    row = ml.iloc[0]
    if 'ptf' in ml.columns and pd.notna(row.get('ptf')):
        ptf = int(row['ptf'])
    elif 'PTF' in ml.columns and pd.notna(row.get('PTF')):
        ptf = int(row['PTF'])
    if 'lsk' in ml.columns and pd.notna(row.get('lsk')):
        lsk = int(row['lsk'])
    elif 'LSK' in ml.columns and pd.notna(row.get('LSK')):
        lsk = int(row['LSK'])
    return ptf, lsk

def determine_lead_time(
    sending: str,
    receiving: str,
    location_type: str,
    lead_time_df: pd.DataFrame,
    m4_mlcfg_df: pd.DataFrame | None = None,   # â† æ–°å¢
    material: str | None = None                # â† æ–°å¢
) -> tuple[int, str]:
    """
    Plant: lead_time = max(MCT, PDT+GR) + PTF + LSK - 1
    DC:    lead_time = PDT + GR
    PTF/LSK æ¥æº: M4_MaterialLocationLineCfgï¼ˆæŒ‰ material+sending åŒ¹é…ï¼‰
    """
    if lead_time_df.empty:
        return 1, 'empty_lead_time_config'

    row = lead_time_df[
        (lead_time_df['sending'] == sending) &
        (lead_time_df['receiving'] == receiving)
    ]
    if row.empty:
        return 1, 'lead_time_missing'

    try:
        PDT = int(row.iloc[0].get('PDT', 0) or 0)
        GR  = int(row.iloc[0].get('GR',  0) or 0)
        MCT = int(row.iloc[0].get('MCT', 0) or 0)

        ptf, lsk = 0, 1
        if str(location_type).lower() == 'plant' and material is not None:
            # ä¸ M3 å¯¹é½ï¼šæŒ‰ (material, sending) å– PTF/LSK
            ptf, lsk = _get_ptf_lsk(material=material, site=sending, m4_mlcfg_df=m4_mlcfg_df)

        if str(location_type).lower() == 'plant':
            base_lt  = max(MCT, PDT + GR)
            leadtime = base_lt + ptf + lsk - 1
        else:
            leadtime = PDT + GR

        return max(1, int(leadtime)), ""

    except Exception as e:
        return 1, f'lead_time_calculation_error: {str(e)}'

def get_sending_location_type(
    material: str,
    sending: str,
    sim_date: pd.Timestamp,
    network_df: pd.DataFrame,
    location_layer_map: dict
) -> str:
    """
    ä¸ Module3 ä¸€è‡´çš„å£å¾„ï¼š
    1) å…ˆæŸ¥ network ä¸­ (material, location=sending) æ´»åŠ¨è¡Œï¼Œè‹¥å­˜åœ¨åˆ™ç”¨å…¶ location_type
    2) è‹¥ä¸å­˜åœ¨ä¸” sending æ˜¯è‡ªåŠ¨è¯†åˆ«çš„æœ€ä¸Šæ¸¸ï¼ˆlayer=0ï¼‰ï¼Œåˆ™è§†ä¸º Plant
    3) å¦åˆ™é»˜è®¤ DC
    """
    if not sending or pd.isna(sending) or str(sending).strip() == "":
        return 'DC'

    row = get_active_network(network_df, material, sending, sim_date)
    if not row.empty:
        return str(row.iloc[0].get('location_type', 'DC') or 'DC')

    # æœªç»´æŠ¤ä½†è¢«è‡ªåŠ¨è¯†åˆ«ä¸ºæ ¹èŠ‚ç‚¹ â†’ Plant
    if location_layer_map.get(str(sending), None) == 0:
        return 'Plant'

    return 'DC'

# === ç”¨ module3 çš„ç‰ˆæœ¬æ›¿æ¢ ===
def assign_location_layers(network_df: pd.DataFrame) -> pd.DataFrame:
    from collections import defaultdict, deque
    if network_df.empty:
        return pd.DataFrame({'location': [], 'layer': []})

    children = defaultdict(list)
    parents = defaultdict(list)
    for _, row in network_df.iterrows():
        sourcing_val = row['sourcing']
        location_val = row['location']
        sourcing_valid = sourcing_val is not None and pd.notna(sourcing_val) and str(sourcing_val).strip() != ''
        location_valid = location_val is not None and pd.notna(location_val) and str(location_val).strip() != ''
        if sourcing_valid and location_valid:
            children[sourcing_val].append(location_val)
            parents[location_val].append(sourcing_val)

    all_locations = set(network_df['location'].dropna()).union(set(network_df['sourcing'].dropna()))
    potential_roots = [loc for loc in all_locations if not parents[loc]]

    true_roots = []
    for loc in potential_roots:
        if loc in children:
            true_roots.append(loc)
        else:
            has_incoming = any(loc in parents.get(other_loc, []) for other_loc in all_locations)
            if not has_incoming:
                true_roots.append(loc)
    if not true_roots:
        true_roots = potential_roots

    layer_dict = {}
    from collections import deque
    queue = deque()
    for root in true_roots:
        queue.append((root, 0))
    while queue:
        loc, layer = queue.popleft()
        if loc in layer_dict and layer_dict[loc] <= layer:
            continue
        layer_dict[loc] = layer
        for child in children.get(loc, []):
            queue.append((child, layer + 1))

    unassigned = [loc for loc in all_locations if loc not in layer_dict]
    if unassigned:
        max_layer = max(layer_dict.values()) if layer_dict else 0
        for loc in unassigned:
            layer_dict[loc] = max_layer + 1

    layer_df = pd.DataFrame([{'location': loc, 'layer': layer} for loc, layer in layer_dict.items()])
    layer_df = layer_df.sort_values('layer')
    return layer_df

def get_active_network(network_df, material, location, sim_date):
    rows = network_df[
        (network_df['material'] == material) &
        (network_df['location'] == location) &
        (network_df['eff_from'] <= sim_date) &
        (network_df['eff_to'] >= sim_date)
    ]
    return rows

def is_review_day(dt, lsk, day):
    if lsk == 'daily':
        return True
    if lsk == 'weekly':
        return dt.weekday() == (int(day) - 1)
    if lsk == 'monthly':
        return dt.day == int(day)
    raise ValueError(f"Unknown LSK: {lsk}")

def compute_horizon(dt, lsk, day):
    if lsk == 'daily':
        return dt, dt
    if lsk == 'weekly':
        # Only valid if dt is review day
        if dt.weekday() != (int(day)-1):
            raise ValueError(f"compute_horizon: input date {dt} is not review day (expected weekday {int(day)-1})")
        cur = dt + timedelta(days=1)
        while True:
            if cur.weekday() == (int(day) - 1):
                break
            cur += timedelta(days=1)
        window_end = cur - timedelta(days=1)
        return dt, window_end
    if lsk == 'monthly':
        if dt.day != int(day):
            raise ValueError(f"compute_horizon: input date {dt} is not review day (expected day {int(day)})")
        y, m = dt.year, dt.month
        if dt.day >= int(day):
            m += 1
            if m > 12:
                m = 1
                y += 1
        next_review = pd.Timestamp(y, m, int(day))
        window_end = next_review - timedelta(days=1)
        return dt, window_end
    raise ValueError(f"Unknown LSK: {lsk}")

def load_integrated_config(
    config_dict: dict,
    module1_output_dir: str,
    module4_output_path: str, 
    orchestrator: object,
    current_date: pd.Timestamp
) -> dict:
    """
    åŠ è½½é›†æˆé…ç½®æ•°æ®ï¼Œæ›¿ä»£åŸæ¥çš„load_config
    
    Args:
        config_dict: é…ç½®æ•°æ®å­—å…¸
        module1_output_dir: Module1è¾“å‡ºç›®å½•
        module4_output_path: Module4è¾“å‡ºæ–‡ä»¶è·¯å¾„
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ
        
    Returns:
        dict: é›†æˆé…ç½®æ•°æ®
    """
    config = {}
    validation_log = []
    
    # 1. ä»é…ç½®è¡¨åŠ è½½é™æ€æ•°æ®
    config['SafetyStock'] = config_dict.get('M3_SafetyStock', pd.DataFrame())
    config['Network'] = config_dict.get('Global_Network', pd.DataFrame())
    config['LeadTime'] = config_dict.get('Global_LeadTime', pd.DataFrame())
    config['DemandPriority'] = config_dict.get('Global_DemandPriority', pd.DataFrame())
    config['PushPullModel'] = config_dict.get('M5_PushPullModel', pd.DataFrame())
    config['DeployConfig'] = config_dict.get('M5_DeployConfig', pd.DataFrame())
    
    # åº”ç”¨å­—ç¬¦ä¸²æ ¼å¼åŒ–åˆ°æ‰€æœ‰é…ç½®è¡¨
    for sheet_name in ['SafetyStock', 'Network', 'LeadTime', 'DemandPriority', 'PushPullModel', 'DeployConfig']:
        if not config[sheet_name].empty:
            config[sheet_name] = _normalize_identifiers(config[sheet_name])
    
    # 2. ä»Module1åŠ è½½å½“æ—¥æ•°æ®
    config['SupplyDemandLog'] = config_dict.get('M5_SupplyDemandLog', pd.DataFrame())  # ä»æµ‹è¯•é…ç½®åŠ è½½
    
    # ä»Module1åŠ è½½å½“æ—¥"è®¢å•æ± "
    if module1_output_dir and current_date:
        config['OrderLog'] = load_module1_daily_orders(module1_output_dir, current_date)
    else:
        config['OrderLog'] = pd.DataFrame()

    # å®é™…ä» Module1 è¾“å‡ºåŠ è½½å½“æ—¥æ•°æ®
    if module1_output_dir and current_date:
        try:
            # ä» Module1 æ—¥è¾“å‡ºåŠ è½½ SupplyDemandLog
            date_str = current_date.strftime('%Y%m%d')
            module1_file = f"{module1_output_dir}/module1_output_{date_str}.xlsx"
            if os.path.exists(module1_file):
                xl = pd.ExcelFile(module1_file)
                if 'SupplyDemandLog' in xl.sheet_names:
                    m1_supply_demand = xl.parse('SupplyDemandLog')
                    if not m1_supply_demand.empty:
                        config['SupplyDemandLog'] = m1_supply_demand
                        # print(f"  âœ… ä» Module1 åŠ è½½äº† {len(m1_supply_demand)} æ¡ SupplyDemandLog æ•°æ®")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•ä» Module1 åŠ è½½æ•°æ®: {e}")
    
    # ä»Module1åŠ è½½å½“æ—¥å‘è´§æ•°æ®
    if module1_output_dir and current_date:
        config['TodayShipment'] = load_module1_daily_shipment(module1_output_dir, current_date)
    else:
        config['TodayShipment'] = pd.DataFrame()
    
    # 3. ç”Ÿäº§è®¡åˆ’ï¼šä¿®å¤é‡å¤è®¡ç®—é—®é¢˜ï¼Œåªä½¿ç”¨å®é™…çš„å†å²ç”Ÿäº§GR
    config['ProductionPlan'] = pd.DataFrame()  # å…ˆç½®ç©º
    # === ğŸ”§ ä¿®å¤ï¼šåªä» Orchestrator å–å½“æ—¥å®é™…å†å²ç”Ÿäº§GRï¼Œé¿å…é‡å¤è®¡ç®— ===
    if orchestrator and current_date:
        date_str = current_date.strftime('%Y-%m-%d')
        try:
            # åªè·å–å½“æ—¥å®é™…å†å²ç”Ÿäº§GRï¼Œä¸åŒ…å«è®¡åˆ’ç”Ÿäº§
            prod_gr = orchestrator.get_production_gr_view(date_str)
            if isinstance(prod_gr, pd.DataFrame) and not prod_gr.empty:
                # è§„èŒƒå­—æ®µï¼Œå°†dateé‡å‘½åä¸ºavailable_dateä»¥ä¿æŒå…¼å®¹æ€§
                prod_gr = prod_gr.rename(columns={'date': 'available_date'})[['material', 'location', 'available_date', 'quantity']]
                if 'available_date' in prod_gr.columns:
                    prod_gr['available_date'] = pd.to_datetime(prod_gr['available_date'])
                for col in ['quantity']:
                    if col in prod_gr.columns:
                        prod_gr[col] = pd.to_numeric(prod_gr[col], errors='coerce').fillna(0)
                config['ProductionPlan'] = prod_gr
                # print(f"  âœ… ä» Orchestrator åŠ è½½äº† {len(prod_gr)} æ¡ç”Ÿäº§è®¡åˆ’æ•°æ®ï¼ˆä»…å†å²ç”Ÿäº§GRï¼Œä¿®å¤é‡å¤è®¡ç®—ï¼‰")
            else:
                print(f"  âš ï¸  Orchestratorå½“æ—¥æ— å†å²ç”Ÿäº§GRæ•°æ®")
        except Exception as e:
            print(f"  âš ï¸  ä» Orchestrator åŠ è½½ç”Ÿäº§è®¡åˆ’å¤±è´¥: {e}")

    # === å›é€€ï¼šè‹¥ orchestrator æ— æ•°æ®ï¼Œå†å°è¯•ä» module4 æ–‡ä»¶è¯»å– ProductionPlan ===
    if (config['ProductionPlan'].empty) and module4_output_path and os.path.exists(module4_output_path):
        try:
            xl = pd.ExcelFile(module4_output_path)
            if 'ProductionPlan' in xl.sheet_names:
                m4_production = xl.parse('ProductionPlan')
                if not m4_production.empty:
                    if 'available_date' in m4_production.columns:
                        m4_production['available_date'] = pd.to_datetime(m4_production['available_date'])
                    for col in ['produced_qty', 'uncon_planned_qty', 'planned_qty', 'quantity']:
                        if col in m4_production.columns:
                            m4_production[col] = pd.to_numeric(m4_production[col], errors='coerce').fillna(0)
                    config['ProductionPlan'] = m4_production
                    # print(f"  âœ… å›é€€ï¼šä» Module4 åŠ è½½äº† {len(m4_production)} æ¡ç”Ÿäº§è®¡åˆ’æ•°æ®")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•ä» Module4 åŠ è½½ ProductionPlan: {e}")   

    # è¯»å– M4_MaterialLocationLineCfgï¼ˆç”¨äº PTF/LSKï¼‰
    config['M4_MaterialLocationLineCfg'] = config_dict.get('M4_MaterialLocationLineCfg', pd.DataFrame())
    if module4_output_path and os.path.exists(module4_output_path):
        try:
            xl = pd.ExcelFile(module4_output_path)
            if 'M4_MaterialLocationLineCfg' in xl.sheet_names:
                mlcfg = xl.parse('M4_MaterialLocationLineCfg')
                if not mlcfg.empty:
                    config['M4_MaterialLocationLineCfg'] = mlcfg
                    print(f"  âœ… ä» Module4 åŠ è½½äº† {len(mlcfg)} æ¡ M4_MaterialLocationLineCfg")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•ä» Module4 è¯»å– M4_MaterialLocationLineCfg: {e}")

    # 4. ä»OrchestratoråŠ è½½åŠ¨æ€æ•°æ®
    if orchestrator and current_date:
        date_str = current_date.strftime('%Y-%m-%d')
        try:
            # ğŸ”„ ä¿®æ”¹ï¼šä½¿ç”¨æœŸåˆåº“å­˜è€Œä¸æ˜¯å½“å‰åº“å­˜çŠ¶æ€ï¼Œé¿å…é‡å¤è®¡ç®—
            config['InventoryLog'] = orchestrator.get_beginning_inventory_view(date_str)
            config['InTransit'] = orchestrator.get_planning_intransit_view(date_str)
            config['DeliveryGR'] = load_orchestrator_delivery_gr(orchestrator, current_date)
            config['OpenDeployment'] = load_orchestrator_open_deployment(orchestrator, current_date)
            config['ReceivingSpace'] = orchestrator.get_space_quota_view(date_str)
            # print(f"  âœ… ä» Orchestrator åŠ è½½äº†åŠ¨æ€æ•°æ®ï¼ˆä½¿ç”¨æœŸåˆåº“å­˜åŸºç¡€ï¼‰")
        except Exception as e:
            print(f"  âš ï¸  ä» Orchestrator åŠ è½½åŠ¨æ€æ•°æ®å¤±è´¥: {e}")
            # ä½¿ç”¨ç©ºæ•°æ®ä½œä¸ºå¤‡é€‰
            config['InventoryLog'] = pd.DataFrame()
            config['InTransit'] = pd.DataFrame() 
            config['DeliveryGR'] = pd.DataFrame()
            config['OpenDeployment'] = pd.DataFrame()
            config['ReceivingSpace'] = pd.DataFrame()
    else:
        # ä½¿ç”¨ç©ºæ•°æ®
        config['InventoryLog'] = pd.DataFrame()
        config['InTransit'] = pd.DataFrame()
        config['DeliveryGR'] = pd.DataFrame()
        config['OpenDeployment'] = pd.DataFrame()
        config['ReceivingSpace'] = pd.DataFrame()
    
    # ä¸´æ—¶ä½¿ç”¨ç©ºæ•°æ®ä»¥ä¿æŒå…¼å®¹æ€§
    for key in ['SupplyDemandLog', 'ProductionPlan', 'InventoryLog', 'InTransit', 'ReceivingSpace']:
        if key not in config:
            config[key] = pd.DataFrame()
    
    # æ—¥æœŸå­—æ®µå¤„ç†
    date_fields = {
        'SupplyDemandLog': ['date'],
        'ProductionPlan': ['available_date'],
        'InventoryLog': ['date'],
        'InTransit': ['available_date'],
        'SafetyStock': ['date'],
        'ReceivingSpace': ['date'],
        'Network': ['eff_from', 'eff_to'],
        'OrderLog': ['date', 'simulation_date'],
    }
    
    for sheet, fields in date_fields.items():
        if sheet in config and not config[sheet].empty:
            for f in fields:
                if f in config[sheet].columns:
                    config[sheet][f] = pd.to_datetime(config[sheet][f])
    
    # æœ€ç»ˆæ ¼å¼åŒ–æ‰€æœ‰é…ç½®è¡¨çš„æ ‡è¯†ç¬¦å­—æ®µ
    for sheet_name, df in config.items():
        if isinstance(df, pd.DataFrame) and not df.empty:
            config[sheet_name] = _normalize_identifiers(df)
    
    config['ValidationLog'] = validation_log
    return config

def load_config(input_path: str):
    required_sheets = [
        'SupplyDemandLog', 'ProductionPlan', 'InventoryLog', 'InTransit', 'SafetyStock',
        'Network', 'PushPullModel', 'ReceivingSpace', 'LeadTime',
        'DemandPriority', 'DeployConfig'
    ]
    config = {}
    validation_log = []
    xl = pd.ExcelFile(input_path)
    for sheet in required_sheets:
        if sheet not in xl.sheet_names:
            validation_log.append({'No': len(validation_log)+1, 'Issue': f'Missing required sheet: {sheet}'})
            config[sheet] = pd.DataFrame()
        else:
            df = xl.parse(sheet)
            config[sheet] = df
    # å­—æ®µæ ¡éªŒä¸¾ä¾‹
    sdl_required = ['date', 'material', 'location', 'demand_element', 'quantity']
    if not config['SupplyDemandLog'].empty:
        missing_cols = [c for c in sdl_required if c not in config['SupplyDemandLog'].columns]
        if missing_cols:
            validation_log.append({'No': len(validation_log)+1, 'Issue': f'SupplyDemandLog missing columns: {",".join(missing_cols)}'})
    # æ—¥æœŸç±»å‹å¤„ç†
    date_fields = {
        'SupplyDemandLog': ['date'],
        'ProductionPlan': ['available_date'],
        'InventoryLog': ['date'],
        'InTransit': ['available_date'],
        'SafetyStock': ['date'],
        'ReceivingSpace': ['date'],
        'Network': ['eff_from', 'eff_to'],
        'OrderLog': ['date', 'simulation_date'],
    }
    for sheet, fields in date_fields.items():
        if sheet in config and not config[sheet].empty:
            for f in fields:
                if f in config[sheet].columns:
                    config[sheet][f] = pd.to_datetime(config[sheet][f])
    
    # æœ€ç»ˆæ ¼å¼åŒ–æ‰€æœ‰é…ç½®è¡¨çš„æ ‡è¯†ç¬¦å­—æ®µ
    for sheet_name, df in config.items():
        if isinstance(df, pd.DataFrame) and not df.empty:
            config[sheet_name] = _normalize_identifiers(df)
    
    config['ValidationLog'] = validation_log
    return config

def validate_config_before_run(config, validation_log):
    deploy_cfg = config['DeployConfig']
    leadtime_df = config['LeadTime']
    pushpull = config['PushPullModel']
    demand_priority = config['DemandPriority']
    network = config['Network']
    # ======= æ ¡éªŒnetworkæ˜¯å¦æœ‰multiple sourcing ==========
    multi_sourcing = (
        network.groupby(['material', 'location'])['sourcing']
        .nunique().reset_index()
    )
    multi_sourcing = multi_sourcing[multi_sourcing['sourcing'] > 1]
    for _, row in multi_sourcing.iterrows():
        validation_log.append({
            'No': len(validation_log) + 1,
            'Issue': f"Networké…ç½®ä¸åˆæ³•: material={row['material']}, location={row['location']} æœ‰å¤šä¸ªsourcing"
        })
    # æ ¡éªŒleadtime
    for _, row in network.iterrows():
        if leadtime_df[
            (leadtime_df['sending'] == row['sourcing']) & (leadtime_df['receiving'] == row['location'])
        ].empty:
            validation_log.append({'No': len(validation_log)+1,
                                  'Issue': f"Missing leadtime for {row['sourcing']}->{row['location']} ({row['material']})"})
    # æ ¡éªŒpushpull
    for _, row in deploy_cfg.iterrows():
        if pushpull[
            (pushpull['material'] == row['material']) & (pushpull['sending'] == row['sending'])
        ].empty:
            validation_log.append({'No': len(validation_log)+1,
                'Issue': f"Missing PushPullModel for {row['material']}/{row['sending']}"})
    # ======= æ ¡éªŒ/è¡¥å…… DemandPriority ==========
    dp = demand_priority.copy()

    # æ—¢çœ‹ SupplyDemandLog çš„ demand_elementï¼Œä¹Ÿçœ‹ OrderLog çš„ demand_typeï¼ˆAO/normalï¼‰
    sdl_types = set(config['SupplyDemandLog']['demand_element'].unique()) if not config['SupplyDemandLog'].empty else set()
    ol = config.get('OrderLog', pd.DataFrame())
    ol_types = set(ol['demand_type'].unique()) if ('demand_type' in ol.columns and not ol.empty) else set()

    # æŠŠ AO/normal æ˜ å°„ä¸º demand_element å­—æ®µé‡Œçš„å€¼ï¼ˆæˆ‘ä»¬åç»­ç”¨ demand_element åšä¼˜å…ˆçº§ï¼‰
    needed = sdl_types | ol_types  # AO/normal ä¹Ÿåœ¨å…¶ä¸­

    # ç¼ºå•¥è¡¥å•¥ï¼ˆé»˜è®¤ï¼šAO=1ï¼Œnormal=2ï¼Œå…¶ä½™ç»™ä¸ªè¾ƒä½ä¼˜å…ˆçº§ 9ï¼‰
    def _ensure_priority(elem, default_p):
        if dp[dp['demand_element'] == elem].empty:
            dp.loc[len(dp)] = {'demand_element': elem, 'priority': default_p}
            validation_log.append({
                'No': len(validation_log)+1,
                'Issue': f'Auto add DemandPriority for {elem}={default_p}'
            })
    for elem in needed:
        if elem == 'AO':
            _ensure_priority('AO', 1)
        elif elem == 'normal':
            _ensure_priority('normal', 2)
        else:
            _ensure_priority(elem, 9)
    # å›å†™
    config['DemandPriority'] = dp

    return validation_log

def collect_node_demands(material, location, sim_date, config, up_gap_buffer):
    supply_demand_log = config['SupplyDemandLog']
    safety_stock = config['SafetyStock']
    deploy_cfg = config['DeployConfig']
    network = config['Network']
    leadtime_df = config['LeadTime']

    # å‚æ•°
    param_row = deploy_cfg[
        (deploy_cfg['material'] == material) & (deploy_cfg['sending'] == location)
    ]
    if not param_row.empty:
        moq = int(param_row.iloc[0]['moq'])
        rv = int(param_row.iloc[0]['rv'])
        lsk = param_row.iloc[0]['lsk']
        day = int(param_row.iloc[0]['day'])
    else:
        moq, rv, lsk, day = 1, 1, 1, 1

    network_row = get_active_network(network, material, location, sim_date)
    if not network_row.empty:
        upstream = network_row.iloc[0]['sourcing']
    else:
        upstream = None

    # ç»Ÿä¸€å£å¾„ï¼šé€šè¿‡å±‚çº§åˆ¤æ ¹â†’Plant
    sending_location_type = get_sending_location_type(
        material=str(material),
        sending=str(upstream) if upstream else "",
        sim_date=sim_date,
        network_df=network,
        location_layer_map=config.get('LocationLayerMap', {})
    )

    # â€”â€” åŒºåˆ†â€œçª—å£å‰ç½®LT(lt_for_window)â€ä¸â€œè®¡åˆ’è¡Œè¿è¾“LT(lt_for_row)â€ â€”â€”
    lt_for_row = 0
    lt_for_window = 0

    # ä½¿ç”¨ä¸Module3ä¸€è‡´çš„æå‰æœŸè®¡ç®—é€»è¾‘ï¼ˆéé¡¶å±‚æ²¿ç”¨åŸæ¥ï¼›é¡¶å±‚ä»…ç”¨äºçª—å£å‰ç½®ï¼‰
    if upstream and pd.notna(upstream) and str(upstream).strip():
        lt_for_row, error_msg = determine_lead_time(
            sending=str(upstream),
            receiving=str(location),
            location_type=str(sending_location_type),
            lead_time_df=leadtime_df,
            m4_mlcfg_df=config.get('M4_MaterialLocationLineCfg', pd.DataFrame()),
            material=str(material)
        )
        if error_msg:
            print(f"Warning: {error_msg} for {upstream}->{location}, using default leadtime=1")
            lt_for_row = 1
        lt_for_window = lt_for_row  # éé¡¶å±‚ï¼šçª—å£å‰ç½®LT = è¿è¾“LTï¼ˆä¿æŒåŸè¡Œä¸ºï¼‰
    else:
        # é¡¶å±‚ï¼šçª—å£å‰ç½®LT = MCT + PTF + LSK - 1ï¼›è¿è¾“LTï¼ˆè‡ªè¡¥è´§ï¼‰= 0
        ptf, lsk_val = _get_ptf_lsk(
            material=str(material),
            site=str(location),
            m4_mlcfg_df=config.get('M4_MaterialLocationLineCfg', pd.DataFrame())
        )
        mct_series = leadtime_df.loc[leadtime_df['sending'] == str(location), 'MCT']
        mct_val = int(pd.to_numeric(mct_series, errors='coerce').max()) if not mct_series.empty else 0
        lt_for_window = max(0, mct_val) + int(ptf) + int(lsk_val) - 1
        lt_for_row = 0  # é¡¶å±‚è‡ªè¡¥è´§è¡Œè¿è¾“LTæ’ä¸º0

    # ä½¿ç”¨ç»Ÿä¸€çš„planned_deploy_dateç­›é€‰é€»è¾‘: [simulation_date, simulation_date + lsk - 1]
    filter_start = sim_date
    filter_end = sim_date + pd.Timedelta(days=int(lsk) - 1)

    demand_rows = []

    # SupplyDemandLogï¼ˆéœ€æ±‚åŸå§‹è¡Œï¼‰
    sdl = supply_demand_log[
        (supply_demand_log['material'] == material) & (supply_demand_log['location'] == location)
    ].copy()
    if not sdl.empty:
        # dateå­—æ®µä»£è¡¨requirement_dateï¼ˆéœ€æ±‚éœ€è¦çš„æ—¥æœŸï¼‰
        sdl['requirement_date'] = pd.to_datetime(sdl['date'])
        # è®¡ç®—planned_deploy_dateå¹¶ç­›é€‰ï¼ˆä½¿ç”¨çª—å£å‰ç½®LTï¼‰
        sdl['planned_deploy_date'] = sdl['requirement_date'] - pd.Timedelta(days=lt_for_window)
        sdl['planned_deploy_date'] = sdl[['planned_deploy_date']].apply(
            lambda x: max(x['planned_deploy_date'], sim_date), axis=1
        )
        # ä½¿ç”¨planned_deploy_dateçª—å£ç­›é€‰
        mask = (sdl['planned_deploy_date'] >= filter_start) & (sdl['planned_deploy_date'] <= filter_end)
        sdl = sdl[mask]
    for _, row in sdl.iterrows():
        requirement_date = row['requirement_date']
        planned_deploy_date = row['planned_deploy_date']

        demand_rows.append({
            'material': material,
            'location': location,
            'sending': upstream,
            'receiving': location,
            'demand_element': row['demand_element'],
            'demand_qty': int(row['quantity']),
            'planned_qty': int(row['quantity']),
            'moq': moq,
            'rv': rv,
            'leadtime': lt_for_row,  # â† æ”¹ä¸ºlt_for_row
            'requirement_date': requirement_date,
            'plan_deploy_date': planned_deploy_date,
        })

    # SafetyStockåŒç†
    ss = safety_stock[
        (safety_stock['material'] == material) & (safety_stock['location'] == location)
    ].copy()
    if not ss.empty:
        # safety stockçš„dateå­—æ®µä¹Ÿä»£è¡¨requirement_date
        ss['requirement_date'] = pd.to_datetime(ss['date'])
        # è®¡ç®—planned_deploy_dateå¹¶ç­›é€‰ï¼ˆä½¿ç”¨çª—å£å‰ç½®LTï¼‰
        ss['planned_deploy_date'] = ss['requirement_date'] - pd.Timedelta(days=lt_for_window)
        ss['planned_deploy_date'] = ss[['planned_deploy_date']].apply(
            lambda x: max(x['planned_deploy_date'], sim_date), axis=1
        )
        # ä½¿ç”¨planned_deploy_dateçª—å£ç­›é€‰
        mask = (ss['planned_deploy_date'] >= filter_start) & (ss['planned_deploy_date'] <= filter_end)
        ss = ss[mask]
    for _, row in ss.iterrows():
        requirement_date = row['requirement_date']
        planned_deploy_date = row['planned_deploy_date']

        demand_rows.append({
            'material': material,
            'location': location,
            'sending': upstream,
            'receiving': location,
            'demand_element': 'safety',
            'demand_qty': int(row['safety_stock_qty']),
            'planned_qty': int(row['safety_stock_qty']),
            'moq': moq,
            'rv': rv,
            'leadtime': lt_for_row,  # â† æ”¹ä¸ºlt_for_row
            'requirement_date': requirement_date,
            'plan_deploy_date': planned_deploy_date,
        })

    # ========= æ–°å¢ï¼šå°†å½“æ—¥ç‰ˆæœ¬ OrderLogï¼ˆå«AO/normalï¼‰çº³å…¥è°ƒè¿éœ€æ±‚ =========
    order_df = config.get('OrderLog', pd.DataFrame())
    if not order_df.empty:
        orders = order_df[
            (order_df['material'] == material) &
            (order_df['location'] == location)
        ].copy()

        if not orders.empty:
            # éœ€æ±‚æ—¥æœŸ = è®¢å•åˆ°æœŸæ—¥
            orders['requirement_date'] = pd.to_datetime(orders['date'])
            orders['demand_element'] = orders['demand_type']
            # planned_deploy_date = requirement_date - lt_for_windowï¼ˆä½†ä¸å¯æ—©äºsim_dateï¼‰
            orders['planned_deploy_date'] = orders['requirement_date'] - pd.Timedelta(days=lt_for_window)
            orders['planned_deploy_date'] = orders['planned_deploy_date'].apply(lambda d: max(d, sim_date))

            # LSK çª—å£ç­›é€‰ï¼šplanned_deploy_date âˆˆ [sim_date, sim_date + lsk - 1]
            mask = (orders['planned_deploy_date'] >= filter_start) & (orders['planned_deploy_date'] <= filter_end)
            orders = orders[mask]

            for _, row in orders.iterrows():
                requirement_date = row['requirement_date']
                planned_deploy_date = row['planned_deploy_date']
                qty = int(row['quantity'])

                demand_rows.append({
                    'material': material,
                    'location': location,
                    'sending': upstream,
                    'receiving': location,
                    'demand_element': row['demand_element'],   # 'AO' / 'normal'
                    'demand_qty': qty,
                    'planned_qty': qty,         # MOQ/RV ç¨åç»Ÿä¸€å¤„ç†
                    'moq': moq,
                    'rv': rv,
                    'leadtime': lt_for_row,     # â† æ”¹ä¸ºlt_for_row
                    'requirement_date': requirement_date,
                    'plan_deploy_date': planned_deploy_date,
                    'orig_location': location
                })

    # gapè¡Œï¼Œè¿™éƒ¨åˆ†éœ€è¦æŒ‰requirement_dateé‡æ–°è®¡ç®—planned_deploy_dateå¹¶ç­›é€‰
    if up_gap_buffer is not None and (material, location) in up_gap_buffer:
        for gap in up_gap_buffer[(material, location)]:
            requirement_date = gap.get('requirement_date', None)
            if requirement_date is None:
                # å¦‚æœæ²¡æœ‰requirement_dateï¼Œé»˜è®¤ä½¿ç”¨å½“å‰æ—¥æœŸ
                requirement_date = sim_date
                planned_deploy_date = sim_date
            else:
                requirement_date = pd.to_datetime(requirement_date)
                # åŸºäºçª—å£å‰ç½®LTé‡æ–°è®¡ç®—planned_deploy_date
                planned_deploy_date = requirement_date - pd.Timedelta(days=lt_for_window)
                planned_deploy_date = max(planned_deploy_date, sim_date)

            # æ£€æŸ¥planned_deploy_dateæ˜¯å¦åœ¨ç­›é€‰çª—å£å†…
            if planned_deploy_date >= filter_start and planned_deploy_date <= filter_end:
                demand_rows.append({
                    'material': material,
                    'location': gap.get('location', location),
                    'receiving': gap.get('receiving', gap.get('location', location)),
                    'orig_location': gap.get('orig_location', gap.get('location', location)),
                    'sending': upstream,
                    'demand_element': gap['demand_element'],
                    'demand_qty': gap['planned_qty'],
                    'planned_qty': gap['planned_qty'],
                    'moq': moq,
                    'rv': rv,
                    'leadtime': lt_for_row,  # â† æ”¹ä¸ºlt_for_row
                    'requirement_date': requirement_date,
                    'plan_deploy_date': planned_deploy_date,
                    'from_location': gap.get('from_location', None),
                })
    return demand_rows

def push_softpush_allocation(
    deployment_plan_rows, config, dynamic_soh, sim_date
):
    """
    å¯¹push/soft-pushæ¨¡å¼èŠ‚ç‚¹ï¼Œåˆ†é…å‰©ä½™åº“å­˜åˆ°ä¸‹æ¸¸receiving, è¾“å‡ºpushè¡¥è´§è®¡åˆ’è¡Œ
    ä¿®å¤ï¼š
    1. sending site safetyåŸºäºsimulation_date
    2. receiving site safetyåŸºäºsimulation_date + leadtime  
    3. å¦‚æœæ‰€æœ‰receiving sitesçš„safetyéƒ½æ˜¯0ï¼Œåˆ™æ— éœ€åˆ†é…
    4. pushå’Œsoft pushéƒ½æŒ‰receiving siteçš„safetyæƒé‡åˆ†é…
    """
    pushpull = config['PushPullModel']
    safety_stock = config['SafetyStock']
    leadtime_df = config['LeadTime']
    deploy_cfg = config['DeployConfig']
    net = config['Network']
    plan_rows_push = []
    
    # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—å·²åˆ†é…ç»™æ­£å¸¸éœ€æ±‚çš„åº“å­˜
    allocated_inventory = {}
    # print(f"\nğŸ” è°ƒè¯•Pushè¡¥è´§åº“å­˜åˆ†é…ï¼ˆ{sim_date}ï¼‰:")
    # print(f"   ä¼ å…¥çš„deployment_plan_rowsæ•°é‡: {len(deployment_plan_rows)}")
    
    for row in deployment_plan_rows:
        # åªè®¡ç®—éPushè¡¥è´§çš„åˆ†é…é‡ï¼Œä¸”åªè®¡ç®—è·¨èŠ‚ç‚¹è°ƒæ‹¨
        if (row['sending'] != row['receiving'] and 
            'push' not in row.get('demand_element', '').lower()):
            key = (row['material'], row['sending'])
            qty = row.get('deployed_qty_invCon', 0)
            allocated_inventory[key] = allocated_inventory.get(key, 0) + qty
    #         print(f"   æ­£å¸¸éœ€æ±‚åˆ†é…: {key} += {qty} (demand_element: {row.get('demand_element', 'N/A')})")
    
    # print(f"   è®¡ç®—å¾—åˆ°çš„å·²åˆ†é…åº“å­˜: {allocated_inventory}")
    
    group_keys = {(row['material'], row['sending']) for row in deployment_plan_rows}
    for mat, sending in group_keys:
        row_pp = pushpull[
            (pushpull['material'] == mat) & (pushpull['sending'] == sending)
        ]
        if row_pp.empty:
            continue
        model = row_pp.iloc[0]['model']
        if model not in ['push', 'soft push']:
            continue
        
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å‰©ä½™åº“å­˜è€Œä¸æ˜¯å…¨éƒ¨åº“å­˜
        total_soh = dynamic_soh.get((mat, sending), 0)
        already_allocated = allocated_inventory.get((mat, sending), 0)
        soh = max(0, total_soh - already_allocated)
        
        # print(f"     ææ–™{mat}@{sending}: æ€»åº“å­˜={total_soh}, å·²åˆ†é…={already_allocated}, å‰©ä½™åº“å­˜={soh}")
        
        if soh <= 0:
            continue  # å¦‚æœæ²¡æœ‰å‰©ä½™åº“å­˜ï¼Œè·³è¿‡Pushè¡¥è´§
        recs = net[(net['material']==mat) & (net['sourcing']==sending)]['location'].unique()
        param_row = deploy_cfg[
            (deploy_cfg['material'] == mat) & (deploy_cfg['sending'] == sending)
        ]
        if not param_row.empty:
            lsk = int(param_row.iloc[0]['lsk'])  # ç¡®ä¿LSKä¸ºæ•´æ•°
            day = int(param_row.iloc[0]['day'])
        else:
            lsk, day = 1, 1
        
        # ğŸ”§ ä¿®å¤1: è®¡ç®—sending siteçš„å®‰å…¨åº“å­˜ (åŸºäºsimulation_date)
        sending_ss = 0
        if model == 'soft push':
            ss_self = safety_stock[
                (safety_stock['material'] == mat) & (safety_stock['location'] == sending)
            ]
            ss_self_filtered = ss_self[pd.to_datetime(ss_self['date']) == sim_date] if not ss_self.empty else pd.DataFrame()
            if not ss_self_filtered.empty:
                sending_ss = ss_self_filtered['safety_stock_qty'].sum()
            else:
                print(f"     Warning: æ²¡æœ‰æ‰¾åˆ°{sim_date.date()}çš„sendingå®‰å…¨åº“å­˜é…ç½®ï¼Œ{sending}ææ–™{mat}é»˜è®¤ä¸º0")
        
        # è®¡ç®—å¯ç”¨åº“å­˜
        if model == 'push':
            available_soh = soh  # pushä½¿ç”¨å…¨éƒ¨å‰©ä½™åº“å­˜
        else:  # soft push
            available_soh = max(0, soh - sending_ss)  # soft pushæ‰£é™¤sendingçš„å®‰å…¨åº“å­˜
        
        # print(f"     {model}å¯ç”¨åº“å­˜: {available_soh} (sending_ss={sending_ss})")
        
        if available_soh <= 0:
            continue
            
        # ğŸ”§ ä¿®å¤2: å‡†å¤‡receiving sitesçš„å®‰å…¨åº“å­˜æ•°æ® (åŸºäºsimulation_date + leadtime)
        receiving_ss_data = []
        
        for loc in recs:
            # è®¡ç®—leadtime
            sending_location_type = get_sending_location_type(
                material=str(mat),
                sending=str(sending),
                sim_date=sim_date,
                network_df=net,
                location_layer_map=config.get('LocationLayerMap', {})
            )
            leadtime, error_msg = determine_lead_time(
                sending=str(sending),
                receiving=str(loc),
                location_type=str(sending_location_type),
                lead_time_df=leadtime_df,
                m4_mlcfg_df=config.get('M4_MaterialLocationLineCfg', pd.DataFrame()),
                material=str(mat)
            )
            if error_msg:
                print(f"     Warning: {error_msg} for {sending}->{loc}, using default leadtime=1")
                leadtime = 1
            
            # åŸºäºleadtime end dateæŸ¥æ‰¾receiving siteçš„å®‰å…¨åº“å­˜
            leadtime_end_date = sim_date + pd.Timedelta(days=leadtime)
            loc_ss = safety_stock[
                (safety_stock['material'] == mat) & (safety_stock['location'] == loc)
            ]
            
            loc_ss_filtered = loc_ss[pd.to_datetime(loc_ss['date']) == leadtime_end_date] if not loc_ss.empty else pd.DataFrame()
            if loc_ss_filtered.empty:
                if not loc_ss.empty:
                    print(f"     Warning: æ²¡æœ‰æ‰¾åˆ°{leadtime_end_date.date()}çš„receivingå®‰å…¨åº“å­˜é…ç½®ï¼Œ{loc}ææ–™{mat}é»˜è®¤ä¸º0")
                ss_qty = 0
            else:
                ss_qty = loc_ss_filtered['safety_stock_qty'].sum()
            
            receiving_ss_data.append({
                'location': loc,
                'safety_stock_qty': ss_qty,
                'leadtime': leadtime,
                'leadtime_end_date': leadtime_end_date
            })
        
        # è®¡ç®—total receiving safety stock
        total_receiving_ss = sum(item['safety_stock_qty'] for item in receiving_ss_data)
        
        # print(f"     ä¸‹æ¸¸ä½ç½®å®‰å…¨åº“å­˜æ€»è®¡: {total_receiving_ss}")
        
        # ğŸ”§ ä¿®å¤3: å¦‚æœæ‰€æœ‰receiving sitesçš„safetyéƒ½æ˜¯0ï¼Œåˆ™æ— éœ€åˆ†é…
        if total_receiving_ss == 0:
            # print(f"     æ‰€æœ‰receiving sitesçš„å®‰å…¨åº“å­˜éƒ½ä¸º0ï¼Œæ— éœ€åˆ†é…")
            continue
        
        # ğŸ”§ ä¿®å¤4: pushå’Œsoft pushéƒ½æŒ‰receiving siteçš„safetyæƒé‡åˆ†é…
        for item in receiving_ss_data:
            loc = item['location']
            ss_val = item['safety_stock_qty']
            leadtime = item['leadtime']
            
            qty = available_soh * ss_val / total_receiving_ss
            qty = int(np.floor(qty))
            
            if qty > 0:
                planned_delivery_date = sim_date + timedelta(days=leadtime)
                plan = {
                    'date': sim_date,
                    'material': mat,
                    'sending': sending,
                    'receiving': loc,
                    'demand_qty': 0,
                    'demand_element': 'push replenishment' if model=='push' else 'soft push replenishment',
                    'planned_qty': qty,
                    'deployed_qty_invCon_push': qty,
                    'planned_delivery_date': planned_delivery_date,
                }
                plan['deployed_qty_invCon'] = plan['deployed_qty_invCon_push']  # å…¼å®¹åç»­ç©ºé—´åˆ†é…å’Œåº“å­˜ç»Ÿè®¡
                plan_rows_push.append(plan)
                
                # print(f"     {model}åˆ†é…: {loc} = {qty} (æƒé‡={ss_val}/{total_receiving_ss})")
    return plan_rows_push


def apply_receiving_space_quota(deployment_plan_rows, receiving_space, sim_date, demand_priority_map):
    """
    åœ¨æ‰€æœ‰è°ƒè¿è®¡åˆ’æ˜ç»†ç”Ÿæˆåï¼ŒæŒ‰receiving space quotaå†åˆ†é…ï¼Œæ›´æ–°deployed_qtyï¼Œunfulfilled log
    ä¿®å¤ï¼šä»…å¯¹è·¨èŠ‚ç‚¹è°ƒè¿ï¼ˆsending != receivingï¼‰åº”ç”¨receiving space quotaé™åˆ¶
    """
    df = pd.DataFrame(deployment_plan_rows)
    if df.empty:
        df['deployed_qty'] = []
        df['quota'] = []
        return df, []
    
    # å¦‚æœreceiving_spaceé…ç½®ä¸ºç©ºï¼Œç›´æ¥è¿”å›åŸåˆ†é…ç»“æœ
    if receiving_space.empty:
        df['deployed_qty'] = df['deployed_qty_invCon']
        df['quota'] = np.inf
        return df, []
    
    # æŒ‰receiving+dateåˆ†ç»„
    unfulfilled = []
    for (recv, date), grp in df.groupby(['receiving', 'date']):
        quota_row = receiving_space[
            (receiving_space['receiving'] == recv) & (pd.to_datetime(receiving_space['date']) == date)
        ]
        quota = quota_row['max_qty'].iloc[0] if not quota_row.empty else np.inf
        
        # ğŸ”§ ä¿®å¤ï¼šä»…è®¡ç®—è·¨èŠ‚ç‚¹è°ƒè¿çš„quantityå ç”¨quota
        cross_node_grp = grp[grp['sending'] != grp['receiving']]
        self_fulfillment_grp = grp[grp['sending'] == grp['receiving']]
        
        # è‡ªæˆ‘éœ€æ±‚æ»¡è¶³ä¸å ç”¨quotaï¼Œç›´æ¥é€šè¿‡
        df.loc[self_fulfillment_grp.index, 'deployed_qty'] = self_fulfillment_grp['deployed_qty_invCon']
        df.loc[self_fulfillment_grp.index, 'quota'] = np.inf  # è‡ªæˆ‘æ»¡è¶³ä¸å—quotaé™åˆ¶
        
        if cross_node_grp.empty:
            # å¦‚æœæ²¡æœ‰è·¨èŠ‚ç‚¹è°ƒè¿ï¼Œè·³è¿‡quotaæ£€æŸ¥
            continue
            
        # ä»…æ£€æŸ¥è·¨èŠ‚ç‚¹è°ƒè¿æ˜¯å¦è¶…è¿‡quota
        cross_node_total = cross_node_grp['deployed_qty_invCon'].sum()
        if cross_node_total <= quota:
            df.loc[cross_node_grp.index, 'deployed_qty'] = cross_node_grp['deployed_qty_invCon']
            df.loc[cross_node_grp.index, 'quota'] = quota
            continue
        # è·¨èŠ‚ç‚¹è°ƒè¿ç©ºé—´ä¸è¶³ï¼ŒæŒ‰ä¼˜å…ˆçº§+æƒé‡åˆ†é…ï¼ˆä»…å¤„ç†è·¨èŠ‚ç‚¹è°ƒè¿ï¼‰
        cross_node_rows = cross_node_grp.to_dict(orient='records')
        
        # æŒ‰ä¼˜å…ˆçº§å¯¹è·¨èŠ‚ç‚¹è°ƒè¿è¿›è¡Œæ’åºå’Œåˆ†ç»„
        rows_sorted = sorted(cross_node_rows, key=lambda r: demand_priority_map.get(r['demand_element'], 99))
        grouped = {}
        for r in rows_sorted:
            p = demand_priority_map.get(r['demand_element'], 99)
            grouped.setdefault(p, []).append(r)
        
        left = quota
        deploy_qtys = {i: 0 for i in range(len(cross_node_rows))}
        
        for priority in sorted(grouped):
            group = grouped[priority]
            group_total = sum(r['deployed_qty_invCon'] for r in group)
            if left >= group_total:
                for r in group:
                    idx = cross_node_rows.index(r)
                    deploy_qtys[idx] = r['deployed_qty_invCon']
                left -= group_total
            else:
                allocated = 0
                for r in group:
                    idx = cross_node_rows.index(r)
                    weight = r['deployed_qty_invCon'] / group_total if group_total > 0 else 0
                    q = int(left * weight)
                    deploy_qtys[idx] = min(q, r['deployed_qty_invCon'])
                    allocated += deploy_qtys[idx]
                left -= allocated
                # ä¸å†åˆ†é…
                break
        
        # æ›´æ–°è·¨èŠ‚ç‚¹è°ƒè¿çš„å®é™…åˆ†é…
        for idx, qty in deploy_qtys.items():
            original_row = cross_node_rows[idx]
            # æ‰¾åˆ°åŸå§‹DataFrameä¸­å¯¹åº”çš„ç´¢å¼•
            original_idx = cross_node_grp[
                (cross_node_grp['sending'] == original_row['sending']) &
                (cross_node_grp['receiving'] == original_row['receiving']) &
                (cross_node_grp['material'] == original_row['material']) &
                (cross_node_grp['demand_element'] == original_row['demand_element'])
            ].index[0]
            
            df.at[original_idx, 'deployed_qty'] = qty
            df.at[original_idx, 'quota'] = quota
            
            gap = original_row['deployed_qty_invCon'] - qty
            if gap > 0:
                unfulfilled.append({
                    'date': date,
                    'sending': original_row['sending'],
                    'receiving': original_row['receiving'],
                    'demand_qty': original_row['demand_qty'],
                    'demand_element': original_row['demand_element'],
                    'unfulfilled_qty': gap,
                    'reason': "space constraint"
                })
    # ç©ºé—´å……è¶³è¡Œ
    df['deployed_qty'] = df['deployed_qty'].fillna(df['deployed_qty_invCon'])
    df['quota'] = df['quota'].fillna(np.nan)
    return df, unfulfilled

def log_outputs(output_path: str, outputs: Dict[str, pd.DataFrame]):
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        for sheet, df in outputs.items():
            if df.empty:
                # è¾“å‡ºç©ºè¡¨å¤´
                pd.DataFrame(columns=df.columns).to_excel(writer, sheet_name=sheet, index=False)
            else:
                # ç¡®ä¿è¾“å‡ºæ—¶æ ‡è¯†ç¬¦å­—æ®µä¸ºå­—ç¬¦ä¸²æ ¼å¼
                normalized_df = _normalize_identifiers(df)
                normalized_df.to_excel(writer, sheet_name=sheet, index=False)

# ============ 2. ä¸»æµç¨‹ ===============

def main(
    input_path: str = None, 
    output_path: str = None, 
    sim_start: str = None, 
    sim_end: str = None,
    # æ–°å¢å‚æ•°æ”¯æŒé›†æˆæ¨¡å¼
    config_dict: dict = None,
    module1_output_dir: str = None,
    module4_output_path: str = None,
    orchestrator: object = None,
    current_date: str = None
):
    """
    Module 5: å¤šå±‚çº§éƒ¨ç½²è§„åˆ’æ¨¡å—
    
    æ”¯æŒä¸¤ç§è¿è¡Œæ¨¡å¼:
    1. ç‹¬ç«‹æ¨¡å¼: ä¼ å…¥input_path, output_path, sim_start, sim_end
    2. é›†æˆæ¨¡å¼: ä¼ å…¥config_dict, module1_output_dir, module4_output_path, orchestrator, current_date
    
    Args:
        # ç‹¬ç«‹æ¨¡å¼å‚æ•°
        input_path: è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ 
        sim_start: ä»¿çœŸå¼€å§‹æ—¥æœŸ
        sim_end: ä»¿çœŸç»“æŸæ—¥æœŸ
        
        # é›†æˆæ¨¡å¼å‚æ•°
        config_dict: é…ç½®æ•°æ®å­—å…¸
        module1_output_dir: Module1è¾“å‡ºç›®å½•
        module4_output_path: Module4è¾“å‡ºæ–‡ä»¶è·¯å¾„
        orchestrator: Orchestratorå®ä¾‹
        current_date: å½“å‰æ—¥æœŸ(å•æ—¥è¿è¡Œæ—¶)
    """
    # åˆ¤æ–­è¿è¡Œæ¨¡å¼
    if config_dict is not None:
        # é›†æˆæ¨¡å¼ - å®Œæˆçš„é›†æˆæ•°æ®åŠ è½½
        # print("\nğŸ”„ Module5 è¿è¡Œäºé›†æˆæ¨¡å¼")
        current_date_obj = pd.to_datetime(current_date) if current_date else None
        config = load_integrated_config(
            config_dict, module1_output_dir, module4_output_path, 
            orchestrator, current_date_obj
        )
        sim_dates = [current_date_obj] if current_date_obj else pd.date_range(sim_start, sim_end, freq='D')
        
        # é›†æˆæ¨¡å¼è¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = f"./Module5Output_{current_date_obj.strftime('%Y%m%d')}.xlsx" if current_date_obj else "./Module5Output.xlsx"
    else:
        # ç‹¬ç«‹æ¨¡å¼ - ä¿æŒå¾€åå…¼å®¹
        # print("\nğŸ“œ Module5 è¿è¡Œäºç‹¬ç«‹æ¨¡å¼") 
        config = load_config(input_path)
        sim_dates = pd.date_range(sim_start, sim_end, freq='D')
    
    # ç»§ç»­åŸæœ‰é€»è¾‘æµç¨‹
    validation_log = list(config.get('ValidationLog', []))
    validate_config_before_run(config, validation_log)

    network = config['Network']
    deploy_cfg = config['DeployConfig']
    inventory_log = config['InventoryLog']
    production_plan = config['ProductionPlan']
    in_transit = config['InTransit']
    demand_priority = config['DemandPriority']
    receiving_space = config['ReceivingSpace']

    network_layers = assign_location_layers(network)
    location_to_layer = dict(zip(network_layers['location'], network_layers['layer']))
    layer_list = sorted(network_layers['layer'].unique(), reverse=True)  # ä»æœ€å¤§å±‚å¾€ä¸Šæ¸¸æ¨è¿›
    demand_priority_map = {row['demand_element']: row['priority'] for _, row in demand_priority.iterrows()}
    config['LocationLayerMap'] = location_to_layer
    # ========== åˆå§‹åŒ–åº“å­˜ soh_dict ==========
    # 1. å…¨æ”¶é›†æ‰€æœ‰material/locationï¼ˆåŒ…å« OrderLogï¼‰
    ol_df = config.get('OrderLog', pd.DataFrame())
    mats_from_ol = set(ol_df['material'].unique()) if ('material' in ol_df.columns and not ol_df.empty) else set()
    locs_from_ol = set(ol_df['location'].unique()) if ('location' in ol_df.columns and not ol_df.empty) else set()

    all_mats = set(config['SupplyDemandLog']['material'].unique()) | \
            set(config['SafetyStock']['material'].unique()) | \
            mats_from_ol

    all_locs = set(config['SupplyDemandLog']['location'].unique()) | \
            set(config['SafetyStock']['location'].unique()) | \
            locs_from_ol

    # 2. ç¡®å®šä»¿çœŸå¼€å§‹æ—¥æœŸå¹¶è·å–å½“å¤©çš„åº“å­˜
    # é›†æˆæ¨¡å¼ä¸‹ä½¿ç”¨ç¬¬ä¸€ä¸ªä»¿çœŸæ—¥æœŸï¼Œç‹¬ç«‹æ¨¡å¼ä¸‹ä½¿ç”¨sim_startå‚æ•°
    actual_sim_start = (sim_dates[0] if hasattr(sim_dates, '__getitem__') else pd.to_datetime(sim_start))
    
    inv_df = inventory_log[inventory_log['date'] == actual_sim_start]
    if inv_df.empty:
        print(f"[WARN] No inventory records found for sim_start: {actual_sim_start}")

    # 3. æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤è®°å½•
    duplicates = inv_df.duplicated(subset=['material', 'location'], keep=False)
    if duplicates.any():
        dup_rows = inv_df[duplicates]
        raise ValueError(f"InventoryLog contains duplicate (material, location) on sim_start {sim_start}:\n{dup_rows[['material', 'location', 'date']]}")

    # 4. åˆå§‹åŒ–soh_dictï¼Œé»˜è®¤0
    soh_dict = {}
    for mat in all_mats:
        for loc in all_locs:
            soh_dict[(mat, loc)] = 0  # é»˜è®¤0

    for _, row in inv_df.iterrows():
        soh_dict[(row['material'], row['location'])] = int(row['quantity'])


    deployment_plan_rows = []
    unfulfilled_rows = []
    stock_on_hand_log = []

    up_gap_buffer = {}

    for sim_date in sim_dates:
        # === ä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º ===
        # print(f"\n{'='*60}")
        # print(f"ğŸ“… ä»¿çœŸæ—¥æœŸ: {sim_date.strftime('%Y-%m-%d')}")
        # print(f"{'='*60}")

        # ===== åº“å­˜è®¡ç®—é€»è¾‘é‡æ„ (ä¿®å¤é‡å¤è®¡ç®—é—®é¢˜) =====
        # ğŸ”„ æ–°çš„åº“å­˜è®¡ç®—å…¬å¼: åŸºäºæœŸåˆåº“å­˜é¿å…é‡å¤è®¡ç®—
        # available_inventory = 
        #   beginning_inventory +              # å½“æ—¥æœŸåˆåº“å­˜ï¼ˆæœªåŒ…å«å½“æ—¥äº‹åŠ¡ï¼‰
        #   in_transit +                      # åœ¨é€”åº“å­˜
        #   delivery_gr +                     # å½“æ—¥æ”¶è´§æ•°æ®  
        #   today_production +                # å½“æ—¥ç”Ÿäº§ (available_date = today)
        #   future_production +               # æœªæ¥ç”Ÿäº§ (available_date > today)
        #   - today_shipment -                # å½“æ—¥å‘è´§æ•°æ®
        #   - open_deployment                 # å¼€æ”¾è°ƒæ‹¨æ•°æ®
        
        # ä½¿ç”¨æœŸåˆåº“å­˜ä½œä¸ºåŸºç¡€ï¼Œé¿å…é‡å¤è®¡ç®—M1 shipmentå’ŒM4 production
        beginning_inventory = soh_dict.copy()
        
        # ä» Module4/Orchestrator è·å–å½“æ—¥å’Œæœªæ¥ç”Ÿäº§ï¼ˆæ¥æºè§ load_integrated_config çš„é…ç½®ï¼‰
        today_production_gr = {}
        future_production = {}
        if not production_plan.empty:
            # ğŸ” è°ƒè¯•ç”Ÿäº§è®¡åˆ’æ•°æ®
            # print(f"\nğŸ” è°ƒè¯•ç”Ÿäº§è®¡åˆ’æ•°æ®:")
            # print(f"   ç”Ÿäº§è®¡åˆ’æ€»æ¡ç›®: {len(production_plan)}")
            # print(f"   ç”Ÿäº§è®¡åˆ’åˆ—: {production_plan.columns.tolist()}")
            
            # æ£€æŸ¥æ‰€æœ‰å½“æ—¥ç”Ÿäº§è®¡åˆ’
            all_today = production_plan[production_plan['available_date'] == sim_date]
            # print(f"   æ‰€æœ‰å½“æ—¥ç”Ÿäº§è®¡åˆ’: {len(all_today)} æ¡")
            # for _, row in all_today.iterrows():
                # print(f"   - {row.get('material')}@{row.get('location')}: {row.get('quantity')}")
            
            # æŸ¥çœ‹å½“æ—¥çš„80813644@0386ç”Ÿäº§è®¡åˆ’
            # debug_today = production_plan[
            #     (production_plan['available_date'] == sim_date) & 
            #     (production_plan['material'] == '80813644') & 
            #     (production_plan['location'] == '0386')
            # ]
            # if not debug_today.empty:
            #     print(f"   å½“æ—¥80813644@0386ç”Ÿäº§è®¡åˆ’: {len(debug_today)} æ¡")
            #     for _, row in debug_today.iterrows():
            #         print(f"   - material: {row.get('material')}, location: {row.get('location')}")
            #         print(f"     produced_qty: {row.get('produced_qty')}, planned_qty: {row.get('planned_qty')}")
            #         print(f"     quantity: {row.get('quantity')}, available_date: {row.get('available_date')}")
                    
            # ğŸ” é‡è¦ï¼šå¯¹æ¯”å†å²ç”Ÿäº§å…¥åº“vsè®¡åˆ’ç”Ÿäº§
            if orchestrator:
                date_str = sim_date.strftime('%Y-%m-%d')
                # print(f"\nğŸ” å¯¹æ¯”å†å²ç”Ÿäº§å…¥åº“ vs è®¡åˆ’ç”Ÿäº§:")
                # è·å–å½“æ—¥å†å²ç”Ÿäº§GR
                # prod_gr_view = orchestrator.get_production_gr_view(date_str)
                # print(f"   å½“æ—¥å†å²ç”Ÿäº§GRæ¡ç›®: {len(prod_gr_view) if not prod_gr_view.empty else 0}")
                # if not prod_gr_view.empty:
                #     for _, row in prod_gr_view.iterrows():
                #         print(f"   - å†å²GR: {row.get('material')}@{row.get('location')}: {row.get('quantity')}")
                
                # # è·å–è®¡åˆ’ç”Ÿäº§backlog
                # if hasattr(orchestrator, 'production_plan_backlog'):
                #     backlog_today = [p for p in orchestrator.production_plan_backlog 
                #                    if pd.to_datetime(p.get('available_date')).normalize() == sim_date.normalize()]
                #     print(f"   å½“æ—¥è®¡åˆ’ç”Ÿäº§backlogæ¡ç›®: {len(backlog_today)}")
                #     for record in backlog_today:
                #         print(f"   - è®¡åˆ’backlog: {record.get('material')}@{record.get('location')}: {record.get('quantity')}")
                # else:
                #     print(f"   Orchestratoræ²¡æœ‰production_plan_backlogå±æ€§")
            
            # # å½“æ—¥ç”Ÿäº§ (available_date = sim_date) â€”â€” ç”¨ produced_qty
            today_prod = production_plan[production_plan['available_date'] == sim_date]
            # print(f"   å½“æ—¥ç”Ÿäº§æ¡ç›®: {len(today_prod)}")
            for _, row in today_prod.iterrows():
                k = (row['material'], row['location'])
                if 'produced_qty' in row and pd.notna(row['produced_qty']):
                    qty_today = int(row['produced_qty'])
                elif 'planned_qty' in row and pd.notna(row['planned_qty']):
                    qty_today = int(row['planned_qty'])
                elif 'quantity' in row and pd.notna(row['quantity']):
                    qty_today = int(row['quantity'])
                else:
                    qty_today = 0
                today_production_gr[k] = today_production_gr.get(k, 0) + qty_today
                # if k[0] == '80813644' and k[1] == '0386':
                    # print(f"   æ·»åŠ 80813644@0386ç”Ÿäº§: {qty_today} (ç´¯è®¡: {today_production_gr[k]})")

            # æœªæ¥ç”Ÿäº§ (available_date > sim_date) â€”â€” ç”¨ uncon_planned_qty
            future_prod = production_plan[production_plan['available_date'] > sim_date]
            for _, row in future_prod.iterrows():
                k = (row['material'], row['location'])
                if 'uncon_planned_qty' in row and pd.notna(row['uncon_planned_qty']):
                    qty_future = int(row['uncon_planned_qty'])
                elif 'produced_qty' in row and pd.notna(row['produced_qty']):
                    # å›é€€ï¼šè‹¥æ²¡æœ‰ unconï¼Œåˆ™ç”¨ producedï¼ˆå°½é‡ä¸ä¸¢æ•°æ®ï¼‰
                    qty_future = int(row['produced_qty'])
                elif 'planned_qty' in row and pd.notna(row['planned_qty']):
                    qty_future = int(row['planned_qty'])
                elif 'quantity' in row and pd.notna(row['quantity']):
                    qty_future = int(row['quantity'])
                else:
                    qty_future = 0
                future_production[k] = future_production.get(k, 0) + qty_future
        
        # ä» Orchestrator è·å–åœ¨é€”åº“å­˜
        today_intransit = {}
        if not in_transit.empty:
            for _, row in in_transit[in_transit['available_date'] == sim_date].iterrows():
                k = (row['material'], row['receiving'])
                today_intransit[k] = today_intransit.get(k, 0) + int(row['quantity'])
        
        # åŠ è½½å½“æ—¥æ”¶è´§ã€å‘è´§å’Œå¼€æ”¾è°ƒæ‹¨æ•°æ®
        delivery_gr_data = config.get('DeliveryGR', pd.DataFrame())
        today_shipment_data = config.get('TodayShipment', pd.DataFrame())
        open_deployment_data = config.get('OpenDeployment', pd.DataFrame())
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        delivery_gr = {}
        if not delivery_gr_data.empty:
            filtered_delivery = delivery_gr_data[pd.to_datetime(delivery_gr_data['date']) == sim_date] if 'date' in delivery_gr_data.columns else delivery_gr_data
            for _, row in filtered_delivery.iterrows():
                k = (row['material'], row['receiving'])
                delivery_gr[k] = delivery_gr.get(k, 0) + int(row['quantity'])
        
        today_shipment = {}
        if not today_shipment_data.empty:
            filtered_shipment = today_shipment_data[pd.to_datetime(today_shipment_data['date']) == sim_date] if 'date' in today_shipment_data.columns else today_shipment_data
            for _, row in filtered_shipment.iterrows():
                k = (row['material'], row['location'])
                today_shipment[k] = today_shipment.get(k, 0) + int(row['quantity'])
        
        open_deployment = {}
        if not open_deployment_data.empty:
            for _, row in open_deployment_data.iterrows():
                # åªè®¡ç®—çœŸæ­£ä»è¯¥åœ°ç‚¹å‘å‡ºçš„è°ƒæ‹¨ï¼Œæ’é™¤è‡ªå¾ªç¯ï¼ˆsending=receivingï¼‰
                if row['sending'] != row['receiving']:
                    k = (row['material'], row['sending'])
                    open_deployment[k] = open_deployment.get(k, 0) + int(row['quantity'])
        # ğŸ” æ–°å¢ï¼šæ„é€  inbound è§†å›¾ (material, receiving) â†’ qty
        open_deployment_inbound = build_open_deployment_inbound(open_deployment_data)

        # è®¡ç®—é¢„æµ‹åº“å­˜ï¼ˆç”¨äºgapè®¡ç®—ï¼‰
        projected_soh = calculate_projected_inventory(
            beginning_inventory=beginning_inventory,
            in_transit=today_intransit, 
            delivery_gr=delivery_gr,
            today_production_gr=today_production_gr,
            future_production=future_production,
            today_shipment=today_shipment,
            open_deployment=open_deployment
        )
        
        # è®¡ç®—å½“æ—¥çœŸå®å¯ç”¨åº“å­˜ï¼ˆç”¨äºå®é™…åˆ†é…ï¼‰
        dynamic_soh = calculate_available_inventory(
            beginning_inventory=beginning_inventory,
            delivery_gr=delivery_gr,
            today_production_gr=today_production_gr,
            today_shipment=today_shipment,
            open_deployment=open_deployment,
            open_deployment_inbound=open_deployment_inbound
        )

        
        # print(f"ğŸ” åº“å­˜è®¡ç®—åŸºç¡€: æœŸåˆåº“å­˜ {len(beginning_inventory)} é¡¹, é¢„æµ‹åº“å­˜ {len([k for k, v in projected_soh.items() if v > 0])} é¡¹æœ‰åº“å­˜, å½“æ—¥å¯ç”¨åº“å­˜ {len([k for k, v in dynamic_soh.items() if v > 0])} é¡¹æœ‰åº“å­˜")
        
        # ğŸ” è°ƒè¯•ï¼šè¯¦ç»†åˆ†æ80813644@0386çš„åº“å­˜è®¡ç®—
        # debug_key = ('80813644', '0386')
        # if debug_key in beginning_inventory or debug_key in dynamic_soh:
        #     print(f"\nğŸ” è°ƒè¯•80813644@0386åº“å­˜è®¡ç®—:")
        #     print(f"   æœŸåˆåº“å­˜ (beginning_inventory): {beginning_inventory.get(debug_key, 0)}")
        #     print(f"   äº¤ä»˜å…¥åº“ (delivery_gr): {delivery_gr.get(debug_key, 0)}")
        #     print(f"   å½“æ—¥ç”Ÿäº§å…¥åº“ (today_production_gr): {today_production_gr.get(debug_key, 0)}")
        #     print(f"   å½“æ—¥å‘è´§å‡ºåº“ (today_shipment): {today_shipment.get(debug_key, 0)}")
        #     print(f"   å¼€æ”¾éƒ¨ç½²æ‰£å‡ (open_deployment): {open_deployment.get(debug_key, 0)}")
        #     calculated = (beginning_inventory.get(debug_key, 0) + 
        #                  delivery_gr.get(debug_key, 0) + 
        #                  today_production_gr.get(debug_key, 0) - 
        #                  today_shipment.get(debug_key, 0) - 
        #                  open_deployment.get(debug_key, 0))
        #     print(f"   è®¡ç®—ç»“æœ = {beginning_inventory.get(debug_key, 0)} + {delivery_gr.get(debug_key, 0)} + {today_production_gr.get(debug_key, 0)} - {today_shipment.get(debug_key, 0)} - {open_deployment.get(debug_key, 0)} = {calculated}")
        #     print(f"   dynamic_sohå®é™…å€¼: {dynamic_soh.get(debug_key, 0)}")
            
            # # ğŸ” è°ƒè¯•today_production_grçš„å…·ä½“æ¥æº
            # print(f"\nğŸ” è°ƒè¯•today_production_grçš„æ¥æº:")
            # print(f"   today_production_græ€»æ¡ç›®: {len(today_production_gr)}")
            # for key, qty in today_production_gr.items():
            #     if key[0] == '80813644' and key[1] == '0386':
            #         print(f"   å‘ç°80813644@0386çš„ç”Ÿäº§å…¥åº“: {qty}")
            
            # å¯¹æ¯”Orchestratorçš„unrestricted_inventory
            # if orchestrator:
            #     date_str = current_date.strftime('%Y-%m-%d') if hasattr(current_date, 'strftime') else str(current_date)
            #     orch_inventory = orchestrator.get_unrestricted_inventory_view(date_str)
            #     orch_row = orch_inventory[(orch_inventory['material'] == '80813644') & (orch_inventory['location'] == '0386')]
            #     if not orch_row.empty:
            #         orch_qty = orch_row.iloc[0]['quantity']
                    # print(f"   Orchestrator unrestricted_inventory: {orch_qty}")
                    # print(f"   å·®å¼‚: dynamic_soh({dynamic_soh.get(debug_key, 0)}) - unrestricted({orch_qty}) = {dynamic_soh.get(debug_key, 0) - orch_qty}")
                    
                    # ğŸ” è°ƒè¯•Orchestratorå½“æ—¥å†å²ç”Ÿäº§å…¥åº“è®°å½•
                    # print(f"\nğŸ” è°ƒè¯•Orchestratorå½“æ—¥å†å²ç”Ÿäº§å…¥åº“:")
                    # if hasattr(orchestrator, 'production_gr'):
                    #     prod_records = [p for p in orchestrator.production_gr if 
                    #                   p.get('date') == date_str and 
                    #                   p.get('material') == '80813644' and 
                    #                   p.get('location') == '0386']
                    #     print(f"   Orchestratorå½“æ—¥å†å²ç”Ÿäº§å…¥åº“è®°å½•æ•°: {len(prod_records)}")
                    #     total_orch_prod = sum(p.get('quantity', 0) for p in prod_records)
                    #     print(f"   Orchestratorå½“æ—¥å†å²ç”Ÿäº§å…¥åº“æ€»é‡: {total_orch_prod}")
                    #     for record in prod_records:
                    #         print(f"   - {record}")
                    # else:
                    #     print(f"   Orchestratoræ²¡æœ‰production_grå±æ€§")
        up_gap_next = {}

        for layer in layer_list:
            # print(f"\nğŸ“¦ å¤„ç†å±‚çº§ {layer}")
            # print(f"{'-'*40}")
            
            # ç»„åˆæ‰€æœ‰material-locationå¯¹ï¼ˆåŒ…å« OrderLogå’Œsafety stockï¼‰
            materials_union = set(config['SupplyDemandLog']['material'].unique())
            if 'OrderLog' in config and not config['OrderLog'].empty:
                materials_union |= set(config['OrderLog']['material'].unique())
            if not config['SafetyStock'].empty:
                materials_union |= set(config['SafetyStock']['material'].unique())
            base_pairs = set(
                (mat, loc)
                for loc, l in location_to_layer.items() if l == layer
                for mat in materials_union
            )
            # gap bufferè¡¥å……
            gap_pairs = set(
                (mat, loc)
                for (mat, loc) in up_gap_buffer
                if location_to_layer.get(loc, None) == layer
            )
            all_pairs = base_pairs | gap_pairs
            
            for mat, loc in all_pairs:
                node_key = (mat, loc)
                current_stock = dynamic_soh.get(node_key, 0)
                # print(f"ğŸ“ èŠ‚ç‚¹: {mat}@{loc} [å¯ç”¨åº“å­˜: {current_stock}]")
                
                demand_rows = collect_node_demands(mat, loc, sim_date, config, up_gap_buffer)
                if not demand_rows:
                    # print(f"   âš ï¸  æ— éœ€æ±‚éœ€è¦å¤„ç†")
                    continue
                
                demand_types = [d['demand_element'] for d in demand_rows]
                # print(f"   ğŸ“‹ éœ€æ±‚ç±»å‹: {', '.join(demand_types)}")
                
                # ğŸ”§ ä¿®å¤ï¼šMOQ/RVåº”ç”¨é€»è¾‘ç§»è‡³è°ƒæ‹¨è®¡åˆ’ç”Ÿæˆé˜¶æ®µï¼Œæ ¹æ®å®é™…çš„sending/receivingå…³ç³»å†³å®š
                # æ­¤å¤„å…ˆå°†planned_qtyè®¾ä¸ºdemand_qtyï¼Œç¨ååœ¨ç”Ÿæˆplan_rowæ—¶å†å†³å®šæ˜¯å¦åº”ç”¨MOQ/RV
                for d in demand_rows:
                    d['planned_qty'] = d['demand_qty']  # æš‚æ—¶è®¾ä¸ºåŸå§‹éœ€æ±‚é‡

                # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„å¤„ç†
                demand_rows_sorted = sorted(demand_rows, key=lambda d: demand_priority_map.get(d['demand_element'], 99))
                grouped = {}
                for d in demand_rows_sorted:
                    p = demand_priority_map.get(d['demand_element'], 99)
                    grouped.setdefault(p, []).append(d)
                
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨åˆ†ç»„MOQ/RVé€»è¾‘è®¡ç®—æ€»éœ€æ±‚é‡
                adjusted_qtys = apply_grouped_moq_rv(demand_rows, loc)
                total_actual_demand = sum(adjusted_qtys.values())
                # print(f"   ğŸ“Š æ€»éœ€æ±‚: {total_actual_demand}, å¯ç”¨åº“å­˜: {current_stock}")
                
                for priority in sorted(grouped):
                    group = grouped[priority]
                    # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆçº§ç»„éœ€æ±‚é‡åŸºäºåˆ†ç»„MOQ/RVè°ƒæ•´ç»“æœ
                    group_actual_demand = 0
                    for i, d in enumerate(demand_rows):
                        if d in group:
                            group_actual_demand += adjusted_qtys.get(i, d['demand_qty'])
                    # print(f"   ğŸ”¢ ä¼˜å…ˆçº§ {priority}: éœ€æ±‚ {group_actual_demand}")
                    
                    # å¦‚æœæ²¡æœ‰å‰©ä½™åº“å­˜ï¼Œæ‰€æœ‰åç»­ä¼˜å…ˆçº§éƒ½åˆ†é…0
                    if current_stock <= 0:
                        for d in group:
                            d['deployed_qty_invCon'] = 0
                        # print(f"      âŒ æ— å‰©ä½™åº“å­˜ï¼Œè·³è¿‡")
                        continue
                    
                    if group_actual_demand == 0:
                        for d in group:
                            d['deployed_qty_invCon'] = 0
                        continue
                    
                    if current_stock >= group_actual_demand:
                        # åº“å­˜å……è¶³ï¼Œå®Œå…¨æ»¡è¶³å½“å‰ä¼˜å…ˆçº§
                        for i, d in enumerate(demand_rows):
                            if d in group:
                                adjusted_qty = adjusted_qtys.get(i, d['demand_qty'])
                                d['deployed_qty_invCon'] = adjusted_qty
                        current_stock -= group_actual_demand
                        # print(f"      âœ… åº“å­˜å……è¶³ï¼Œå®Œå…¨æ»¡è¶³")
                    else:
                        # åº“å­˜ä¸è¶³ï¼ŒæŒ‰æƒé‡åˆ†é…æ‰€æœ‰å‰©ä½™åº“å­˜ç»™å½“å‰ä¼˜å…ˆçº§
                        # å…³é”®ä¿®å¤ï¼šç”¨å®Œåº“å­˜åï¼Œåç»­ä¼˜å…ˆçº§ä¸å†åˆ†é…
                        for i, d in enumerate(demand_rows):
                            if d in group:
                                adjusted_qty = adjusted_qtys.get(i, d['demand_qty'])
                                weight = adjusted_qty / group_actual_demand if group_actual_demand > 0 else 0
                                d['deployed_qty_invCon'] = min(int(current_stock * weight), adjusted_qty)
                        
                        # é‡æ–°è®¡ç®—å®é™…åˆ†é…é‡
                        actual_allocated = sum(d['deployed_qty_invCon'] for d in group)
                        current_stock = 0  # å…³é”®ä¿®å¤ï¼šåº“å­˜ä¸è¶³æ—¶ï¼Œç”¨å®Œæ‰€æœ‰åº“å­˜ï¼Œåç»­ä¼˜å…ˆçº§ä¸å†åˆ†é…
                        # print(f"      âš ï¸  åº“å­˜ä¸è¶³ï¼Œéƒ¨åˆ†æ»¡è¶³ {actual_allocated}/{group_actual_demand}ï¼Œåç»­ä¼˜å…ˆçº§ä¸å†åˆ†é…")
                        
                        # ä¸ºåç»­ä¼˜å…ˆçº§é¢„è®¾0åˆ†é…
                        remaining_priorities = [p for p in sorted(grouped) if p > priority]
                        for remaining_priority in remaining_priorities:
                            for d in grouped[remaining_priority]:
                                d['deployed_qty_invCon'] = 0
                        break  # è·³å‡ºä¼˜å…ˆçº§å¾ªç¯
                    
                    # æ˜¾ç¤ºåˆ†é…è¯¦æƒ…
                    for i, d in enumerate(demand_rows):
                        if d in group:
                            receiving = d.get('from_location', d.get('receiving', loc))
                            is_cross_node = (loc != receiving)
                            adjusted_qty = adjusted_qtys.get(i, d['demand_qty'])
                            status = "âœ…" if d['deployed_qty_invCon'] == adjusted_qty else "âš ï¸"
                            # print(f"      {status} [{d['demand_element']}] åŸå§‹éœ€æ±‚={d['demand_qty']} è®¡åˆ’={adjusted_qty} åˆ†é…={d['deployed_qty_invCon']} è·¨èŠ‚ç‚¹={is_cross_node}")

                # å¤„ç†GAPå’Œç”Ÿæˆè°ƒæ‹¨è®¡åˆ’
                gap_count = 0
                for i, d in enumerate(demand_rows):
                    # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—gapæ—¶ä½¿ç”¨åˆ†ç»„MOQ/RVè°ƒæ•´åçš„æ•°é‡
                    receiving = d.get('from_location', d.get('receiving', loc))
                    is_cross_node = (loc != receiving)
                    adjusted_qty = adjusted_qtys.get(i, d['demand_qty'])
                    gap_qty = adjusted_qty - d['deployed_qty_invCon']
                    
                    if gap_qty > 0:
                        up_loc = get_upstream(loc, mat, network, sim_date)
                        gap_count += 1
                        
                        if up_loc:
                            new_demand_element = f"net demand for {d['demand_element']}"
                            up_gap_next.setdefault((mat, up_loc), []).append({
                                'demand_element': new_demand_element,
                                'planned_qty': gap_qty,
                                'leadtime': d['leadtime'],
                                'requirement_date': d.get('requirement_date', d['plan_deploy_date']),
                                'location': up_loc,
                                'from_location': loc,
                                'orig_location': d.get('orig_location', d['location'])
                            })
                        
                        unfulfilled_rows.append({
                            'date': d['plan_deploy_date'],
                            'sending': loc,
                            'receiving': receiving,
                            'demand_qty': d['demand_qty'],
                            'demand_element': d['demand_element'],
                            'unfulfilled_qty': gap_qty,
                            'reason': "supply shortage"
                        })
                        
                        # print(f"      ğŸ”¼ éœ€æ±‚ç¼ºå£: {gap_qty} [{d['demand_element']}] â†’ ä¸Šæ¸¸ {up_loc} (is_cross_node: {is_cross_node}, adjusted_qty: {adjusted_qty})")
                
                # if gap_count == 0:
                    # print(f"      ğŸŸ¢ æ— éœ€æ±‚ç¼ºå£")
                
                # ç”Ÿæˆè°ƒæ‹¨è®¡åˆ’è¡Œ
                for i, d in enumerate(demand_rows):
                    receiving = d.get('from_location', d.get('receiving', loc))
                    
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨åˆ†ç»„MOQ/RVè°ƒæ•´åçš„æ•°é‡
                    is_cross_node = (loc != receiving)
                    actual_planned_qty = adjusted_qtys.get(i, d['demand_qty'])
                    
                    # è‡ªè¡¥è´§ï¼ˆsending == receivingï¼‰ä¸åº”æœ‰leadtime
                    if loc == receiving:
                        planned_delivery_date = d['plan_deploy_date']
                        leadtime_for_row = 0
                    else:
                        planned_delivery_date = d.get('requirement_date', d['plan_deploy_date'])
                        # å³æ—¶è®¡ç®—è¯¥è¡Œçš„ lead timeï¼šsending=loc, receiving=receiving
                        sending_location_type = get_sending_location_type(
                            material=str(mat),
                            sending=str(loc),
                            sim_date=sim_date,
                            network_df=network,
                            location_layer_map=config.get('LocationLayerMap', {})
                        )
                        lt_row, _ = determine_lead_time(
                            sending=str(loc),
                            receiving=str(receiving),
                            location_type=str(sending_location_type),
                            lead_time_df=config['LeadTime'],
                            m4_mlcfg_df=config.get('M4_MaterialLocationLineCfg', pd.DataFrame()),
                            material=str(mat)
                        )
                        leadtime_for_row = int(lt_row)
                    
                    plan_row = {
                        'date': d['plan_deploy_date'],
                        'material': mat,
                        'sending': loc,
                        'receiving': receiving,
                        'demand_qty': d['demand_qty'],
                        'demand_element': d['demand_element'],
                        'planned_qty': actual_planned_qty,  # ğŸ”§ ä½¿ç”¨æ­£ç¡®åº”ç”¨MOQ/RVåçš„æ•°é‡
                        'deployed_qty_invCon': d['deployed_qty_invCon'],
                        'planned_delivery_date': planned_delivery_date,
                        'orig_location': d.get('orig_location', d['location']),
                        'leadtime': leadtime_for_row,
                        'is_cross_node': is_cross_node,  # æ·»åŠ æ ‡è¯†ä¾¿äºè°ƒè¯•
                    }
                    deployment_plan_rows.append(plan_row)

            # print(f"\nâœ… å±‚çº§ {layer} å¤„ç†å®Œæˆï¼Œå‘ä¸Šæ¸¸ä¼ é€’ {sum(len(v) for v in up_gap_next.values())} ä¸ªéœ€æ±‚ç¼ºå£")

            # æ›´æ–°GAPç¼“å†²åŒº
            up_gap_buffer = up_gap_next.copy()
        
        # push/soft-pushå†åˆ†é…
        dynamic_soh_for_push = {
            k: dynamic_soh.get(k, 0) - open_deployment_inbound.get(k, 0)
            for k in set(dynamic_soh) | set(open_deployment_inbound)
        }
        plan_push = push_softpush_allocation(deployment_plan_rows, config, dynamic_soh_for_push, sim_date)

        if plan_push:
            deployment_plan_rows.extend(plan_push)
            # print(f"\nğŸ”„ Push/Soft-push è¡¥è´§: ç”Ÿæˆ {len(plan_push)} æ¡è¡¥è´§è®¡åˆ’")

        # æ›´æ–°åº“å­˜ï¼ˆåŸºäºå½“æ—¥äº‹åŠ¡æµæ°´ï¼‰
        deployed_dict = {}
        df = pd.DataFrame(deployment_plan_rows)
        if not df.empty:
            today_rows = df[df['date'] == sim_date]
            for _, row in today_rows.iterrows():
                k = (row['material'], row['sending'])
                qty = row['deployed_qty_invCon'] if row['sending'] != row['receiving'] else 0
                deployed_dict[k] = deployed_dict.get(k, 0) + qty

        # æ›´æ–°soh_dictä¸ºä¸‹ä¸€æ—¥çš„æœŸåˆåº“å­˜
        all_keys = set(list(beginning_inventory.keys()) +
                       list(today_production_gr.keys()) +
                       list(today_intransit.keys()) +
                       list(deployed_dict.keys()) +
                       list(today_shipment.keys()) +
                       list(delivery_gr.keys()))
        
        for (mat, loc) in all_keys:
            beginning_soh = beginning_inventory.get((mat, loc), 0)
            prod = today_production_gr.get((mat, loc), 0)
            intrans = today_intransit.get((mat, loc), 0)
            deliv_gr = delivery_gr.get((mat, loc), 0)
            deployed = deployed_dict.get((mat, loc), 0)
            shipped = today_shipment.get((mat, loc), 0)
            
            # æœŸæœ«åº“å­˜è®¡ç®—ï¼šæœŸåˆ + ç”Ÿäº§ + åœ¨é€”åˆ°è´§ + æ”¶è´§ - å‘è´§ - è°ƒæ‹¨
            end_soh = beginning_soh + prod + intrans + deliv_gr - shipped - deployed
            soh_dict[(mat, loc)] = end_soh  # ä½œä¸ºä¸‹ä¸€æ—¥çš„æœŸåˆåº“å­˜
            
            stock_on_hand_log.append({
                'material': mat,
                'location': loc,
                'date': sim_date,
                'beginning_soh': beginning_soh,
                'production': prod,
                'in_transit': intrans,
                'delivery_gr': deliv_gr,
                'today_shipment': shipped,
                'deployed_qty': deployed,
                'ending_soh': end_soh
            })
        
        # print(f"\nğŸ“Š å½“æ—¥ç»Ÿè®¡:")
        # print(f"   æ€»è°ƒæ‹¨è®¡åˆ’æ•°: {len(deployment_plan_rows)}")
        # print(f"   æœªæ»¡è¶³éœ€æ±‚æ•°: {len([r for r in unfulfilled_rows if r['date'] == sim_date])}")

    # åº”ç”¨æ”¶è´§ç©ºé—´é…é¢
    deployment_plan_rows_df, unfulfilled_space = apply_receiving_space_quota(
        deployment_plan_rows, receiving_space, sim_date, demand_priority_map
    )
    unfulfilled_all = pd.DataFrame(unfulfilled_rows + unfulfilled_space)

    outputs = {
        'DeploymentPlan': deployment_plan_rows_df,
        'UnfulfilledLog': unfulfilled_all,
        'StockOnHandLog': pd.DataFrame(stock_on_hand_log),
        'Validation': pd.DataFrame(validation_log),
    }
    log_outputs(output_path, outputs)
    
    # é›†æˆæ¨¡å¼ï¼šå°†éƒ¨ç½²è®¡åˆ’å‘é€ç»™Orchestratorï¼ˆç”±ä¸»é›†æˆè„šæœ¬ç»Ÿä¸€å¤„ç†ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œæš‚æ—¶æ³¨é‡Šæ‰ç›´æ¥è°ƒç”¨ï¼Œäº¤ç”±ä¸»é›†æˆè„šæœ¬ç»Ÿä¸€å¤„ç†ä»¥é¿å…é‡å¤
    # if config_dict is not None and orchestrator is not None and not deployment_plan_rows_df.empty:
    #     try:
    #         # è¿‡æ»¤å‡ºæœ‰å®é™…éƒ¨ç½²é‡çš„è®¡åˆ’
    #         valid_deployment = deployment_plan_rows_df[
    #             (deployment_plan_rows_df['deployed_qty_invCon'] > 0) & 
    #             (deployment_plan_rows_df['deployed_qty_invCon'].notna())
    #         ].copy()
    #         
    #         if not valid_deployment.empty:
    #             # é‡å‘½ååˆ—ä»¥åŒ¹é…orchestratoræœŸæœ›çš„æ ¼å¼
    #             orchestrator_deployment = valid_deployment.rename(columns={
    #                 'date': 'planned_deployment_date',
    #                 'deployed_qty_invCon': 'deployed_qty'
    #             })[['material', 'sending', 'receiving', 'planned_deployment_date', 'deployed_qty', 'demand_element']]
    #             
    #             orchestrator.process_module5_deployment(orchestrator_deployment, current_date)
    #             print(f"âœ… å·²å‘Orchestratorå‘é€ {len(orchestrator_deployment)} æ¡éƒ¨ç½²è®¡åˆ’")
    #         else:
    #             print(f"â„¹ï¸  æ— æœ‰æ•ˆéƒ¨ç½²è®¡åˆ’å‘é€ç»™Orchestrator")
    #     except Exception as e:
    #         print(f"âš ï¸  Orchestratoré›†æˆå¤±è´¥: {str(e)}")
    #         print(f"Error type: {type(e).__name__}")
    #         print(f"Deployment plan columns: {list(deployment_plan_rows_df.columns)}")
    #         print(f"Deployment plan shape: {deployment_plan_rows_df.shape}")
    #         if not deployment_plan_rows_df.empty:
    #             print(f"Sample row: {deployment_plan_rows_df.iloc[0].to_dict()}")
    #         import traceback
    #         traceback.print_exc()
    
    # print(f"\n{'='*60}")
    # print(f"ğŸ‰ ä»¿çœŸå®Œæˆ! æ‰€æœ‰å±‚çº§å·²å¤„ç†å®Œæ¯•")
    # print(f"ğŸ’¾ è°ƒæ‹¨è®¡åˆ’å·²ä¿å­˜è‡³: {output_path}")
    # print(f"ğŸ“ˆ æ€»è°ƒæ‹¨è®¡åˆ’æ•°: {len(deployment_plan_rows_df)}")
    # print(f"ğŸ“ æœªæ»¡è¶³éœ€æ±‚æ•°: {len(unfulfilled_all)}")
    # print(f"âœ… ä¿®å¤é‡å¤è®¡ç®—é—®é¢˜: ä½¿ç”¨æœŸåˆåº“å­˜ä½œä¸ºè®¡ç®—åŸºç¡€")
    # print(f"{'='*60}")
    
    # è¿”å›ç»“æœç”¨äºé›†æˆæ¨¡å¼
    return {
        'deployment_plan': deployment_plan_rows_df,
        'unfulfilled_log': unfulfilled_all,
        'stock_on_hand_log': pd.DataFrame(stock_on_hand_log),
        'validation_log': pd.DataFrame(validation_log),
        'statistics': {
            'deployment_count': len(deployment_plan_rows_df),
            'unfulfilled_count': len(unfulfilled_all),
            'processed_dates': len(sim_dates) if isinstance(sim_dates, list) else 1
        }
    }


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='Module 5: Multi-echelon Deployment Planning')
    parser.add_argument('--input', required=True, help='Input config excel path')
    parser.add_argument('--output', required=True, help='Output excel path')
    parser.add_argument('--sim_start', required=True, help='Simulation start date, YYYY-MM-DD')
    parser.add_argument('--sim_end', required=True, help='Simulation end date, YYYY-MM-DD')
    args = parser.parse_args()
    main(args.input, args.output, args.sim_start, args.sim_end)
